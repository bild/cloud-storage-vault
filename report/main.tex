\documentclass[pdftex,english,10pt,b5paper,twoside]{book}
\usepackage[T1]{fontenc} % In case we want special characters
\usepackage[utf8]{inputenc} % We are all writing in UTF-8

\usepackage[numbers]{natbib} % We need to tweak our referencing a bit.
\usepackage{appendix} % Fixes formatting of appendices
\usepackage[printonlyused]{acronym} % Package to handle the acronym list
\usepackage{graphicx} % We *may* use images
\graphicspath{{images/}} % and it is clean to put them in a separate dir
\usepackage{amstext} % To support \text in math mode
\usepackage{hyperref} % Internal and external links is nice
\hypersetup{
    pdfborder=0 0 0, % ..especially without red borders
    pdftitle={Cloud Storage Vault},
    pdfauthor={Haver, Melvold and Ruud},
    pdfsubject={Secure Storage in the Cloud},
    pdfkeywords={NTNU, thesis, secure, cloud, cryptographic, sharing}
}

% Packages and settings for code listings
\usepackage{listings}
\usepackage{caption}
\usepackage{upquote}
\usepackage{xcolor}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{
language=Java,
keywordstyle=\bfseries\ttfamily\color[rgb]{0,0,1},
identifierstyle=\ttfamily,
commentstyle=\color[rgb]{0.133,0.545,0.133},
stringstyle=\ttfamily\color[rgb]{0.627,0.126,0.941},
showstringspaces=false,
basicstyle=\small,
numberstyle=\footnotesize,
numbers=left,
stepnumber=1,
numbersep=10pt,
tabsize=2,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
breakatwhitespace=false,
aboveskip={1.5\baselineskip},
columns=fixed,
upquote=true,
extendedchars=true,
frame=bottomline,
inputencoding=utf8
}

% Set equal margins on book style
% \usepackage{layout} % Use \layout to print out the margins (debug)
%\usepackage{geometry}
%\geometry{bindingoffset=1cm}
\usepackage[lmargin=25mm,rmargin=25mm,tmargin=27mm,bmargin=30mm]{geometry}

% Restyle chapter headers
\usepackage{fix-cm}
\makeatletter
\renewcommand{\@makechapterhead}[1]{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedright \normalfont
    \vspace{15pt}%
    \ifnum \c@secnumdepth >\m@ne
        %\hfill\huge\scshape \@chapapp\space
        \hfill\fontsize{60}{90}\selectfont \thechapter % Chapter number
        \par\nobreak
        \vskip 20\p@
    \fi
    \interlinepenalty\@M
    \hfill \Huge \scshape #1\par % Chapter title
    \vspace{5pt}
    \hrule
    \nobreak
    \vskip 40\p@
  }}
\makeatother

\author{Eirik Haver \and Eivind Melvold \and Pål Ruud}
\title{Master thesis - Cloud Storage Vault}
\date{\today}

\begin{document}

\include{title}
\pagestyle{empty}

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\pagestyle{plain}
\pagenumbering{Roman}
\setcounter{page}{1}

%  Writers should follow a checklist consisting of:
% Motivation: Why do we care about the problem and results?
% Problem Statement: What problem are we trying to solve? Scope/limits.
% Approach: How did we go about solving or making progress on the problem?
% Results: What is the answer? Numbers, not vague 'very', 'small' etc.
% Conclusions: What are the implications of your answer? Further work.
%
%  Each section is typically a single sentence, although there is room for
%  creativity.

Today, major IT-companies, such as Microsoft, Amazon and Google, are offering
storage as a cloud service to their customers. This is a preferable solution to
regular storage in terms of low hardware costs, reliability, scalability and capacity.

However, the idea of storing customer data by an untrusted cloud provider
introduces the issue of data privacy and integrity. The customer is no longer in
position to control the physical access to the stored data, and is therefore
not guaranteed data privacy or integrity by the cloud provider.

To solve this problem, we have proposed a solution that ensures
privacy and integrity of customers' data stored by untrusted cloud providers.
The proposed solution does also support sharing of private data among customers
of the same cloud provider. The solution has further been implemented as a proof of concept. 

When implementing the solution, we first created an underlying framework to support the
proposed and necessary cryptographic functionality. The framework was further
utilized to implement the final application.

Application Results:

Conclusion:


\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

The work behind this project report was carried out during the spring semester
in 2011 at the Norwegian University of Science and Technology (NTNU), Department
of Telematics (ITEM).
\vspace{13pt}

\begin{center}
Eirik Haver, Eivind Melvold and Pål Ruud
\vspace{13pt}

\end{center}

\tableofcontents

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\listfigurename}
\listoffigures

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\listtablename}
\listoftables

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\lstlistlistingname}
\lstlistoflistings
\cleardoublepage

\chapter*{Acronyms}
\addcontentsline{toc}{chapter}{Acronyms}

\begin{acronym}[PBKDF2]
\acro{ACL}{Access Control List}
\acro{AES}{Advanced Encryption Standard}
\acro{API}{Application Programming Interface}
\acro{BC}{Bouncy Castle}
\acro{CA}{Certification Authority}
\acro{CBC}{Cipher Block Chaining}
\acro{CDA}{Cluster Dictionary Attack}
\acro{CG}{Credential Generator}
\acro{CPU}{Central Processing Unit}
\acro{DP}{Data Processor}
\acro{DRY}{Don't Repeat Yourself}
\acro{DSA}{Digital Signature Algorithm}
\acro{DSS}{Digital Signature Scheme}
\acro{DV}{Data Verifier}
\acro{EC2}{Elastic Compute Cloud}
\acro{ECB}{Electronic Codebook}
\acro{FAQ}{Frequently Asked Questions}
\acro{GPU}{Graphics Processing Unit}
\acro{FEC}{Forward Error Correction}
\acro{HDFS}{Hadoop Distributed File System}
\acro{HTTP}{Hypertext Transfer Protocol}
\acro{HTTPS}{Hypertext Transfer Protocol Secure}
\acro{IaaS}{Infrastructure as a Service}
\acro{IV}{Initialization Vector}
\acro{JCA}{Java Cryptography Architecture}
\acro{JCE}{Java Cryptographic Extensions}
\acro{JDK}{Java Development Kit}
\acro{JRE}{Java Runtime Environment}
\acro{JVM}{Java Virtual Machine}
\acro{LAFS}{Least Authority File System}
\acro{MITM}{Man-in-the-middle}
\acro{NIST}{National Institute of Standards and Technology}
\acro{PBKDF2}{Password-Based Key Derivation Function version 2}
\acro{PaaS}{Platform as a Service}
\acro{PasS}{Privacy as a Service}
\acro{PEP}{Python Enhancement Proposal}
\acro{PGP}{Pretty Good Privacy}
\acro{PKI}{Public Key Infrastructure}
\acro{PoC}{Proof-of-concept}
\acro{PRNG}{Pseudorandom Number Generator}
\acro{QR}{Quick Response}
\acro{RAM}{Random Access Memory}
\acro{ROM}{Read Only Memory}
\acro{REST}{Representational State Transfer}
\acro{RSA}{Rivest, Shamir and Adleman}
\acro{SaaS}{Software as a Service}
\acro{SDK}{Software Development Kit}
\acro{SHA}{Secure Hash Algorithm}
\acro{SQL}{Structured Query Language}
\acro{SSL}{Secure Socket Layer}
\acro{TCCP}{Trusted Cloud Computing Platform}
\acro{TCG}{Trusted Computing Group}
\acro{TG}{Token Generator}
\acro{TLS}{Transport Layer Security}
\acro{TPM}{Trusted Platform Module}
\acro{TTP}{Trusted Third Party}
\acro{URI}{Uniform Resource Indetifier}
\acro{URL}{Uniform Resource Locator}
\acro{VM}{Virtual Machine}
\acro{WSGI}{Web Server Gateway Interface}
\end{acronym}

%**************************************%
\chapter{Introduction}
%**************************************%
\pagenumbering{arabic}
\setcounter{page}{1}

% TODO: Generic introduction

\section{Motivation}

% What is different with this solution, than the other on the market?
% (Hva vi får ut av dette)
In the last decade, the supply of storing data remotely in the cloud has
increased considerable. Storing private data at a third party cloud provider
in contrast to self owned storage devices has proven to be preferable due to low
storage costs and high reliability, scalability and capacity.

However, storing data at a remote location prevents users from physically
protecting their storage medium. With this in mind, there is no guarantee that a
customer's data is kept private/secure from an untrusted storage provider.

To solve this issue, there has lately been introduced numerous of applications
providing solutions to ensure privacy and integrity of customer data stored at a
third party cloud provider. However, all of these alternative applications are
missing one or more features towards being, as we define, a completely secure
storage solution. %Open source, privacy, integrity, 

This situation has given motivation to implement a proof of concept
application, that provides what we define as a secure cloud storage service.
%TODO: presiser/skriv om motivasjonene under
The task will additionally give us more experience within software development,
development methodologies, team work, security and cryptography.


\section{Related Work}

% Summary of corresponding section in Background ch., and especially weight
% Tahoe.

In the later years, there has been quite a lot of research done in the field of
security in cloud computing. The problems that arise, are fundamentally not
different from those revealed by classic information security scenarios. The
key point, is that when using a service hosted by someone you do not know if
you can trust, you have to treat that \emph{someone} as untrusted and as a
possible attacker. Generally speaking, you loose control over the hosting
environment, and hence has to deal with the security issues this implies.

In Section \ref{sec:research}, we present four papers \cite{PasS,
privacymanager, tccp, microsoftresearch} which try to solve security issues in
a shared hosting environment. Common to all of these, is that they either rely
on special, secure and tamper-proof hardware and/or a trusted third party.

Another way of providing a solution to the same problem, is to give the
responsibility of the security operations to the client, i.e. in an environment
that the user has control of. In Section \ref{sec:existing}, we present three
commercially and publicly available software services that relates to this way
of thinking.

\section{Scope and Objectives}

% Sum up problem description and concretize the goals.

\subsection{Criteria for a Secure Cloud Storage Service}
\label{sec:criteria}
% TODO: Complete this list and section and section

\begin{enumerate}
  \item Open Source
  \item Encryption locally
\end{enumerate}

\section{Limitations}

% What we do not focus on (GUI, lesser important functions).
% Time constraints in relation to amount of work

\section{Methodology}

% theory, abstraction, design
% Research methodology, Scrum?, iterative
% Android, Eclipse

\section{Outline}

The work is presented as per the following chapters:

\paragraph{Chapter 2} provides background knowledge of the technologies and
software used.


%**************************************%
\chapter{Background}
%**************************************%

The basis and underlying technologies for a secure storage service in the
cloud, are quite numerous and quite often complex.

In the following sections, we will go through the security services, cryptographic
services and attacks that are relevant to such a service. In addition, we present
related research and existing solutions available at the time of writing.

This chapter forms the basis for the architecture of the proposed solution
presented in this thesis.

\section{Security Services}

This section explains the security services and technology used in this thesis. A security
service is any processing or communication service that enhances the security of
the data processing systems and the information transfers of any organization,
as defined by \citet[p. 12]{stallings}.

\paragraph{Confidentiality} Confidentiality is the act of keeping a message
secret from unauthorized parties \cite[p. 18]{stallings}. This can typically be
done by either preventing other parties access to the message at all, or by making
the contents unreadable, for instance by the use of encryption.

\paragraph{Integrity} Integrity implies that a message cannot be altered
without the receiving part noticing. In a security perspective, integrity deals
with detecting, preventing and recovering a message being changed by an
attacker \cite{stallings}.

\paragraph{Availability} The property of a system being accessible and usable
upon demand by an authorized system entity, are defined by the availability
service \cite{stallings}.

\paragraph{Authentication} Authentication is the act of a user, service or
similar to prove that he is what he claims to be \cite{stallings}.

\paragraph{Non-Repudiation} Non-repudiation prevents both the sender and the
receiver of a message from refuting the authenticity of transmitted message. In
other words, one party can prove the involvement of the other party
\cite{stallings}.

\section{Cryptographic Primitives}

This section describes the low level security primitives used in the results of
this thesis.

\emph{Randomness} is a basic property that multiple of the cryptographic
primitives rely on, and hence deserves an explanation. Random data is
informally defined as unpredictable to the attacker, even if he is taking
active steps to defeat the randomness \cite[p. 137]{schneier}.

A \emph{Cryptographic \ac{PRNG}} deterministically produce numbers based on a
seed, and it should be infeasible to determine the next number without knowing
the seed \cite[p. 140]{schneier}.

\subsection{Encryption}

Encryption is the process of transforming some information into an unreadable
form. It is primarily used to enforce confidentiality, but can also be
used for other purposes, e.g. authentication.

In its very basic form, an encryption scheme consist of an encryption algorithm
(the \emph{cipher}), a key and a message (the \emph{plaintext}), that is all
used to create an encrypted message, i.e. the \emph{ciphertext}. If a strong
cipher is used, knowledge of the cipher, or multiple plaintext and multiple
ciphertext, should not be enough to obtain the key, or to decrypt ciphertext
with a corresponding unknown plaintext \cite{schneier}.

\paragraph{Block Cipher and Stream Cipher} There are different classifications
on how a cipher treats data \cite[p. 32]{stallings}. A \emph{block cipher} will
encrypt a block of data of a specific size. If the data is larger than the
block size used by the application, a \emph{mode of operation} is needed. In a
\emph{stream cipher}, the plaintext will usually be combined with a pseudorandom key
stream to generate the ciphertext.

\paragraph{Symmetric Encryption} Symmetric-key encryption is an encryption scheme
where the same key is used for both encryption and decryption \cite[p.
32]{stallings}. The \ac{AES} is a block cipher and is the current standard for
symmetric encryption. The \ac{AES} works on a block of 128 bits at a time,
and support keys with length of 128, 192 and 256 bits.

\paragraph{The Mode of Operation} The mode of operation used for a
symmetric-key encryption enables subsequent safe use of the same key.

In a simple scenario, this could be to encrypt the normal data block-by-block
with pure \ac{AES}, which is called the \ac{ECB} mode of operation. The problem
with this is that some information of the plaintext will leak, i.e. the same
plaintext will always be encrypted as the same ciphertext.

An other mode is \emph{\ac{CBC}}. In \ac{CBC}, a non-predictable and not reused
\ac{IV} is used. The \ac{IV} is XORed with the first block of plaintext, which
again is encrypted with \ac{AES}. The resulting ciphertext is used as an
``\ac{IV}'' for the next block \cite[p. 183]{stallings}, and so on.

\paragraph{Asymmetric Encryption} Asymmetric key encryption is an encryption scheme
where different keys are used for encryption and decryption
\cite[p. 259]{stallings}.

An asymmetric encryption scheme is often called a \emph{public-key
encryption} scheme, where one key is defined as private and the other as public.
The public key is shared to allow other parties to encrypt messages that only the
owner of the private key can decrypt.

The downside of asymmetric encryption compared to symmetric is that it requires
a larger key, and that it has a larger computational overhead to obtain the
same level of confidentiality as comparable symmetric-key encryption. The
probably best known asymmetric cipher is \ac{RSA}.

\subsection{Cryptographic Hash Functions}

A cryptographic hash function is a deterministic mathematical procedure, which
takes an arbitrary block of data and outputs a fixed size bit string. The
output is referred to as the \emph{hash value}, \emph{message digest} or simply
\emph{digest}.

Another property of a cryptographic hash function, is that the
smallest change in the input data, e.g. one bit, should completely change the
output of the hash function. In other words, it should be infeasible to find the
reverse of a cryptographic hash function \cite[p. 335]{stallings}. It should
also be infeasible to find two blocks of data which produce the same hash value
(a \emph{collision}).

The standard for cryptographic hash functions today, are \ac{SHA}-1 and the
\ac{SHA}-2 family.

\section{Applications of Cryptographic Primitives}

\subsection{Digital Signatures}

A digital signature is the digital equivalent of a normal signature, i.e. it
verifies that an entity approves with or has written a message. It can also
verify the date the signature was made. In addition, it should be verifiable by
a third party \cite[p.  379]{stallings}.

It should logically not be possible, or at least unfeasible, to fake a digital
signature.

The \ac{RSA} cipher can be used to generate signatures. In addition, there is also a
standard for digital signatures, called \ac{DSS}, which uses \ac{DSA} as the
underlying algorithm.

\subsection{Digital Certificates and PKI}

A digital certificate is the pairing of a digital signature and a public key
\cite{stallings}. By this scheme, the services confidentiality, authentication
and non-repudiation can be achieved.

For example, a person has a certificate with some clues about the identity
in it, e.g. the e-mail, together with a public key. This certificate can then
be signed using digital signatures, to verify that some other entity trusts this
certificate.

In practice, the entity which signs certificates is the \ac{CA}, which all
clients have the public key information for, and trusts. The \ac{CA} will also
contain information about which certificates has been revoked, i.e. should not
be trusted in use. Such a scheme is usually referred to as a \ac{PKI}.

\subsubsection{PGP}

\ac{PGP} is a scheme similar to \ac{PKI}, but with no \ac{CA} that all users
trust \cite{stallings}. Instead, trust is made between users by somehow
verifying their public key, for instance by meeting face to face. A user can
then sign another users key, set a trust level for the user, and publish this
information to a key server.

Another user can then calculate a trust on an unknown person, based on the trust
set by peoples that he trusts, from information located on publicly
available key servers.

\subsection{SSL/TLS}

\ac{TLS}, and its predecessor \ac{SSL}, are technologies for obtaining
confidentiality, integrity and authentication for transfer of files over a
network \cite{stallings}. It does so by a combination of different algorithms
and primitives, but a digital certificate is required for authentication.

To transfer files securely over \ac{HTTP}, \ac{TLS}/\ac{SSL} is used to form
\ac{HTTPS}.

\subsection{PBKDF2}
\label{sec:PBKDF2}

\ac{PBKDF2} is a key derivation function used to create an encryption key based
on a password. The key point of this, is that a password is often something
that a person has to be able to recall from memory. But, a password phrase that
is memorable to a person, might be too short to withstand a dictionary or even
a brute force attack.

What \ac{PBKDF2} does, is to make the process of deriving the key from the password
an expensive process in terms of computational power, to make it more resistant
to brute force attacks. This feature is known as \emph{key stretching}.

The efficiency of the key derivation, is dependent on the number of process
iterations chosen in the implementation of the function.

\section{Security Attacks}

This section briefly list security attacks relevant to this thesis, as defined
by \citet[Ch. 1.3]{stallings}.

\paragraph{Active and Passive Attacks} Two general classifications of security
attacks exist, where a \emph{passive attack} attempts to learn or make use of
information from the system, but does not affect system resources. An
\emph{active attack} attempts to alter system resources or affect their
operation.

\paragraph{Traffic Analysis} Traffic Analysis is the act of capturing and
examining communication data sent between two parties. This information might
contain secrets or for instance leak enough information about an encryption key
to make it breakable.

\paragraph{Masquerade} Masquerade is an active attack where the attacker pretends to be
one of the legitimate parties.

\paragraph{Replay} Replay is an active attack where the attacker capture some
data in a communication session and subsequently retransmit that information.

\paragraph{Modification of Messages} Modification of messages is an active
attack where the attacker alters some of the contents of a message sent between
two communicating parties.

\paragraph{Denial of Service} Denial of Service is an active attack where the
attacker seeks to make resources unavailable for legit users, i.e. by
overloading an application by sending it lots of traffic.

\paragraph{\acl{MITM}} \ac{MITM} is an attack where an attacker intercepts messages
between the communicating parties and then either relay or substitute the
intercepted message.

\subsection{Attacks on Cryptographic Primitives}

Even though cryptographic primitives are designed to be secure, they might have
implementation flaws and be used in an improper fashion, e.g. by using wrong
parameters.

\paragraph{Cryptanalysis Attack} A cryptanalysis attack is an attempt to deduce
a specific plaintext or to deduce the key being used in a ciphertext.

\paragraph{Brute-Force Attack} In a brute-force attack, an attacker tries
to obtain a secret by testing the algorithm with up to all possible inputs. The
secret might be an encryption key, or the data fed into a cryptographic hash
function.

A related attack is the \emph{Dictionary attack}, where the attacker
tries to obtain a secret by trying a subset of all known inputs, i.e. a
predefined dictionary of words.

\section{Cloud Computing}

In a draft \cite{cloud_nistdef}, the \ac{NIST} defines cloud computing as:
\begin{quote}\it
``Cloud computing is a model for enabling ubiquitous, convenient,
on-demand network access to a shared pool of configurable computing resources
(e.g., networks, servers, storage, applications, and services) that can be
rapidly provisioned and released with minimal management effort or service
provider interaction.''
\end{quote}

\subsection{Service Models}
The \ac{NIST} also defines three service models which deals with what kind of
service the consumer can rent from a provider.

\paragraph{\ac{SaaS}} The capability for a consumer to run the provider's
application running on cloud infrastructure, using a thin-client, browser or
similar, is called \ac{SaaS}. The web-based email service
GMail\footnote{\url{http://www.gmail.com}} can be seen as an example of this.

\paragraph{\ac{PaaS}} The capability for a consumer to deploy software onto
the cloud, but without actually controlling the underlying platform, operating
system and so on, is called \ac{PaaS}.

\paragraph{\ac{IaaS}} The capability provided to the consumer to provision
processing, storage, networks and other fundamental computing resources where
he can run arbitrary software, including operating systems and applications, is
called \ac{IaaS}. An example is when renting a \ac{VM}.

\subsection{Deployment Models}

The \ac{NIST} draft \cite{cloud_nistdef} also lists several deployment models
which deals with how the cloud is organized in terms of where it is hosted, and
who has access to it.

\paragraph{Private Cloud} A private cloud is a cloud infrastructure operated
solely for an organization. Which party manages the cloud, and where it is
located is not defined.

\paragraph{Community Cloud} A community cloud is a cloud infrastructure is
shared by several organizations to serve a common concern. Where it is located
and who manages it is not given.

\paragraph{Public Cloud} A public cloud is a cloud infrastructure where
everyone, or at least a large group, can have access, and is owned by an external
provider of cloud services.

\paragraph{Hybrid Cloud} A hybrid cloud is a cloud infrastructure composed of
two or more clouds of any other model.

\subsection{Security Considerations in Cloud Computing}

There are some considerations when using cloud services from an external
provider, as opposed to self controlled hardware, software and platforms. Most
notably is that you loose the control of selecting the people which will have
physical and digital access to the infrastructure \cite{cloud_getoff}. In
essence, this means that the provider can read every data sent to and from the
cloud as well as the data saved in the cloud.

Another risk is that information might be leaked to other users of the same
cloud. For instance it might be able possible for a \ac{VM} to leak information
to other \acp{VM} on the same host \cite{cloud_getoff}.

\section{Research}
\label{sec:research}

This section will elaborate on selected previous research concerning privacy
within cloud computing. The research on this subject can be divided into
proactive solutions that either reduce, or prevent the risk of leaking privacy
related information. Only the latter type of solutions are further discussed.

\subsection{Privacy as a Service}

A concept entitled \ac{PasS}, was suggested in 2009 \cite{PasS}. \ac{PasS} is a set
of security protocols ensuring privacy of customer data in cloud computing
architectures. The main design goal with \ac{PasS}, is to maximize the user's control
over his sensitive data, both processed and stored within a cloud.

The \ac{PasS} concept is based on a fundamental \emph{system model} and \emph{trust
model}. The system model consists of three communicating parties, namely a
\emph{cloud provider}, a \emph{cloud customer} and a \emph{\ac{TTP}}. The
\ac{PasS} system model is shown in Figure \ref{fig:RW:PasS}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ArchitecturePasS.pdf}
    \caption{System model of PasS}
    \label{fig:RW:PasS}
\end{figure}

It is important to notice that the \ac{PasS} system model is dependent on
pre-installed cryptographic coprocessors in the hardware running the cloud
service.

A cryptographic coprocessor is a small hardware card, including a processor,
\ac{RAM}, \ac{ROM}, backup battery, persistent storage and an Ethernet network
card. A coprocessor interfaces with a server in the cloud, and provides a safe
environment for processing of a customer's sensitive data.

The cryptographic coprocessors are used in the cloud because they are
tamper-proof against physical attacks. The coprocessors are pre-configured by
the \ac{TTP} before they are installed. By using this procedure, the \ac{TTP}
provides a safe computational environment for the cloud customer, which is kept
secret from the cloud provider.

The main task of the \ac{TTP} is to compute a set of public/private key pairs,
load them into the persistent storage of the co-processor, and further send
them to the customer. The \ac{TTP} also loads its own secret key into the
coprocessor. This key distribution ensures secure communication between the
\ac{TTP}, coprocessors and the cloud customer. The customer's key pair is sent
through a secure communication channel.

With cryptographic coprocessors in the cloud and a secure communication, the
cloud customer can choose between three different levels of privacy towards the
cloud provider -- no privacy, privacy with a trusted provider and privacy with
a none-trusted provider.

\emph{No privacy} implies storing data as clear text in the cloud.
\emph{Privacy with a trusted provider} involves storing encrypted data in the
cloud. This data is encrypted by the cloud provider and only achievable by the
customer or cloud provider.

In the case of \emph{privacy with a non-trusted provider}, the customer
encrypts the private data before uploading it to the cloud provider. The key
used for encryption is shared with the cryptographic co-processor, through an
authenticated version of the Diffie-Hellman key management protocol. The
co-processor can further process the encrypted data and store it in the cloud
facility. The stored data is encrypted and unknown to the cloud provider.

\subsection{Privacy Manager}

In 2009, HP Labs proposed a way to manage and control a user's private data,
stored and processed in a cloud facility \cite{privacymanager}. Their solution
was partially implemented as a software program called a \emph{privacy manager}.

The privacy manager uses a feature called \emph{obfuscation}, which is quite
similar to encryption. However, the obfuscation method is different from
encryption in the sense that the obfuscated data can be processed in the
cloud, without the cloud provider knowing the encryption key or the original
data. \citet{privacymanager} mention the following obfuscation methods:

\begin{itemize}
\item Yao's protocol for secure two-party computation \cite{yao}
\item Gentry's homomorphic encryption scheme \cite{gentry}
\item Narayanan and Schmatikov's obfuscation method \cite{obfuscationmethod}
\end{itemize}

Due to better efficiency, the privacy manager uses the latter alternative. However,
Narayanan and Schmatikov's obfuscation method does not provide complete
confidentiality to the cloud provider \cite{obfuscationmethod}.

In addition to installing a privacy manager at the user's terminal, HP Labs
suggests the use of trusted computing solutions to address the lower-level
protection of data. The \ac{TCG} is an example of an organization developing
and providing trusted computing solutions \cite{tcg}. A tamper-proof piece of
hardware called a \ac{TPM} is recommended \cite{privacymanager}, which is
designed by \ac{TCG}. The \ac{TPM} is installed in the machine running the
privacy manager, to ensure that processes carried out by the privacy manager can
be fully trusted.

The privacy manager is suggested to work in three different use cases. It can
be implemented to support a \emph{single client}, the use of \emph{hybrid
clouds} and/or the use of an \emph{infomediary} within the cloud.

%Regarding applications in the cloud where users have to upload unobfuscated
%private data, the privacy manager includes two additional features called
%preferences and personae. Both features are dependent on a trustworthy service
%and cloud provider, and are therefore irrelevant to our development.

\subsection{Trusted Cloud Computing Platform}

Equal to \acl{PasS} and the privacy manager, \emph{\ac{TCCP}} was proposed as a
solution to provide secure computations and storage within a non-trusted cloud
provider \cite{tccp}. As opposed to the previous solutions, \ac{TCCP} is
directed against secure execution of guest \acp{VM} outsourced to \ac{IaaS}
providers.

The original infrastructure, before adding \ac{TCCP}, is assumed to
consist of a \emph{cloud manager}, which manages a cluster of nodes running one or more
\acp{VM}. Among multiple tasks, the cloud manager is responsible for loading \ac{VM}
images into its own nodes.  Each node has a \emph{\ac{VM} monitor} which will further
launch and monitor \acp{VM} from the received corresponding images.

\ac{TCCP} is based upon the \acf{TPM} chip designed by the \acl{TCG}. The
\ac{TPM} contains a private/public key pair that it uses to uniquely identify
itself. The public key is additionally signed by the manufacturer to guarantee
correctness of the \ac{TPM} chip.

With this in mind, \ac{TCCP} is based upon a \emph{remote attestation scheme}.
The scheme enables a network entity to verify whether another remote entity
runs a \ac{TPM} chip or not. A detailed description of the remote attestation scheme
is given by \citet{tccp}.

The \ac{TCCP} system architecture is illustrated in Figure \ref{fig:RW:TCCP}.
The trusted computing base of \ac{TCCP} includes a \emph{trusted coordinator}
and a \emph{trusted virtual machine monitor}. The coordinator manages the
trusted nodes within a cluster. To be trusted, a node must be located within a
security perimeter and run a trusted virtual machine monitor.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{ArchitectureTCCP.pdf}
    \caption{System architecture of TCCP}
    \label{fig:RW:TCCP}
\end{figure}

The coordinator maintains a record of the nodes located in the security
perimeter, and use remote attestation to ensure nodes are trusted. Each trusted
node in a cluster contains a \ac{TPM} chip and a corresponding trusted monitor.
The main task of the trusted monitor, is to enforce a local closed box
protection of a client's running \ac{VM}. Details about the design of the
trusted \ac{VM} monitor, are given by \citet{tccp}.

Each trusted virtual machine monitor cooperates with a trusted coordinator to
protect the transmission of \acp{VM} between trusted nodes, and to ensure that
\acp{VM} are executed by trusted nodes. In this context, the \ac{TCCP}
specifies several protocols for both launching and migrating \acp{VM} inside
the cloud. These protocols are described by \citet{tccp}.

The trusted coordinator-part is installed in servers operated and maintained by a
trusted third party, to prevent unwanted tampering from the \ac{IaaS} provider.
A client can further use remote attestation to the coordinator to verify that the
\ac{IaaS} provider secures its computation.

With \ac{TCCP}, the client interacts with the \ac{IaaS} provider as usual. The
difference is that the trusted nodes and their trusted coordinator communicates
to ensure a secure environment for executing the client's \ac{VM}.

\subsection{Cryptographic Cloud Storage}

In 2010, researchers at Microsoft were looking at the problem of building a
secure cloud storage service on top of a non-trusted cloud storage provider
\cite{microsoftresearch}. They described architectural solutions related to
both consumers and enterprises. The architectures were explained in high level
and were designed to utilize and combine recent and non-standard cryptographic
primitives.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ArchitectureCCSC.pdf}
    \caption{Cryptographic cloud storage, customer scenario.}
    \label{fig:RW:CCS:CA}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ArchitectureCCSE.pdf}
    \caption{Cryptographic cloud storage, enterprise scenario.}
    \label{fig:RW:CCS:EA}
\end{figure}

The consumer architecture is depicted in Figure \ref{fig:RW:CCS:CA}, and a typical
enterprise architecture is shown in Figure \ref{fig:RW:CCS:EA}.\\

\noindent Each architecture consists of the following computational components:
\begin{description}
  \item[\ac{DP}] \hfill \\Processes data before it is sent to the cloud.
  \item[\ac{DV}] \hfill \\Checks whether data stored in the cloud has been
  tampered with.
  \item[\ac{TG}] \hfill \\Generates tokens that enable the cloud provider to
  retrieve segments of customer data.
  \item[\ac{CG}] \hfill \\Responsible for creating and distributing access
  policies.
\end{description}

The core components are suggested to support \emph{searchable encryption},
\emph{attribute-based encryption} and a \emph{proofs of storage} protocol.

\section{Existing Solutions}
\label{sec:existing}

There are a number of existing solutions for storing data in the cloud,
with more or less of the functionality required to fulfill the problem
description for this thesis. The section highlights some of them.

\subsection{Dropbox}

Dropbox\footnote{\url{http://www.dropbox.com/}} is a popular commercial
application for storing data in the cloud, claiming more than 25 million users
\cite{dropbox_users}. All files are saved using Amazons S3 storage service.

The company boasts strong encryption and strict access control
\cite{dropbox_security}, but has received criticism for its lack of security
\cite{dropbox_concerns}. Among these concerns, is the \emph{Forgotten Password}
feature, which implies that Dropbox can read the users files if they really
want to -- because they have the password -- and that the encryption is
performed server-side.

In addition, Dropbox is not Open Source, and hence one has no way of verifying
that the security features actually work as claimed.

\subsection{Tahoe-LAFS}

Tahoe-\ac{LAFS}\footnote{\url{http://www.tahoe-lafs.org/}} is an open source,
distributed and secure cloud storage file system, which does fulfill
the criteria set in Section \ref{sec:criteria}.
The integrity and confidentiality of the
files are guaranteed by the algorithms used on the client, and is independent
of the storage servers, which may be operated by untrusted people.
This is defined as \emph{provider-independent security} \cite{tahoe}.

In Tahoe-\ac{LAFS}, files are exclusively encrypted client-side, then split up
using \emph{Erasure-coding}, before being uploaded into the cloud\footnote{The
\emph{cloud} in the Tahoe-\ac{LAFS} sense, often refers to other nodes in a so
called \emph{friend net}.}, as illustrated in Figure \ref{fig:B:tahoe}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{Tahoe-newfile.pdf}
    \caption{Tahoe-LAFS: Insertion of a new file}
    \label{fig:B:tahoe}
\end{figure}


\subsubsection{Architecture of Tahoe-LAFS}

Tahoe-\ac{LAFS} has a three layer architecture: the key-value store, the filesystem, and
the application \cite{tahoe}.

The \textbf{key-value store}, is the lowest layer and is implemented by a grid
of Tahoe-LAFS storage servers. Data is kept on the storage servers in the form
of \emph{shares}, which are encrypted and encoded parts of files. Capabilities
are short ASCII strings, containing information on where to find a file, and
how to verify it.  Nodes in the grid learn about each other through an
\emph{introducer}.

The \textbf{filesystem} layer is responsible for mapping human-meaningful
pathnames to pieces of data. Each directory contains a table of capabilities
for its children, i.e. subdirectories or files. Two forms of capabilities is
available for each file, read-only and read-write, and these can be distributed
to e.g. share a file with friends.

Since it is not practical for users to remember strings containing random
characters, the \textbf{application} layer is used for providing a user-friendly
interface to the directories and files.

\paragraph{File Types}

There are two kinds of files in the Tahoe-\ac{LAFS} -- \textbf{immutable} and
\textbf{mutable} files. An immutable file is created exactly once, i.e. it
cannot be modified, and can be read repeatedly. Mutable files can be modified,
and everyone who has access to the signing key can make new versions of
the mutable file. Directories are implemented as mutable files.

\paragraph{Erasure Coding}

Erasure-coding with the Solomon-Reed scheme, enables Tahoe-\ac{LAFS} to recover
a file using only a predefined subset of the parts distributed to the storage
servers. Erasure coding is a type of \ac{FEC} code, which extends a message
with $C$ characters into a longer message with $N$ symbols
\cite{t_reed-solomon}. The original $C$ characters can then be recovered from a
subset of the $N$ symbols.

\subsection{Wuala}

Wuala\footnote{\url{http://www.wuala.com/}} is a closed source secure cloud
storage file system, that seemingly operates very similar to Tahoe-\ac{LAFS}.

The authors have released a paper on a cryptographic tree structure for file
systems, called Cryptree \cite{cryptree}, and has strong focus on reliability
by both providing central servers, in addition to a \emph{P2P cloud} of Wuala
users that has donated capacity to the system.

%**************************************%
\chapter{Technical Procedure}
%**************************************%
\section{Architectural Overview}
%**************************************%
\label{chap:AS}

The architectural solution of a secure cloud file sharing system has to
convince its users that the functions indeed are secure, and that the concepts
are easy to understand and accept. The following sections will elaborate on the
architecture designed by us, favouring simplicity and familiar concept such as
files and directories. We also introduce the concept of a \textbf{Capability}.

Figure \ref{fig:AS:overview} represents an overview of the functionality that
the architecture must support. The Figure exhibits a user uploading a file to
the cloud, and adding this to a parent directory. After he has done this it is
possible for him to distribute the Capability to other users to realize sharing
of files or directories.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureOverview.pdf}
    \caption{Overview of user functionality}
    \label{fig:AS:overview}
\end{figure}

\subsection{File Storage}
\label{sec:AS:FS}

The solution proposed in this thesis, is that only a simple key-value store is
needed on the server side. The key works as a lookup index for a specific value,
while the corresponding value equals an encrypted file object. The server will
be required to support the operations of uploading and downloading files from
this store.

From the users perspective a file object can however have multiple forms, it
can either be a mutable or immutable file. A mutable file can be changed, and
is what a user will see as a directory, while an immutable file is what a users
would see as a normal file.  

A user will need certain information to be able to reach and read a file
object, we define these properties as the \emph{Capability} of a file object.
For now the Capability represents the ability to find, read, verify that a file
has not been tampered with and possibly write to the file object.


\subsubsection{Directory Structure} 

The contents of a directory are files or other directories. More specifically a
directory contains the means to find files or directories, namely the
Capabilities of these file objects. In addition there exist a human readable
name, an \emph{Alias}, for each entry in a directory. This design gives a
flexible and space-conservative structure, since any file object may be found
from multiple directory, but does only exist once in the cloud.

A user will have to have some way of storing the Capabilities of his file
objects. This could potentially be done client side, but a problem arises if
the user wants to use several terminals. Therefore we introduce the \emph{root
folder}, a folder from which all other files and folders can be reached.  The
user will then only need to know of one single Capability to reach all his
stored data. This capability needs to be stored and protected by the client in
a password protected \emph{keyring}. The resulting structure is a directed
graph illustrated in Figure \ref{fig:AS:filesystem}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureFileSystem.pdf}
    \caption{File System Structure}
    \label{fig:AS:filesystem}
\end{figure}

\subsection{ACL/Authentication Layer}

The possession of a Capability gives a user access to read a file or read or
write a folder. However there are some properties that The server provider
might want or needs that can not be given by the Capability. Therefore a layer
implementing authentication and possibly more access control could be
preferable.

\subsubsection{Block access to encrypted data}

The capability for a file or folder might be intentionally or unintentionally
leaked by a user. In this case it would be preferable that the server can block
access to a particular object. The server could also potentially enforce access
right on all encrypted objects based on who a user has shared a file with.
This does however require the client to notify a server every time he shares a
file object with a new person, and is strictly not necessary from a security
standpoint.

\subsubsection{Modification and deletion of objects} 

For each directory there exist a different Capability for read and write
operations, however the read Capability can be deduced from the write
Capability. From the write Capability it is possible to deduce another secret,
the \emph{Write Enabler} which the server also knows of.  Knowledge of the
write enabler is needed for the server to grant access to modify or delete a
folder. 

For immutable files there is no concept of write-access, only read. It is both
illogical and impractical to assume that read access should also yield delete
access. A layer that identifies the creators of a file, can by the same method
decide who should have the rights to delete it.

\subsubsection{Accounting}

If the server side of the application is held by a cloud storage provider, it is
important to be able to decide which users should be billed for the file storage
and generated network traffic.

In the case of an immutable file, the storage costs can be billed to the user
creating the file. The costs of network traffic can further be charged to the
users retrieving the file.

Accounting might also be interesting for an organization using a third party
cloud provider. For instance an employee who leaves the organization might be
tempted to copy all the data stored on the server, the organization should then
be able to discover what he has done. It is however worth noting that if the
accounting happens server side, there is no real way to verify that all logs
stored there are correct, since the cloud provider will have access to at least
delete them.

\subsection{User Scenarios}

The various user scenarios supported by the software, provides a logical way to
describe the external properties of the system. The fundamental operations are
\emph{downloading}, \emph{uploading} and \emph{sharing} of files.

\subsubsection{Download File}

The download procedure is depicted in Figure \ref{fig:AS:download}.  The client
sends a download request with the identifier of a folder which he possesses the
Capability of. The server will respond with the encrypted directory. The user
will use the Capability to decrypt the directory. In the directory the user
finds the aliases and necessary Capabilities to gain access to the children of
that folder. If the user now wants to download a file from the opened folder he
obtains the identifier for this file from the files Capability, and requests
the server for this file. Once downloaded the Capability provides means of
decrypting and verifying that the file has not been tampered with.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureDownload.pdf}
    \caption{Scenario: Downloading a file}
    \label{fig:AS:download}
\end{figure}

\subsubsection{Upload File}

Figure \ref{fig:AS:upload} shows the process of uploading new files. The
Capability for the new file is generated by the client, and used to encrypt the
file. The file is then uploaded to the cloud, and the Capability and an alias
is linked in to the parent folder of the file. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureUpload.pdf}
    \caption{Scenario: Uploading a file}
    \label{fig:AS:upload}
\end{figure}

\subsubsection{Share Files}

As shown in Figure \ref{fig:AS:sharing}, for Alice to be able to share files
with Bob, she first has to create a new directory that will contain these
files. Alice is then required to share a capability of the new directory with
Bob. When the capability is shared, the new directory will work as a secure
channel where Bob and Alice can share their own folders and files.

Before transferring the capabilities to Bob, Alice links the shared directory to
a parent directory, so she can easily find it again at a later time. She can
also link files to the shared directory.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureShare.pdf}
    \caption{Scenario: Sharing files}
    \label{fig:AS:sharing}
\end{figure}

The capability distribution is a key design issue, and has to be performed in a
secure manner. This can be solved in a variety of ways, and the solutions
proposed in this thesis are discussed in Section \ref{sec:DI:keydist}.

After receiving the capabilities for the shared folder from Alice, Bob requests
and receives the encrypted shared directory, in addition to linking it with a
parent directory for future usage. He can then download shared files as if they
where his own.

\paragraph{Read-Only Shares}

If Alice wants to share a directory in Read-Only mode, she can simply share the
read Capability with Bob instead of the write Capability. This will work as
intended but might prove somewhat irritating for Alice. If Alice wants to write
to the directory she has shared with Bob she can not enter it through the
parent folder shared with Bob, since this will only grant her the read
Capability. The implication is that Alice will have to find the directory
another place in her directory tree, which might be cumbersome. 

A more simple solution is to enable Alice to store the write capability
individually among her private files, while storing the read capability in the
shared parent directory. The solution can easily be implemented by using a
specialized \emph{write key folder} under Alice's root folder. The write key
folder will then contain write capabilities to every folder that Alice has
shared in Read-Only mode.  The idea behind the write key folder is illustrated
in Figure \ref{fig:AS:readonly}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureShareReadOnlyFolder.pdf}
    \caption{Sharing write-protected folders}
    \label{fig:AS:readonly}
\end{figure}

\subsection{Implications of User Equipment}

The software should be able to run on restricted devices, i.e. equipment with
limited memory and \ac{CPU} power, often in addition to constraints on power and
network consumption.

This has implications for the design of the software, since all cryptographic
operations has to be performed client-side. These considerations will be
brought up throughout the further description of the software.

%**************************************%
\section{Cryptographic Architecture}
%**************************************%
\label{chap:CS}
This section will elaborate on the cryptographic solutions applied to the
architectural scheme in Chapter \ref{chap:AS}. We will take a closer look at
how confidentiality, integrity and authentication can be integrated into the
proposed architecture.

%A fundamental scheme for key distribution is needed to realize the desired
%security features, hence an appropriate solution for key distribution will
%also be given.

The first section is a brief introduction explaining the basic
security concept used by the application. Following is a detailed description of
the cryptographic solutions adapted. The cryptographic solutions are revealed
in terms of file and directory operations performed by the application. The
chapter ends with a description of a users keychain.

\subsection{Security Concept}

The basic security concept of the application is to keep a user's remote storage
confidential to a third-party storage provider. To solve this, the application
encrypt files locally at the users terminal before uploading them to the
third-party storage provider. When accessing a file, the application first
download the encrypted file and further decrypt it locally. To enable this
simple encryption scheme, the user terminal is required to possess at least one
cryptographic key. Cryptographic keys are stored in a single keychain at the user
terminal.

By initially knowing that files are placed encrypted on a remote server and that
the local user possess one or more cryptographic keys, we can continue with a
more comprehensive description of the complete cryptographic solution. The
details are explained in terms of the following directory and file operations.

\subsection{Directory Operations}
\label{sec:CS:DO}

This section presents the two basic directory operations used by the
application. The ``create directory'' and ``open directory'' operations are
explained as follows.

\subsubsection{Create Directory}

The create directory operation is divided into two subsequent parts. First, the
directory must be created locally at the user's terminal. Second, the directory
must further be uploaded to the remote server.  Uploading a file or directory is
possible only if the user is authenticated.

Creating and uploading a directory from the user terminal is illustrated in
Figure \ref{fig:CS:CD}.

\begin{figure}[h!]
    \centering
        \includegraphics[width=\columnwidth]{CryptoCreateFolder.pdf}
	    \caption{Creating and uploading a directory.}
    \label{fig:CS:CD}
\end{figure}

Before creating a new directory it is necessary to generate an RSA key-pair. The
key-pair is specific to the new directory and consists of a public and private
signing key. The signing key is further used to derive a write and a read key
for the corresponding directory. The read key is a hashed value of the write
key, while the write key equals the hashed value of the signing  key.

% TODO: Will we use counter IV?
After key generation, the public key is directly added to the new directory. The
directory's storage index is further added as a hash value of the directory's
read key. The next value added to the directory is the initialization vector
\ac{IV}. The IV is generated from a counter value stored at the user terminal. It
is used to prevent predictable ciphertext, when the directory's entries are encrypted.

The next value added to the directory is the write enabler. The write enabler is
an HMAC-SHA-2 value created from the directory's write key and a static chosen
text value. It is uploaded as a part of the directory, but can never be
downloaded from the server. The write enabler is used by the server to enable
users, that possess the directory's write key, to modify the directory. This
ensures that only authorized users can modify a directory.

After adding the write enabler, the user must add the directory's private
signing key. The signing key should only be available for users with write
permission to the directory. It is therefore encrypted with the directory's
write key before it is added to the directory. The signing key is encrypted using \ac{AES} in
\ac{CBC} mode. The next value added is the directory's entries. The entries of a
directory should only be visible to users with read permissions to
the directory. They are therefore encrypted with the directory's \ac{IV} and read
key prior to insertion. The entries are encrypted using \ac{AES} in \ac{CBC} mode. The
last value added to the directory is a signed hash value of the encrypted
entries. The hash value is encrypted with the signing key using \ac{RSA}. A
signature is needed for other users to know that the directory was created from
an authorized user.

After creating a new directory, the directory is further uploaded to the remote
server.

It is important to notice that none of the values contained within the
directory or any of the cryptographic keys are kept locally by the user. The
user can only achieve the public and private keys through the remote directory.
The directory's read and write keys can only be achieved through capabilities stored
in the remote directory's parent directory. This is true for all directories
stored on the server except for the user's root directory. The keys to the
root directory are stored in the user's local keyring. The keyring is explained
in Section \ref{KEYRING}.

\subsubsection{Open Directory}

This section describes the procedure for opening a directory. Opening a
directory involves both downloading, verifying and decrypting the directory. The
download and verify procedure is illustrated in Figure \ref{fig:CS:VOD} and
described below. A description of the subsequent decryption procedure follows.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{VerifyOpenFolder.pdf}
    \caption{Downloading and verifying a remote directory.}
    \label{fig:CS:VOD}
\end{figure}

First of all, to download a desired directory, the user must be in
possession of a read key specific to that directory. The read key is either
created from a hash value of the directory's write key, or obtained from a read
capability stored in the parent directory.

The directory's storage index is further obtained. It is either created from the
obtained read key, or obtained from the read capability stored in the parent
directory. The storage index is a simple hash value of the read key. It is used to
localize the specific directory on the remote server. The localized directory is
further downloaded to the user's terminal.

When the correct directory is downloaded, it will further exhibit a verification
procedure prior to decryption. The verification procedure is illustrated in
Figure \ref{fig:CS:VOD}.

The purpose of the verification procedure is to check the integrity of the
content and to verify that it has been written by an authorized user.
If one or neither of these checks are verified, the directory content will not
be decrypted.

The first check verifies the correctness of the public key stored within the
downloaded directory. The key must be checked to ensure that it belongs to the signing
key. If it does, it indicates that an authorized user has signed the directory
content. The check is carried out by hashing the directory's public key and
comparing it with a verification capability.

If the directory passes the first check, it will further be checked for content
integrity. The integrity check ensures that the directory content, in form of
entries, has not been tampered with. It is carried out by decrypting a stored
encrypted hash value in the directory and comparing it against the hash value of
the directory's encrypted entries. The encrypted hash value stored in the
directory is decrypted using the previously verified public key. The integrity
check is depicted as a part of Figure \ref{fig:CS:VOD}.

If the directory passes the verification procedure, the user will decrypt the
directory's encrypted entries using the directory specific read key. The decryption procedure
is illustrated as a part of Figure \ref{fig:CS:OD}. An \ac{IV} is additionally
used with the read key to carry out the decryption procedure. The \ac{IV} is easily
fetched from the directory prior to decryption.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{OpenFolder.pdf}
    \caption{Decrypting a remote directory: Decrypting directory content and
    obtaining the signature key.}
    \label{fig:CS:OD}
\end{figure}

\subsubsection{Modify Directory}
In addition to read the content of a directory, the user might want to write to it as well.
To be able to modify a downloaded directory, the user must be in possession of
the directory's write key. The write key is needed to obtain the directory's
signing key and write enabler.

The signing key is needed by the user to correctly sign the
modified directory. Remember that a directory can only be read by users if it
contains a valid signature. Obtaining the signing key from a downloaded
directory is shown as a part of Figure \ref{fig:CS:OD}.

The write enabler is generated as a HMAC-SHA-2 value from the write key and a
static known text value. It is used to prove the user's write permissions to the
receiving ACL layer at the remote server. This ensures that the directory has
been modified by an authorized user.

The user fetches the encrypted signing key and decrypts it with the
write key. This is illustrated in Figure \ref{fig:CS:OD}.


\subsection{File Operations}
This section describes the elementary file operations supported by the
application. The ``create file'' and ``open file'' operations are considered.

\subsubsection{Create File}
\label{sec:CS:CF}
In the create file operation, a file must be created locally on the user's terminal
prior to upload. The operation is depicted in Figure \ref{fig:CS:CF} and
described as follows.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{CryptoCreateFile.pdf}
    \caption{Creating and uploading a file. }
    \label{fig:CS:CF}
\end{figure}

The user chooses a local file to upload. This file is depicted as the
``content'' value in Figure \ref{fig:CS:CF}. A cryptographic write key, specific
for the new file, is further generated. The key generation algorithm is
explained in Section \ref{KEYGEN}. The write key is further hashed to create a
file specific storage index. The storage index is stored in the new file. A
file's storage index has the same property as a directory's storage index. The
\ac{IV} is the next value that is inserted into the new file. It is
generated from a counter stored at the user's terminal.

The previously chosen file content is further encrypted with the write key and
file \ac{IV}. The encrypted file content is then inserted to the new file. The last
value added to the new file is an encrypted hash value of the encrypted content.
The hash value is encrypted using the file's write key. Both the file content
and hash value are encrypted using \ac{AES} in \ac{CBC} mode.

\subsubsection{Open File}
\label{sec:CS:OF}
\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{CryptoOpenFile.pdf}
    \caption{Downloading a file from the server}
    \label{fig:CS:OF}
\end{figure}

The process of retrieving a file is illustrated in figure \ref{fig:CS:OF}.A
file is located by hashing the write key, which in turn is obtained either by
knowledge by the user or client or from a parent folder. The ciphertext, the
\ac{IV} and the encrypted hash of the ciphertext is downloaded from the server.
The ciphertext is hashed client side and the encrypted hash from the server is
decrypted with the write key, if these two outputs match the ciphertext has not
been tampered with. The ciphertext is then decrypted using the write key and
\ac{IV} to obtain the file contents.

\subsection{Keychain}

As stated, each client keeps a local copy of the identity and write key to the
personal root folder in a password protected keychain. This is done to be able
to encrypt the root folder with a key that is not based on a password, but
completely randomly generated. In addition, this means that no special scheme is
needed for the root folder, as we can use the same procedures as for ``normal''
folders as defined in the previous sections.

The strength of a password is related to its length and its randomness
properties. Passwords shorter than 10 characters are usually considered to be
weak \cite{pbkdf_nist}. In the event of loosing one of the clients, and thus the
keychain, a potential attacker can use fast password cracking attacks to try to
compromise the root folder keys. As an precaution for this, we will use
\ac{PBKDF2}/RFC2898\footnote{http://tools.ietf.org/html/rfc2898} with a salt
value to create additional computational work for the process of unlocking the
keychain. This method is known as key stretching \cite{keystretch}.

\subsection{Choice of Cryptographic Primitives}

The scheme which has been described in this section requires three primitives;
a cryptographic hash function, a symmetric cipher and an asymmetric cipher
which can be used for digital signatures. The choices should reflect the
following security demands of our application, all with the assumption that the
possible attacker has access to vast quantities of computing power.

% TODO: Sikkerhetskrav bør vi definere tidligere
\begin{enumerate}
    \item It should be infeasible to break confidentiality for any file or folder
    \item It should be infeasible to break integrity for any file or folder
\end{enumerate}

\subsubsection{Symmetric Cipher}
For a symmetric cipher the choice is pretty simple; \ac{AES}. \ac{AES} is
a standard, has been around for a long time, and does not have any serious
security issues as long as it is used correctly.
% Kilder kilder TODO

%%**************************************%
%\chapter{Implementation}
%%**************************************%
%This chapter describes the implementation of our proof-of-concept client and
%server. The technologies and software \ac{API}s used will be described, in
%addition to implementation details that require special attention.

\section{Server Implementation}

The server, in the most basic form, has to support two operations -- sending
and receiving files. In addition, an \ac{ACL} layer is needed to support user
management and access control to able to allow the deletion of files from the
server.

\subsection{Communication and Architectural Patterns}

By definition, cloud applications are accessible over the Internet. The system
we are creating, should be able to send and receive files and information from
a server in the cloud. The \acf{HTTP} is the foundation of data communication
for the World Wide Web, it is well tested, will pass through most firewalls and
has a multitude of libraries in programming languages. To get a working server
we can also use any existing web server as a foundation, which saves a lot of
work. Thus \ac{HTTP} was chosen as our communication protocol.

\subsubsection{\acs{REST}} The Web is built around an architectural style called
\ac{REST} \cite[ch. 5]{fielding}, which is defined by four interface
constraints: identification of resources, manipulation of resources through
representations, self-descriptive messages, and, hypermedia as the engine of
application state. In addition, \ac{REST} dictates five\footnote{And one
optional, Code on demand, which is not applicable for our system.} architectural
constraints \cite{fielding}. Our server application adheres to these
constraints or \emph{patterns} as follows:

\begin{description}
  \item[Client-server] \hfill \\
    The server is our server application, and the client is the various client
    applications,

  \item[Stateless] \hfill \\
    Since the server is just a simple key-value file store, it does
    not need to keep state.

  \item[Cacheable] \hfill \\
    The server could easily add caching, by putting each encrypted file in
    memory as downloaded, and using the Least-Frequently Used algorithm for
    choosing which items to swap out. In addition, for every update of a folder,
    the corresponding cache item has to be marked as invalid.

  \item[Layered system] \hfill \\
    Layers are used to encapsulate, separate and hide functionality.
    Figure \ref{fig:IM:layers} illustrates the layers of the server application.

  \item[Uniform interface] \hfill \\
    The interface between clients and server(s) are given by the URI scheme in
    Table \ref{tbl:IM:restinterface}. When a folder is uploaded a Write Enabler
    must also be provided together with the storage index..
\end{description}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ImplementationServerLayers.pdf}
    \caption{Architectural Layers in the Server application.}
    \label{fig:IM:layers}
\end{figure}

\begin{table}[h!]
    \centering
    \caption{The \acs{REST} interface of the server application.}
    \begin{tabular}{|l|l|}
        \hline
        \multicolumn{1}{|c}{\textbf{\acs{URI}}} & \multicolumn{1}{|c|}{\textbf{Description}} \\
        \hline
        \texttt{/put/<storage index>} & Creates or updates encrypted file \\
        \hline
        \texttt{/get/<storage index>} & Retrieves encrypted file \\
        \hline
    \end{tabular}
    \label{tbl:IM:restinterface}
\end{table}

In this context, resources are the encrypted files, and the architectural
constraints of \ac{REST} also matches that of our system as a
whole. Thus, the server application are designed in a \acs{REST}ful manner.

\subsubsection{Network Security} Since we are utilizing \ac{HTTP}, we can
easily add an extra layer of \ac{TLS} to form \ac{HTTPS}. This makes it more
difficult for potential attackers to intercept messages, and also provides
protection against the most basic form of \ac{MITM} attacks. It also provides
protection against eavesdropping, which would have revealed the Write Enabler
for folders and could be used by an attacker to delete user files. The top-most
layer of Figure \ref{fig:IM:layers} thus refers to \ac{TLS}.

\subsection{Environment}

The Python programming language in a Linux environment was chosen as development
platform, together with a set of applications, interfaces and micro frameworks.
The rationale for each of these follows.

\paragraph{Python} Python is a high-level general-purpose programming language.
It was chosen due to previous knowledge and experience by the
authors, in addition to its simplicity.

\paragraph{Apache} The Apache HTTP Server is a well tested and used web
server. According to \citet{netcraft}, Apache is by far the most used web server
software, and has been so since 1996. It was chosen on the basis of previous
experience and its superb documentation.

\paragraph{\acs{WSGI}} The Python \ac{WSGI} is, as the name suggests, an
interface between a web server and a Python application. It is defined in
\ac{PEP} 3333\footnote{\url{http://www.python.org/dev/peps/pep-3333/}}, and
specifies both sides of the interface -- the \emph{application} and the
\emph{server}. The server side is implemented in the form of an Apache
module, namely \texttt{mod\_wsgi}, and the application is where we put our
code.

For each of the requests the server (i.e. \texttt{mod\_wsgi}) receives, a call
to the application function is made with two arguments -- a data structure
containing the environment variables, and a callback function for which the
application uses to return data to the requesting user via the server.

\paragraph{Pyroutes} To adhere to the \ac{DRY} principles, we chose to make use
of a micro framework around \ac{WSGI} called
Pyroutes\footnote{\url{http://www.pyroutes.com/}}. It provides shortcuts for the
most frequently used functionality when developing web services, as that of
\ac{URL} handling and processing of submitted user data in the form of
\texttt{GET} and \texttt{POST} requests.

Pyroutes did not, however, support the HTTP \texttt{PUT} request, so this was
implemented and contributed back to the project.

\subsection{Implementation Details}

The code was structured as illustrated in Figure \ref{fig:IM:layout}. The file
\texttt{handler.py} provides the interface for \texttt{mod\_wsgi} and the server
application, and basically includes the \ac{URL} scheme in
\texttt{fileserver.py}. An example \ac{URL} mapping is shown in Listing
\ref{lst:IM:get}. The function \texttt{get\_file} is registered to have the
\ac{URL} \texttt{/get} through the decorator provided by Pyroutes. After
retrieving the file from disk, a proper \ac{HTTP} response is returned,
containing required headers.

The file \texttt{filesystem.py} contains the low-level file system operations,
\texttt{save\_file()} and \texttt{retrieve\_file()}, together with a set of
helper functions to manage file access checking and database operations.  The
folder \texttt{sql/} contains \ac{SQL} code to create necessary tables in the
database, and \texttt{db.py} provides an helper function to connect to the
database.

\begin{figure}[h!]
\begin{verbatim}
|-- cloudstorage
|   |-- __init__.py
|   |-- db.py
|   |-- fileserver.py
|   |-- filesystem.py
|   |-- settings.py
|   `-- sql
|       `-- write_enablers.sql
|-- handler.py
`-- tests
    `-- filesystem_tests.py
\end{verbatim}
    \caption{Server module structure}
    \label{fig:IM:layout}
\end{figure}

\lstinputlisting[language=Python,breaklines=false,label=lst:IM:get, caption=URL mapping in fileserver.py]
{listings/fileserver.py}

\subsubsection{\acs{ACL} functionality}

The only \ac{ACL} functionality implemented, is the server-side verification
that a client has proper access to overwrite a file, e.g. when a client wishes to
update a folder with new contents. We call this \textbf{Write-Enabler Verification}.

When a client first uploads a new folder, it also provides a
\emph{Write-Enabler Key}, which the server adds to the database along with the
\emph{Storage Index} of the folder.  For every subsequent request to write to a
file with this specific Storage Index, the server verifies that the provided
Write-Enabler Key is equal to that in the database.

If a client tries to put a file with a Storage Index that already exists, the
server replies with an error code if the client in addition does not provide a
valid Write-Enabler Key.

\section{Client Implementation - Android}
% Java/Android/Dalvik/JCE/Commons HTTPClient
% Security vs. Usability - Rationale for GUI
% MVC? V=Android GUI
%
The \ac{PoC} client we have implemented, is made for devices using the Android
operating system, which is based on Linux. The \ac{SDK} for making Android
applications, is essentially a somewhat modified version of Java.

Most devices that use the Android operating system are mobile phones or
tablets, which implies that they are limited in terms of speed and
memory. The point of making the \ac{PoC} client for such a device, i.e. a
\emph{smart phone}, is the growing availability, and the flexibility these
devices provide. A user carries the device everywhere, it has a network
connections, and it is always on.

A nice side effect of developing on a smart phone platform, is that if the
software performs well on a constrained device, it will almost certainly also
have good performance on any faster device as well.

\subsection{Environment}
The \ac{PoC} client was made on the Android platform in the Java programming
language, together with a set of frameworks. The rationale for these are as
follows.

\paragraph{Android} The Android operating system is made by Google, and is most
commonly found on mobile phones and tablets. The platform choice of Android was done
based on hardware availability and familiarity with developing on the
platform and the programming language (Java).

\paragraph{Java} Java is a high-level, object-oriented programming language.
Applications written in Java runs in a \ac{JVM}, which implies that a Java
application can run on almost any device which has a \ac{JVM}. The \ac{JVM} on
Android is called Dalvik.

\paragraph{HttpComponents} Apache HttpComponents are a set of libraries for
\ac{HTTP} transport in Java. The part used in our client is called HttpClient.
Android incorporates parts of this client in its native \ac{JVM}. The use of
this library adheres to the \ac{DRY} principles.

\paragraph{\ac{JCA}} \ac{JCA} is an architecture for doing cryptographic
operations in Java. The architecture is based on principles of implementation
independence, implementation interoperability and algorithm extensibility.
Basically what this means, is that each implementation of the \ac{JVM} can have
different implementations of the cryptographic primitives, but the developer
does not need to know which implementation is available.

\paragraph{ZXing Barcode Scanner} ZXing Barcode Scanner is a popular Android
application which can be used by other Android applications to both scan and
generate barcodes. By the use of this application, we adhere to the \ac{DRY}
principles, by not creating our own code to generate barcodes.

\subsection{Architectural Patterns}

\paragraph{Client-Server} It should be obvious that the client we have
implemented is the client part of the overall client-server pattern.

\paragraph{Pipe-and-Filter} The basis of the pipe-and-filter pattern is that
there exist a chain of processing elements, where the output of one element is
the input of the next element. We use this for file uploads and downloads to
limit the memory usage of the client, as well as to increase performance.

\paragraph{Asynchronous Pattern} We use asynchronous calls to slow operations
-- e.g. file upload and key generation -- extensively, to prevent the interface
from hanging and to deliver a smoother user experience in general.

\subsection{Implementation Details}

\subsubsection{Structure}
% Package Structure, some nice UML (?)
% Which qualities do we wish to achive? Security, Performance, Usability

The source of our client is logically separated into two entities --
\textbf{CSVlib} and \textbf{CSVAndroid}. CSVlib is a pure Java library which
contain the necessary entities, cryptographic operations and communication
calls required for the client. CSVAndroid contains primarily a graphical user
interface to make use of CSVlib on an Android device.

\subsubsection{Cryptographic Entities}
All the cryptographic entities -- namely folders, files and capabilities -- are all
part of CSVlib. Their relationship can be seen in Figure \ref{fig:CSVlib:overview}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{csvobjects.pdf}
    \caption{Cryptographic entities and their relations}
    \label{fig:CSVlib:overview}
\end{figure}

\paragraph{Capabilities} Capabilities are containers for
cryptographic keys and information to identify a corresponding object. A
capability will contain information to identify an object as either a file or a
folder, and have the information to read, write or verify that object.

Capabilities are stored server side in folders, in it's serialized form shown
in Figure \ref{fig:CAP:serial}. \emph{Object Type} specifies if the capability
represents a file or a folder, with values \emph{F} or \emph{D}
respectively.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{CapabilitySerialization.pdf}
    \caption{Serialized form of a Capability}
    \label{fig:CAP:serial}
\end{figure}

\emph{Key Type} specifies the permissions the key will grant on the object and
can be either \emph{RO} (Read Only), \emph{RW} (Read and write) or \emph{V}
(Verify).

The different parts are separated by the character \textbf{:}. The key and
verify string are encoded in Base32, which means that the 128 bits these
strings are represented by, will be replaced by an alphabet of 32 different
symbols, namely A-Z and 2-7. This transformation will give some overhead in
storage and transfer (26 bytes compared to 16), but makes it possible to read for a human
with few mistakes or misunderstandings.

\paragraph{Folders}

A folder is represented by the class \textbf{CSVFolder}. A CSVFolder object is
a collection of aliases and their corresponding capabilities. For
the most part, the data stored in a folder is so small that it can easily live for
as long as needed in the memory of the client.

When a folder is created or updated, the content is serialized and encrypted,
before it is uploaded to the server directly from memory. The serialization for
each item in a folder is simply \textbf{alias;capability}, where the capability
itself is also serialized.

\paragraph{Files}

A file is represented by the class \textbf{CSVFile}. While a folder in general is small,
a file can be of any size, even larger than the space the \ac{RAM} on the
device itself represents.

To keep the memory footprint low, we use the pipe-and-filter architectural
pattern to stream data all the way from the cloud to the disk, or vice versa,
through encryption and verification.

An example of how we do this for uploads is shown in Listing
\ref{lst:inputstream}.

\lstinputlisting[label=lst:inputstream, caption=Pipe and filter upload of a file]
{listings/fileupload_example.java}

The \emph{InputStreams} are chained together, with the effect that a read from
\emph{readBuffer} will trigger a read trough the whole pipe. The
\emph{DigestInputStream} will update the state of the hash function, but is
transparent in the sense that whatever goes into the stream will also be what
comes out. The \emph{CipherInputStream} on the other hand, will output an encrypted
stream of the data from the file. Buffers are placed between each step of the
stream for some performance increase.

\subsubsection{Communication with Server}
% Do not repeat what is said in Server equivalent section
% Apache commons, Serialization of objects

For \ac{HTTP} transport we utilize the Apache Software Foundations
HttpComponents Client\footnote{ \url http://hc.apache.org/} also known as
HttpClient.

This Client offers support for authenticated requests to a server, and both
upload and download through \textbf{PUT} and \textbf{GET} requests respectively.
We wrap communication with the server in two classes,
\texttt{Communication.java} and \texttt{CSVFileManager.java}.
\texttt{Communication.java} provides functionality for sending and retrieving
data from our server, while \texttt{CSVFileManager.java} provides specific
methods for sending and receiving the encrypted objects, CSVFile and CSVFolder.

\subsection{Sharing}
% Sequence Diagram - How we use the cryptographic solutions (and which ones) to
% achieve sharing, securely

A \emph{shared folder} is basically just a folder object which two or more
people have the required encryption keys for.

The problem of creating a share with someone, is that you have to verify that
you are actually sharing with the correct person. The data, or \emph{secret},
that will have to be shared, is a serialized form of the capability of the
shared folder, as shown in Figure \ref{fig:CAP:serial}.

The client supports two methods of doing this. The most cumbersome
is having to manually copying the key from one users client to another, and
afterwards verifying that the key for the selected folder is correct. An example
of this can be seen in Figure \ref{fig:CSVAndroid:manualimport}. This feature
is also needed to support out-of-band methods for establishing a share.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-manualimport.png}
    \caption{Establishing a share by copying the key}
    \label{fig:CSVAndroid:manualimport}
\end{figure}

The other possibility is to make use of a \ac{QR} code, which is a matrix
barcode that can store information. What this means is that one user will
generate a barcode on his device, and the other user can scan that code using
the camera on his device. Figure \ref{fig:CSVAndroid:barcode} illustrates how
this code will look. The barcode contains both the key and the verification for
the shared folder. Once two users have shared a folder once, that folder can be
used for all future shares, which means that the two people will never have to
meet and do the capability exchange again. The identity has thus been verified.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-barcode.png}
    \caption{Establishing a share by using barcodes}
    \label{fig:csvandroid:barcode}
\end{figure}

\subsection{Adding a New Client}

Using more clients, or different devices, is almost the exact same as sharing,
and is solved in the same manner. The only difference is that the capability
that needs to be transfered, is that of the \emph{root folder}. It is also
possible to take any other folder and use as a new root for the new client if
that is the users wish.

\subsection{Securing the Client}

For a user to access his root folder, the client will have to know the
capability of that folder. This is clearly to much for a user to remember, so
the capability will have to be stored on the client. However, the client might
be stolen or broken into by some means, and if the capability is stored in clear
text, it is easily stolen.

We partially remedy this by the use of the \ac{PBKDF2} algorithm, which makes an
encryption key from a password. This generated key is used to encrypt the root
capability in a file stored on the client. We call this the encrypted key ring.

These precautions are however no defense if the attacker managed to read the
memory while the key is unlocked. The client enforces that this password should
be at least 9 characters long.

\subsection{User Interface}
% goal: As easy as possible!
% First start: Generate new cap/import an old one (Adding a new client section)
% Browsing remote file(s)/folders
% Sharing a file - first/following times - Key Distribution
% Uploading/Downloading file

We have tried to make a user interface that is easily understandable by a novice
user, both in terms of \emph{where to click} and in terms of how we name
cryptographic operations. For instance we never use the word \emph{capability}
in the client.

\paragraph{Main Screen}

The main screen of the application is shown in Figure
\ref{fig:CSVAndroid:mainscreen}. However, before the user gets to this screen,
he will have to unlock his local keyring with his password. If it is the first
time the user starts the application, he will have to enter his online
credentials, and gets a choice to either import an existing root folder, or to
generate a new one. In both cases the user will have to choose a password to
encrypt the root capability in to the local keyring.. From the main screen the
most common action would be to \emph{Browse the vault} -- in other words to see
the files that the user has stored in the cloud.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-mainscreen.png}
    \caption{Main screen of client}
    \label{fig:CSVAndroid:mainscreen}
\end{figure}

\paragraph{Browse the Cloud}

The interface for browsing the files stored in the cloud is made in what we
understand as a common and understandable way of interpreting users actions on
the android platform, and can be seen in Figure
\ref{fig:CSVAndroid:remotebrowse}. Tapping a file will download that file, and
tapping a folder will open that folder.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-remotebrowse.png}
    \caption{Browsing the cloud storage from client}
    \label{fig:CSVAndroid:remotebrowse}
\end{figure}

An upload is treated in a similar way. To reveal this option, the user have to
press the \textbf{Menu}-button. The user will then be allowed to browse his
local filesystem for the file he wishes to upload, and tapping that file will
start the upload.

A long press on a file, or a folder item, will reveal the context menu shown in
Figure \ref{fig:CSVAndroid:remotecontext}. The least understandable action is
probably \emph{Unlink}, which remove a file or a folder from the parent folder.
The reason why it says unlink and not delete, is that a file can potentially be
linked in a number of different folders, and it is impossible by our design to
reveal which folders the file has been linked to, except the one that we are
unlinking from.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-browsecontext.png}
    \caption{Context menu}
    \label{fig:CSVAndroid:remotecontext}
\end{figure}

%**************************************%
\chapter{Experimental Procedure}
%**************************************%
This chapter will explain the experimental procedures performed towards the Cloud
Storage Vault. It will start by explaining the
procedures taken to measure the application's performance. The Performance is
further checked against efficiency of similar existing applications.
The chapter will complete by further explaining the experimental procedures
taken to measure some aspects of the application's security.

\section{Performance}
We have tested the application on two Android phones, a HTC Desire and a HTC
Hero. We have also tested the Java libraries on desktop computer. The
specifications for HTC Desire can be seen in Table \ref{tbl:device:desire},
for HTC Hero in Table \ref{tbl:device:hero} and the computer in Table
\ref{tbl:device:computer}.

\input{tables/exp_desire.tex}
\input{tables/exp_hero.tex}
\input{tables/exp_computer.tex}

\subsection{Eliminating Bottlenecks on Android Devices}
On the Android devices we identify three possible bottlenecks that we might be
able to control: The Network, our application and the memory card. The mobile
phones will normally obtain their network connection through a wireless
protocol, normally 3G, EDGE or WLAN. While these protocols works just fine,
form a performance standpoint we want to have a fast and stable connection. Our
solution was therefore to connect the Android devices to the test computer, and
use the computers network.

The other bottleneck might be the memory card. The class of a memory will
identify the lowest speed that the card might give on reads. The class number X
represents this guarantee in y MB, so a class 2 card guarantees 2 MB/s. There
are however the possibility of the card performing significantly better than
what the class indicates.

\subsection{What is Measured}
% Upload and Download of files (speed/bandwidth). Wget speed, folder creation
% etc
% TODO
For \textbf{files} we measure the bandwidth the client uses when uploading and
downloading a file. We do this by measuring the network traffic on the
server, and record this. For comparison we also deactivated hashing and
encryption in the pipeline and recorded the network traffic.

Folders are relatively small in size, so the network should not be a
bottleneck. However the different cryptographic operations might take some
time, as will the serialization of folders. For folders we measured:

\begin{enumerate}
    \item The average time it takes to create a folder
    \item The time it takes to encrypt and sign a folder, with varying amount
    of data
    \item The time it takes to verify a newly downloaded folder, with varying
    amount of data
    \item The time it takes to serialize a folder, with varying amount of data
\end{enumerate}

\subsection{Error Sources}
The trouble with measuring performance on operations that are relatively quick
is that they are very vulnerable to noise from the system. The Android system
comes with a lot of built in services that runs sporadically, which means that
they will affect the measurements. However, the small and quick operations are
not necessarily what is interesting, the interesting thing to see is how their
performance is affected when the amount of data is increased. The goal of the
client is to deliver a quick and smooth experience for the user.

Other error sources is that we cannot explicitly tell what the speed of either
the network is or the memory card. But comparing the speed for file operations
in CSV with the modified version with encryption and hashing disabled should
give us an inclination about how quick the software can be.
\section{Security}

\subsection{Brute Force Local Keyring} \label{sec:BFLK} The locally stored and
encrypted keyring can be considered a security risk if it somehow end up in
malicious hands, either by a device being lost or a person hacking in to a
device. Even though the keyring is encrypted it might be weak to a brute force
or dictionary attack. If an attacker is able to decrypt the keyring he will
obtain the information to access a users root folder. This is potentially
enough for the attacker to access every file stored by the user. This section
describes our approach to attack the keyring.

\subsubsection{Keyring Format} The format of the encrypted keyring is given in
Figure \ref{fig:KeyringFormat}.  It is encrypted with 128-bit \ac{AES} in
\ac{ECB} mode, but the key is not randomly generated.  The key is made by the
key strengthening function \ac{PBKDF2} but is based on a password set by the
user, which is why this key is potentially weaker than the keys for files and
folders. An attacker will also know some of the plaintext for the keyring. The
serialization of Capability for a writeable folder will make a plaintext that
starts with ``D:RW:`` followed by 16-byte of Base32-encoded data, another ``:``
and then 16 more bytes of Base32-encoded data.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{KeyringFormat.pdf}
    \caption{The Keyring format. Encrypted fields are shaded in blue.}
    \label{fig:KeyringFormat}
\end{figure}

\subsubsection{General Procedure} To perform a brute force or dictionary attack
on the encrypted keyring, one must decrypt the keyring for each password
guessed. The decryption involves both key derivation with \ac{PBKDF2} and
decryption with 128-bit \ac{AES} in \ac{ECB} mode. We verified a successful
attack by our knowledge of the serialization of the Capability. \ac{PBKDF2} is
also a function that can be used with a varying number of iterations, our
attacks are tested on 500, 1000, 2000 and 4000 iterations.

\subsubsection{Implemented Attacks} We created two programs designed to crack
the keyring password. The first program, named BruteForce, was designed for a
single computer while the second program, named \ac{CDA}, was designed to
perform attacks by a cluster of cooperating computers. Both use dictionary
attacks, but BruteForce is also capable of a pure brute force attack. The
source code and .jar files for both programs can be found in the attached
CD-ROM. Implementation details are given in Appendix \ref{ap:RI}.

\subsubsection{Configuration} BruteForce requires Java with \ac{JCE} and
Jurisdiction Policy files\footnote{The policy files enables Java to use
stronger encryption than what is allowed by US export law} installed.  It also
requires Java to be configure to use \ac{BC} as its primary \ac{JCE} provider.
The policy files and \ac{BC} provider are required because the keyring is
encrypted using BC version 1.34\footnote{BC version 1.34 is used by default in
Android 2.2.}.\\
%TODO: Confirm that BC v.1.34 is default!!!1

\noindent \ac{CDA} requires almost the same configuration as the BruteForce
attack, but for each node in the cluster. Another requirement for
\ac{CDA} is that the cluster must be configured with Apache Hadoop.\\

\noindent The steps we performed to set up Java with \ac{BC} and the
Jurisdifction Policiy files can be seen in \cite{jce+bc}. The guide we used for
using Apache Hadoop in a Cluster using Ubuntu Server can be found at
\cite{cluster}.

\subsubsection{Hardware Specifications} The hardware specification for the
attacks with the tool BruteForce we ran is given in Table \ref{tab:hwbf}. The
\ac{CDA} attack was executed over a cluster of Amazon \ac{EC2} instances. All
instances used were categorized by Amazon as ``high-CPU extra large
instances``. The hardware specification for a single instance, used in the
\ac{CDA} attack, is given in Table \ref{tab:hwcda}. We used 20 of these
instances.

\begin{table}[!h]
    \centering
    \caption{Hardware specifications for computer executing BruteForce}
    \label{tab:hwbf}
    \begin{tabular}{| l | l |}
	\hline
	Product		        &HP Compaq 8100 Elite SFF PC \\
	\hline
	CPU		            &Intel(R) Core(TM) i7 CPU 860 @ 2.80GHz\\
	\hline
	CPU Architecture    &x86\_64\\
	\hline
	RAM		            &4GiB\\
	\hline
	OS		            &Ubuntu 10.10 (Maverick Meerkat)\\
	\hline
	Kernel Version	    &2.6.35-28-generic\\
	\hline
    \end{tabular}
\end{table}

\begin{table}[!h]
    \centering
    \caption{Hardware specifications for cluster instances executing the
    \ac{CDA}}
    \label{tab:hwcda}
    \begin{tabular}{| l | l |}
	\hline
	Instance Type       &High-CPU Extra Large Instance\\
	\hline
	CPU		            &Intel(R) Xeon(R) CPU E5410 @ 2.33GHz\\
	\hline
	CPU Architecture    &x86\_64\\
	\hline
	RAM		            &7GiB\\
	\hline
	OS		            &Ubuntu 10.10 (Maverick Meerkat)\\
	\hline
	Kernel Version	    &2.6.35-24-virtual\\
	\hline
	I/O Performance	    &High (as defined by Amazon)\\
	\hline
    \end{tabular}
\end{table}

\subsubsection{Running BruteForce}
The command used for executing a brute force attack with the tool BruteForce
can be seen in Listing \ref{lst:bf}. The command for running a dictionary
attack is seen in Listing \ref{lst:da}.

\lstset{label=lst:bf, caption=Running local brute force attack}
\begin{lstlisting}
$ java -jar BruteForce.jar /path/to/keyring  \
    maximum_password_length number_of_threads
\end{lstlisting}

\lstset{label=lst:da, caption=Running local dictionary attack}
\begin{lstlisting}
$ java -jar BruteForce.jar /path/to/keyring \
    /path/to/dictionary number_of_threads
\end{lstlisting}

\subsubsection{Cloud Dictionary Attack with \ac{CDA}} The attack using \ac{CDA}
was carried out over 20 Amazon EC2 ``high-CPU extra large instances``. One
instance was configured as both a Hadoop master and slave node, while the 19
other instances were configured only as slaves. The commands executed to start
the Hadoop master, slaves and their corresponding \ac{HDFS} are shown in
Listing \ref{lst:hadoop}. The last command enables the existing Hadoop cluster
to support MapReduce. This is necessary as the \ac{CDA} attack is implemented
as a map-reduce problem. Details about MapReduce and the implementation of
\ac{CDA} are given in Appendix \ref{ap:RI}.\\

\lstset{language=bash, label=lst:hadoop, caption=Starting Hadoop cluster with HDFS}
\begin{lstlisting}
# Start HDFS and initialize master and slave nodes
$ /path/to/Hadoop/bin/start-dfs.sh

# Start a MapReduce cluster from the master node
$ /path/to/Hadoop/bin/start-mapred.sh
\end{lstlisting}

\noindent The last requirement, before executing the attack, is to copy the
desired dictionary file and keyring into the \ac{HDFS}. Copying files from the
master node to the \ac{HDFS} is done with the command shown in Listing
\ref{lst:cpHDFS}. The attack can then be started on the master node with the
command shown in Listing \ref{lst:CDA}.

\lstset{language=bash, label=lst:cpHDFS, caption=Copying files into HDFS}
\begin{lstlisting}
$ /path/to/Hadoop/bin/hadoop dfs -put /path/to/file \
    /path/to/file/in/HDFS
\end{lstlisting}

\lstset{language=bash, label=lst:CDA, caption=Executing the CDA attack}
\begin{lstlisting}
$ /path/to/Hadoop/bin/hadoop jar /path/to/CDA.jar \
    /HDFSpath/to/dictionary /HDFSpath/to/output/file \
    /HDFSpath/to/keyring number_of_slaves \
    number_of_threads_per_slave
\end{lstlisting}
%**************************************%
\chapter{Results}
%**************************************%
\section{Client Performance}
This section displays the results of the client benchmarking and highlights the
most important results.

\subsection{Files} The following results shows the network speed obtained when
uploading and downloading files. Table \ref{tbl:files:encrypted} shows the
speed when using the unmodified client, while Table \ref{tbl:files:unencrypted}
shows the speed obtained when using the same client but with encryption and
hashing disabled.

% Kanskje en tabell her, som viser søyler med ukryptert bak og kryptert forann?
\input{tables/performance_files.tex}
\input{tables/performance_files_unencrypted.tex}

We observe that the Android devices performance for uploads is severely lower
for uploads than downloads, and that this is not the case for the computer. We
also observe that the speed with encryption and hashing enabled is severely
higher for all three devices.

\subsection{Folders} Table \ref{tbl:folder:createblank} shows the average time
it takes to create an empty folder on the different devices. The Tables
\ref{tbl:folder:serializefolder} and \ref{tbl:folder:encryptsign} shows the
time it takes to serialize and encrypt and sign the folder respectively. These
two actions are what has to be performed every time a folder is changed, while
the creation of a blank folder is added if the content should be added to a new
folder. Table \ref{tbl:folder:verify} displays the time the devices used to
verify an existing folder, a step which is taken by the client every time a
folder is opened.

\input{tables/result_perf_createblankfolder}
\input{tables/result_perf_serializefolder}
\input{tables/result_perf_encryptsignfolder}
\input{tables/result_perf_verifyfolder}

We observe that that the slow part of folders operations are the initial key
generation and more important the serialization speed. Verification, encryption
and signing is pretty fast for all devices.

\section{Brute Force Local Keyring}
\label{sec:R:BFLK}
In Section \ref{sec:BFLK}, we tried to brute force the locally stored keyring,
by implementing and executing two different programs. The first program, named
BruteForce, was designed to run on a single computer, and supports both brute force and
dictionary attacks. The second program, named Cluster Dictionary Attack (CDA), was created to run in a
computational cluster. However, the CDA attack does only support dictionary attacks. The results for
both programs are given below.

\subsection{BruteForce}
With BruteForce we executed both a brute force and a dictionary attack to estimate the
amount of passwords we could brute force within a second. The brute force
and dictionary attacks achieved approximately the same results. However, for
each measurement, the brute force attack turned out to achieve about 50
passwords more per seconds than the dictionary attack. This is believed to
exist due to the file reading overhead in the dictionary attack. The results for both
attacks are illustrated in Figure \ref{fig:bfres}.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.55]{bf.png}
\caption{Results from running brute force and dictionary attacks against a local
keyring. The histogram shows how many passwords per second we were able to brute
force against different amounts of iterations used in PBKDF2.}
\label{fig:bfres}
\end{figure}
\subsection{Cluster Dictionary Attack (CDA)}
In the CDA attack, each node of the cluster achieved approximately the same results as a single computer
running a dictionary attack with BruteForce. We found a small difference where
the local computer achieved about 100 passwords per second more than each
instance in the cluster. With respect to difference in CPU power between the
local computer and a single cluster instance \cite{cpubench}, this is an expected
result. With 20 nodes in the cluster we were able to brute force around 35 000
passwords per second, given PBKDF2 with 1000 iterations.

%**************************************%
\chapter{Discussion}
%**************************************%
\section{Complexity}
% Hvordan vi lagrer filer
% Lagring av nøkler
% Hvordan direktorier fungerer
% Hvordan vi deler

%Vår løsning VS relatert research og existing solutions

\subsection{Keys}
%Type of keys, what distribution scheme was chosen
\subsection{Files}

\subsection{Folders}

\subsection{Sharing}

\section{Performance}
% 1 mappe med 100 filer i, tar ikke mye lenger tid å åpne enn en mappe med 3
% filer i

\subsection{Compared with Other Solutions}

\section{Security}
% Hvordan angripe?
% ACL lag bare ekstra sikkerhet, man kan ikke cracke noe uten keyen!
This thesis is written with the basis that we are hiring storage from an
untrusted provider, and the security of the application should primarily
reflect that. With this starting point we can assume that all data stored on
the server is obtainable by the provider.

\subsection{Key Distribution}
\label{sec:DI:keydist}
%Describe possible key distributions schemes
%Argue why we chose our scheme

\subsection{Passive Attacks}
% Avhengig av cryptographic primitives
% Confidentiality den største utfordringen
% Her trengs det gode kilder
The provider will have access to all data on the server, and also know what
data stored is part of files and what is part of folders. The confidentiality
of both files and folders relies primarily on the symmetric cipher used to
encrypt the data. But for folders one can obtain this key if one manages to
obtain the asymmetric private key belonging to the folder. In other words a
folder is attackable both trough the asymmetric and the symmetric cipher used.
If the confidentiality of a folder is breached it will additionally enable the
attacker to decrypt all of the corresponding sub-folders and files. In contrast,
cracking the confidentiality of a file will only compromise that specific file. It is
also important to note that users will use a root folder which any other file
or folder relies on, if the confidentiality of this folder is breached, all
files are effectively compromised.

\subsubsection{Brute Force Local Keyring}
The confidentiality of the root folder can be breached by brute forcing a user's
locally stored keyring. This was experienced in Section \ref{sec:BFLK}. From the
results in Section \ref{sec:R:BFLK} and Figure \ref{fig:bfres}, we noticed
that the choice of iterations in PBKDF2 were conclusive to the efficiency of a
brute force attack against the local keyring. By doubling the number of
iterations in PBKDF2, the efficiency of a brute force attack would decrease by
half of it's value. The PBKDF2 standard, written by RSA Laboratories in 1999 \cite{PBKDF2std},
recommends the minimum number of iterations to be 1000. With 1000 iterations in
PBKDF2 we were able to achieve a brute force efficiency around 1800 passwords
per second for a single computer, and 35 000 passwords per second running the
CDA attack on 20 Amazon EC2 high-CPU extra large instances. Given a password
with length 5 and containing only small letters, the CDA attack will use 5
minutes and 39 seconds to check all possible values. By using a cluster of 200
nodes the CDA attack is able to crack a similar password of length 6 within 14 minutes
and 42 seconds in worst case.\\

\noindent It is important to notice that both the CDA and BruteForce
attack were written in Java. With this in mind, it is reasonable to believe
that general performance can be improved by using lower-layer
programming languages, such as C, to implement the attacks. Another way to
increase performance is to design both attacks to run on \ac{GPU}s rather than CPUs.\\

\noindent Regarding CDA, the use of cloud computing to execute a brute force
attack is not a new idea \cite{bfpgp, rothsha, rothwpa}. Newly on Black Hat DC 2011, a
security researcher named Thomas Roth, showed that it was possible to brute
force WPA passwords with a speed of 47 000 passwords per second on a single EC2
cluster GPU instance \cite{rothwpa}. Amazon allows a user to execute up to 8
cluster GPU instances, without the need of a special request. This indicate that
anyone can crack WPA passwords at almost 400 000 passwords per second, and that
Amazon can achieve even higher and unknown speed for WPA password cracking. With
this in mind, we should consider that our own keyring can be subject to a lot
more efficient brute force attacks compared to our own findings.\\

\noindent To reduce vulnerability from plain brute force attacks, we decided to
use 4000 iterations in PBKDF2. In addition, we designed the Cloud Storage Vault
to force users to utilize more advanced and sophisticated passwords. Password
requirements for the Cloud Storage Vault are given below:

\begin{itemize}
\item Password length >= 9.
\item Password must include at least one capital letter, one small letter and
one number.
\end{itemize}

\noindent With the password requirements above and with 4000 iterations in PBKDF2, it will
be extremely hard to perform a plain brute force attack against the local
keyring. Figure \ref{fig:bfres} indicates that when using PBKDF2 with 4000
iterations, the local test computer running BruteForce is only able to check
around 400 passwords per second. Given a cluster of 200 such computers, it will
take 2683 years on average to brute force a password following the syntax above
with a length of 9.\\

\noindent Even though the keyring is secured against a plain brute force attack, it is
still, to a certain degree,  vulnerable to a dictionary attack.

\subsubsection{RSA attacks}

\subsubsection{AES attacks}

\subsection{Active attacks}
% MITM - Dersom vi f.eks. skrur av SSL-laget
% Innside attacker - hos Amazon


\subsection{Terminal security}
% What happens if someone steals a terminal
% OR install some backdoor/torjan etc?
Given enough users, at some point there will be a users who looses his
terminal, for instance a mobile phone, a terminal might also be broken into
without the users knowledge.


\section{Omitted Features}
% Ting vi ikke har lagt inn
% - Cascading deletes? Loops.
% - Hvem 'eier' en directory
% - Garbage collection? (vanskelig)


%**************************************%
\chapter{Conclusion and Future Work}
%**************************************%

% BibTeX bibliography lives in external file
\bibliographystyle{unsrtnat}
\bibliography{references}
% TODO: Can we fix references in order of apperance?

%**************************************%
\appendix
\appendixpage
\addappheadtotoc
%**************************************%
%**************************************%
\chapter{Other Relevant Implementations}
%**************************************%
\label{ap:RI}

This chapter will study implementation details from applications that were
created, but not a part of the thesis' main topic. Applications considered are
BruteForce and the Cluster Dictionary Attack (CDA).

\section{BruteForce}

\emph{BruteForce} includes a plain brute force attack and a dictionary attack against
a users encrypted keyring. Details about the implementation follows.

\subsection{Implementation Details}

BruteForce is written in Java and utilize the \texttt{javax.crypto} library with Bouncy
Castle version 1.34 as JCE provider to decrypt the encrypted keyring. The
Bouncy Castle JCE provider seems to be necessary as Android 2.2 uses it by
default to encrypt the keyring. To enable PBKDF2 before decryption, BruteForce
utilize a PBKDF2 Java library \cite{pbkdf2}.

The program is divided into two functions, named \texttt{bruteForceAttack} and
\texttt{dictionaryAttack} that correspondingly executes a brute force and
dictionary attack. The \texttt{bruteForceAttack} function is shown in Listing
\ref{lst:bffunc}.

\lstinputlisting[language=java, label=lst:bffunc, caption=bruteForceAttack
function]{listings/bruteForceAttack.java}

\texttt{bruteForceAttack} starts a number of \texttt{BruteForceThread} threads.
The function continues after all \texttt{BruteForceThreads} are initialized and
ready to start their task. It then enters a while-loop, which executes a
\texttt{pushWord} function for each iteration.

The task of \texttt{pushWord} is to simply create and push all possible words
of a given length onto a stack of words. The length of the words to push are
given by its integer argument. The whole attack is based on letting the main
thread create and push words onto a stack, while the \texttt{BruteForceThreads} are
pulling words from the stack. When a word is pulled from the stack, it is
subject to PBKDF2, where the result is used to decrypt the ciphertext. If
decryption results in a given plaintext, the password is found.

The \texttt{dictionaryAttack} function is shown in Listing \ref{lst:dafunc}.

\lstinputlisting[language=java, label=lst:dafunc, caption=dictionaryAttack
function]{listings/dictionaryAttack.java}

\texttt{dictionaryAttack} reads an input dictionary file into a
\texttt{BufferedReader}. It then starts a given number of
\texttt{DictionaryThreads}. The \texttt{DictionaryThreads} will read from the
\texttt{BufferedReader} in a synchronized way. When a word is read from a
\texttt{DictionaryThread} it will be subject to PBKDF2, where the result is
used to decrypt the ciphertext. If decryption results in a given plaintext, the
password is found.

\section{Cluster Dictionary Attack}

The \ac{CDA} is written in Java, and is built around the same procedure as the
dictionary attack in BruteForce. However, the difference lays in the cooperation
of multiple computers. To enable a cluster of computers to cooperate, we used
the following environment.

\subsection{Environment}

The environment is based upon a software framework from Apache called
\emph{Hadoop}. The main functionality of Hadoop is described below.

\subsubsection{Apache Hadoop}

Apache Hadoop makes it possible for multiple machines to cooperate
and run computational work together. Hadoop also provides a distributed filesystem
\ac{HDFS}, that can store data across multiple cooperating machines \cite{hadoop}. The
computational work in Hadoop is organized and distributed using \emph{MapReduce}.

\paragraph{MapReduce} MapReduce is a programming paradigm introduced by Google.
It is designed to process and generate large sets of data using a cluster of
machines \cite{mapred}. 

In MapReduce, a large set of input data is divided into multiple key/value
pairs. The key/value pairs are further distributed to multiple MapReduce tasks
running on multiple machines. 

A MapReduce task is divided into a \emph{mapper} and a \emph{reducer}. The task
of a mapper is to perform an operation on a key/value pair and return a
key/value pair as a result to the reducer. The reducer collects key/value pairs
from multiple mappers and combine the results into one or more output files.

\subsection{Implementation Details} 

The \ac{CDA} attack is implemented as a MapReduce problem, with a large
dictionary file as the data input set. The dictionary is split into separate
key/value pairs, where each value is a single line in the dictionary and the
key corresponds to the line's offset within the dictionary.

The key/value pairs are handled by a map function implemented in
\texttt{CDAMapper}. The
map function has the responsibility of checking every word on a single
dictionary line. Each line in the dictionary should contain a certain amount of
words. This is to enable the map function to run multiple threads at the same
time, where each thread checks one or more words. With multiple threads, the
attack is able to utilize more \ac{CPU} power for each running machine in the
cluster. A detailed view of the map function, is given in Listing
\ref{lst:mapfunc}.

\lstinputlisting[language=java, label=lst:mapfunc, caption=Mapper function in
CDAMapper]{listings/mapper.java}

When receiving a key/value pair, the map function first splits the input line
into an array of words called line. It then creates a given number of
\texttt{DictionaryThread} threads and serves each thread a sub array of words from the
line array. Each \texttt{DictionaryThread} will check all of its incoming words similar
to the \texttt{DictionaryThread} in BruteForce. If the correct password is found, the
password will be written to the \texttt{sysout} folder on the machine where the mapper is
running.

A class named \texttt{Processor} initializes the \ac{CDA} attack by configuring
the mapper and reducer tasks. The number of mappers is set equal to the number
of nodes used in the cluster. This is to ensure that each machine only runs one
mapper at a time. The number of reducers are set to zero, because their
behavior in MapReduce is not needed.

\paragraph{Notice} The for-loop at Line 10 in Listing \ref{lst:mapfunc}
requires the number of words per line, in the dictionary, to be equal to a
multiple of the number of threads in use. It is recommended that the input
dictionary follows this requirement. 

In this occasion, we have created a Bash script, named \texttt{dictmaker.sh},
that changes a regular dictionary into an $N$ words-per-line dictionary. The
script can be found on the attached CD-ROM.

\chapter{Attachments}

This thesis comes with two available attachments -- one digitally uploaded to
the DAIM system\footnote{\url{http://daim.idi.ntnu.no/}}, and one physical DVD.

\section{Electronic Attachment}

The electronic attachment, uploaded to
DAIM, consists of the following files
and directories:

\begin{description}
  \item[Application] All files and source code to the proof of concept system,
    i.e. the background library, server and client.
  \item[Report] All files that is used to create this report, including images
    and tables.
  \item[Other] Scripts and raw data from the experiments.
\end{description}

\section{Attached DVD}

All the source code generated while working on this thesis, including the
source code for the proof of concept client code, can be found on an attached
DVD. In addition, all files related to the writing of this document, including
images and most of the references, are also included on the same DVD.

\end{document}
