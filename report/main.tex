\documentclass[pdftex,english,10pt,b5paper,twoside]{book}
\usepackage[T1]{fontenc} % In case we want special characters
\usepackage[utf8]{inputenc} % We are all writing in UTF-8

\usepackage[numbers]{natbib} % We need to tweak our referencing a bit.
\usepackage{appendix} % Fixes formatting of appendices
\usepackage[printonlyused]{acronym} % Package to handle the acronym list
\usepackage{graphicx} % We *may* use images
\graphicspath{{images/}} % and it is clean to put them in a separate dir
\usepackage{amstext} % To support \text in math mode
\usepackage{hyperref} % Internal and external links is nice
\hypersetup{
    pdfborder=0 0 0, % ..especially without red borders
    pdftitle={Cloud Storage Vault},
    pdfauthor={Haver, Melvold and Ruud},
    pdfsubject={Secure Storage in the Cloud},
    pdfkeywords={NTNU, thesis, secure, cloud, cryptographic, sharing}
}

% Packages and settings for code listings
\usepackage{listings}
\usepackage{caption}
\usepackage{upquote}
\usepackage{xcolor}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{
language=Java,
keywordstyle=\bfseries\ttfamily\color[rgb]{0,0,1},
identifierstyle=\ttfamily,
commentstyle=\color[rgb]{0.133,0.545,0.133},
stringstyle=\ttfamily\color[rgb]{0.627,0.126,0.941},
showstringspaces=false,
basicstyle=\small,
numberstyle=\footnotesize,
numbers=left,
stepnumber=1,
numbersep=10pt,
tabsize=2,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
breakatwhitespace=false,
aboveskip={1.5\baselineskip},
columns=fixed,
upquote=true,
extendedchars=true,
frame=bottomline,
inputencoding=utf8
}

% Set equal margins on book style
% \usepackage{layout} % Use \layout to print out the margins (debug)
%\usepackage{geometry}
%\geometry{bindingoffset=1cm}
\usepackage[lmargin=25mm,rmargin=25mm,tmargin=27mm,bmargin=30mm]{geometry}

% Restyle chapter headers
\usepackage{fix-cm}
\makeatletter
\renewcommand{\@makechapterhead}[1]{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedright \normalfont
    \vspace{15pt}%
    \ifnum \c@secnumdepth >\m@ne
        %\hfill\huge\scshape \@chapapp\space
        \hfill\fontsize{60}{90}\selectfont \thechapter % Chapter number
        \par\nobreak
        \vskip 20\p@
    \fi
    \interlinepenalty\@M
    \hfill \Huge \scshape #1\par % Chapter title
    \vspace{5pt}
    \hrule
    \nobreak
    \vskip 40\p@
  }}
\makeatother

\author{Eirik Haver \and Eivind Melvold \and Pål Ruud}
\title{Master thesis - Cloud Storage Vault}
\date{\today}

\begin{document}

\chapter*{Problem Description}
\thispagestyle{empty}
\pagestyle{empty}

Modern cloud storage systems that encrypts data for "at rest" protection often
has access to the stored data, since the encryption is performed with an
encryption key known by the service provider.\\

\noindent The candidates will design an application in which all data stored in
the cloud are encrypted with a key that can not be obtained by the service
provider.\\

\noindent Other goals of the application should be the ability to share
encrypted files with others users, without leaking the encryption key to the
service provider, and make it as user friendly as possible without compromising
security. The students will develop a proof of concept implementation of the
design.\\

\medskip\noindent
\begin{tabbing}
    Assignment given: \hspace{12pt} \= 24. January 2011 \\
    Supervisor: \> Danilo Gligoroski\\
    External Supervisors: \> Carsten Maartmann-Moe, Ernst \& Young AS\\
    \> Antonio Martiradonna, Ernst \& Young AS
\end{tabbing}

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\pagestyle{plain}
\pagenumbering{Roman}
\setcounter{page}{1}

%  Writers should follow a checklist consisting of:
% Motivation: Why do we care about the problem and results?
% Problem Statement: What problem are we trying to solve? Scope/limits.
% Approach: How did we go about solving or making progress on the problem?
% Results: What is the answer? Numbers, not vague 'very', 'small' etc.
% Conclusions: What are the implications of your answer? Further work.
%
%  Each section is typically a single sentence, although there is room for
%  creativity.

Today, major IT-companies, such as Microsoft, Amazon and Google, are offering
storage as a cloud service to their customers. This is a preferable solution to
regular storage in terms of low hardware costs, reliability, scalability and capacity.

However, the idea of storing customer data by an untrusted cloud provider
introduces the issue of data privacy and integrity. The customer is no longer in
position to control the physical access to the stored data, and is therefore
not guaranteed data privacy or integrity by the cloud provider.

To solve this problem, we have proposed a solution that ensures
privacy and integrity of customers' data stored by untrusted cloud providers.
The proposed solution does also support sharing of private data among customers
of the same cloud provider. The solution has further been implemented as a proof of concept.

When implementing the solution, we first created an underlying framework to support the
proposed and necessary cryptographic functionality. The framework was further
utilized to implement the final application.

Application Results:

Conclusion:


\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

The work behind this project report was carried out during the spring semester
in 2011 at the Norwegian University of Science and Technology (NTNU), Department
of Telematics (ITEM).
\vspace{13pt}

\begin{center}
Eirik Haver, Eivind Melvold and Pål Ruud
\vspace{13pt}

\end{center}

\tableofcontents

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\listfigurename}
\listoffigures

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\listtablename}
\listoftables

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\lstlistlistingname}
\lstlistoflistings
\cleardoublepage

\chapter*{Acronyms}
\addcontentsline{toc}{chapter}{Acronyms}

\begin{acronym}[PBKDF2]
\acro{ACL}{Access Control List}
\acro{AES}{Advanced Encryption Standard}
\acro{API}{Application Programming Interface}
\acro{BFDA}{Brute Force and Dictionary Attack}
\acro{CA}{Certification Authority}
\acro{CBC}{Cipher Block Chaining}
\acro{CDA}{Cluster Dictionary Attack}
\acro{CG}{Credential Generator}
\acro{CPU}{Central Processing Unit}
\acro{CSV}{Cloud Storage Vault}
\acro{CTR}{Counter}
\acro{DP}{Data Processor}
\acro{DRY}{Don't Repeat Yourself}
\acro{DSA}{Digital Signature Algorithm}
\acro{DSS}{Digital Signature Scheme}
\acro{DV}{Data Verifier}
\acro{EC2}{Elastic Compute Cloud}
\acro{ECB}{Electronic Codebook}
\acro{FAQ}{Frequently Asked Questions}
\acro{GPU}{Graphics Processing Unit}
\acrodef{GUI}{Graphical User Interface}
\acro{FEC}{Forward Error Correction}
\acro{HDFS}{Hadoop Distributed File System}
\acro{HTTP}{Hypertext Transfer Protocol}
\acro{HTTPS}{Hypertext Transfer Protocol Secure}
\acro{IaaS}{Infrastructure as a Service}
\acro{IV}{Initialization Vector}
\acro{JCA}{Java Cryptography Architecture}
\acro{JCE}{Java Cryptographic Extensions}
\acro{JDK}{Java Development Kit}
\acro{JRE}{Java Runtime Environment}
\acro{JVM}{Java Virtual Machine}
\acro{LAFS}{Least Authority File System}
\acro{MAC}{Message Autentication Code}
\acro{MITM}{Man-in-the-middle}
\acro{NIST}{National Institute of Standards and Technology}
\acro{OS}{Operating System}
\acro{PBKDF2}{Password-Based Key Derivation Function version 2}
\acro{PaaS}{Platform as a Service}
\acro{PasS}{Privacy as a Service}
\acro{PEP}{Python Enhancement Proposal}
\acro{PGP}{Pretty Good Privacy}
\acro{PKI}{Public Key Infrastructure}
\acro{PoC}{Proof-of-concept}
\acro{PRNG}{Pseudorandom Number Generator}
\acro{QR}{Quick Response}
\acro{RAM}{Random Access Memory}
\acro{ROM}{Read Only Memory}
\acro{REST}{Representational State Transfer}
\acro{RSA}{Rivest, Shamir and Adleman}
\acro{SaaS}{Software as a Service}
\acro{SDK}{Software Development Kit}
\acro{SHA}{Secure Hash Algorithm}
\acro{SQL}{Structured Query Language}
\acro{SSL}{Secure Socket Layer}
\acro{TCCP}{Trusted Cloud Computing Platform}
\acro{TCG}{Trusted Computing Group}
\acro{TG}{Token Generator}
\acro{TLS}{Transport Layer Security}
\acro{TPM}{Trusted Platform Module}
\acro{TTP}{Trusted Third Party}
\acro{UMTS}{Universal Mobile Telecommunications System}
\acro{URI}{Uniform Resource Indetifier}
\acro{URL}{Uniform Resource Locator}
\acro{USB}{Universal Serial Bus}
\acro{VM}{Virtual Machine}
\acro{WSGI}{Web Server Gateway Interface}
\end{acronym}

%**************************************%
\chapter{Introduction}
\label{ch:intro}
%**************************************%
\pagenumbering{arabic}
\setcounter{page}{1}

% TODO: Generic introduction

The term \emph{Cloud Computing}, and the common shorthand \emph{The Cloud},
is not yet clearly defined \cite{clouddef}, but involves the provision of
software or computational resources available by demand via the Internet.
In a draft \cite{cloud_nistdef}, the \ac{NIST} defines cloud computing as:
\begin{quote}\it
``Cloud computing is a model for enabling ubiquitous, convenient,
on-demand network access to a shared pool of configurable computing resources
(e.g., networks, servers, storage, applications, and services) that can be
rapidly provisioned and released with minimal management effort or service
provider interaction.''
\end{quote}

More and more of the traditionally locally hosted services of businesses is
moving to the cloud. The amount of flexibility and cost savings this
provides, can be quite extensive.

Today, we take the services that the established cloud providers offer us for
granted. For example, both Google and Microsoft provides the services of online
document editing, email, picture collections, file storage and a lot more for
free, and available at anytime from anywhere \cite{googleservices,
microsoftservices}.

However, this often comes at a cost of reduced privacy, as the control over the
hosting environment is lost. Users is therefore forced to increasingly think
about how the data stored online can leak to unwanted people, either by
accident, or by purpose by unfaithful servants at the cloud provider. Should it
be sufficient to trust the security policies of the cloud providers, or is it
possible to handle the privacy issues locally before giving away the files?

\section{Motivation}

In the last decade, the available supply for services that offer data storage
remotely in the cloud has increased considerable. Storing private data at a
third party provider, in contrast to self-hosted storage devices, has proven to
be preferable due to low storage costs and high reliability, scalability and
capacity.

However, storing data at a remote location prevents users from physically
protecting their storage medium. With this in mind, there is no guarantee that
a customer's data is kept private and secure from disloyal employees at the
storage provider.

To solve this issue, there has lately been introduced numerous applications and
architectures \cite{dropbox_security, tahoe, tccp, PasS} providing solutions to
ensure privacy and integrity of customer data stored at the \emph{insecure}
cloud provider. However, all of these alternative systems are missing one
or more features towards being, as we will define it, a completely secure
storage solution.

This situation has given motivation to implement a proof of concept
application, that fulfills all of the criteria for what we define as a secure
cloud storage service.

Additionally, we do also see this as a golden opportunity to learn more
about software development, development methodologies, team work, and practical
use of information security and cryptography.

\section{Related Work}

In the later years, there has been quite a lot of research done in the field of
security in cloud computing. The problems that arise, are fundamentally not
different from those revealed by classic information security scenarios. The
key point, is that when using a service hosted by someone you do not know if
you can trust, you have to treat that \emph{someone} as untrusted and as a
possible attacker. Generally speaking, you loose control over the hosting
environment, and hence has to deal with the security issues this implies.

In Section \ref{sec:research}, we present four papers \cite{PasS,
privacymanager, tccp, microsoftresearch} which try to solve security issues in
a shared hosting environment. Common to all of these, is that they either rely
on special, secure and tamper-proof hardware and/or a trusted third party.

Another way of providing a solution to the same problem, is to give the
responsibility of the security operations to the client, i.e. in an environment
that the user has control of. In Section \ref{sec:existing}, we present three
commercially and publicly available software services that relates to this way
of thinking.

One of these applications, Tahoe-\ac{LAFS} \cite{tahoe}, is given special
attention. This is because it is an Open Source and a well documented piece of
software, that answers most of the problems arising in an untrusted cloud
storage environment, and relates closely to the work performed in this thesis.

\section{Scope and Objectives}
\label{sec:criteria}

There are two main objectives of this thesis. The first objective is to create
a cryptographic scheme that can provide secure storage of data by using an
untrusted cloud storage provider. We define the criteria of a secure storage
system by the following points:

\begin{enumerate}
  \item Data should be encrypted in a safe environment trusted by the owner,
      before it is stored on the server.
  \item It should be possible to verify the integrity of the stored data.
  \item Only authorized people should have access to the data.
  \item The storage scheme should be documented in detail, such that users can
      easily understand the scheme and accept/reject it on that basis.
  \item An implementation of the storage scheme should be Open Source.
  \item An intrusion of the server should not affect the security of
      the stored files.
\end{enumerate}

The cryptographic scheme should, in addition to the mentioned security, provide
the possibility of sharing stored data between multiple cloud storage
customers. The security requirements above should also be valid for the shared
data. The underlying scheme for sharing data should be applicable for both
enterprise and regular customer scenarios.

The second main objective is to implement the proposed scheme as part of a
proof of concept application for Android devices. The application should be
designed for regular customers, although the underlying cryptographic scheme
should additionally support enterprise scenarios. It is further important that
the server side of the application is compatible with as many existing cloud
storage providers as possible.

Finally, it is important that the implementation of the cryptographic scheme
is available as Open Source.

\section{Limitations}

We will focus on making an architecture that covers the scope and objectives,
in an easy to understand and complete way. In addition, making core
functionality, that demonstrates the most important security features in a proof
of concept system, will be prioritized.

However, due to time and resource constraints, we will focus less on the following:
\begin{itemize}
  \item The language in the proof of concept client should be clear, but the
    \ac{GUI} in itself will not get special attention
  \item Experimentation with the proof of concept code, other
    than basic performance and security measurements
  \item Experimentation with the proof of concept client on hardware equipment
    other than what we easily have available at the time of testing
\end{itemize}

\section{Methodology}

The work behind this thesis, is carried out by the three authors in
cooperation. The methodology used, can be categorized based on the three main
parts of this work; the \emph{research}, the \emph{design and abstraction}
part, and the \emph{software development} cycles.

The research will include an analysis of related systems, and a study of
relevant background theory. Based on this theory, we will use experimentation
to create and design a theoretical solution to the problem of secure storage
and sharing of files on an untrusted server. We will iteratively analyse our
experimentation to find and correct flaws with the design.

The third part of the work, is the software development cycles of the proof of
concept application.

\paragraph{SCRUM} We will work after SCRUM principles -- an iterative and
incremental based framework for project management \cite{scrum}. There does not
exist a SCRUM \emph{product owner} for the system we will create, nor do we
fulfill the requirements and characteristics \cite{scrum} of a traditional
SCRUM \emph{team}. Hence, we will use the principles that are practically
possible for us to follow:

\begin{itemize}
  \item Daily \emph{stand-up} with planning of the tasks of the current day
  \item Weekly \emph{sprint}\footnote{A \emph{sprint} is a defined period with
    a given set of tasks.} planning meetings
  \item Keep tasks on stickers, that we move between different phases on a
    board: \emph{to do}, \emph{in progress}, \emph{quality assurance} and
    \emph{done}. This is to keep track of progress in the current sprint
  \item Continuously analyse the process, and improve it if possible
\end{itemize}

\paragraph{DRY} We choose to follow the \ac{DRY} principle when developing
software. \citet{dry} define \ac{DRY} as:

\begin{quote}\it
Every piece of knowledge must have a single, unambiguous, authoritative
representation within a system.
\end{quote}

\noindent This principle can be taken further, as to not develop something that
has already been developed in the past. If there exist a library for a given
task that does fulfill the requirements set for the specific task, we will
choose to utilize the library instead of developing similar code by ourselves.

\section{Outline}

This thesis is presented as per the following chapters:

\paragraph{Chapter \ref{ch:background} -- Background} provides background
knowledge of the security services, technologies and software used to form a
secure cloud storage system. In addition, relevant research and commercial
solutions are scrutinized.

\paragraph{Chapter \ref{ch:technical} -- Technical Procedure} goes through the
development process of the scheme and software produced by this thesis. It
starts with an overview of the architectural properties, followed by the more
specific cryptographic scheme that fits in with the architecture. Lastly, the
implementation of the proof of concept system is described.

\paragraph{Chapter \ref{ch:experimental} -- Experimental Procedure} presents
the measurements and practical experimentation done to look at how the system
performs performance- and security-wise.

\paragraph{Chapter \ref{ch:results} -- Results} illustrates the findings from
the experimentation.

\paragraph{Chapter \ref{ch:discussion} -- Discussion} reflects on the specific
implementation and results from the previous chapters. In addition, associated
functionality to a secure cloud storage system, that has not been mentioned
earlier, is presented and discussed.

\paragraph{Chapter \ref{ch:conclusion} -- Conclusion} extracts the most
important results and findings, and concludes the work done in this thesis.
Further work that can be applied to the created system and scheme,
are prioritized and presented as final ideas.

\bigskip

\noindent In addition, included appendices consist of:

\paragraph{Appendix \ref{ap:other} -- Other Relevant Implementations}
presents the implementations created to carry out the security experiments.

\paragraph{Appendix \ref{ap:attachments} -- Attachments} describes the contents
of the supplied attachments provided.

%**************************************%
\chapter{Background}
\label{ch:background}
%**************************************%

The basis and underlying technologies for a secure storage service in the
cloud, are quite numerous and quite often complex.

In the following sections, we will go through the security services, cryptographic
services and attacks that are relevant to such a service. In addition, we present
related research and existing solutions available at the time of writing.

This chapter forms the basis for the architecture of the proposed solution
presented in this thesis.

\section{Security Services}

This section explains the security services and technology used in this thesis. A security
service is any processing or communication service that enhances the security of
the data processing systems and the information transfers of any organization,
as defined by \citet[p. 12]{stallings}.

\paragraph{Confidentiality} Confidentiality is the act of keeping a message
secret from unauthorized parties \cite[p. 18]{stallings}. This can typically be
done by either preventing other parties access to the message at all, or by making
the contents unreadable, for instance by the use of encryption.

\paragraph{Integrity} Integrity implies that a message cannot be altered
without the receiving part noticing. In a security perspective, integrity deals
with detecting, preventing and recovering a message being changed by an
attacker \cite{stallings}.

\paragraph{Availability} The property of a system being accessible and usable
upon demand by an authorized system entity, are defined by the availability
service \cite{stallings}.

\paragraph{Authentication} Authentication is the act of a user, service or
similar to prove that he is what he claims to be \cite{stallings}.

\paragraph{Non-Repudiation} Non-repudiation prevents both the sender and the
receiver of a message from refuting the authenticity of transmitted message. In
other words, one party can prove the involvement of the other party
\cite{stallings}.

\section{Cryptographic Primitives}

This section describes the low level security primitives used in the results of
this thesis.

\emph{Randomness} is a basic property that multiple of the cryptographic
primitives rely on, and hence deserves an explanation. Random data is
informally defined as unpredictable to the attacker, even if he is taking
active steps to defeat the randomness \cite[p. 137]{schneier}.

A \emph{Cryptographic \ac{PRNG}} deterministically produce numbers based on a
seed, and it should be infeasible to determine the next number without knowing
the seed \cite[p. 140]{schneier}.

\subsection{Encryption}

Encryption is the process of transforming some information into an unreadable
form. It is primarily used to enforce confidentiality, but can also be
used for other purposes, e.g. authentication.

In its very basic form, an encryption scheme consist of an encryption algorithm
(the \emph{cipher}), a key and a message (the \emph{plaintext}), that is all
used to create an encrypted message, i.e. the \emph{ciphertext}. If a strong
cipher is used, knowledge of the cipher, or multiple plaintext and multiple
ciphertext, should not be enough to obtain the key, or to decrypt ciphertext
with a corresponding unknown plaintext \cite{schneier}.

\paragraph{Block Cipher and Stream Cipher} There are different classifications
on how a cipher treats data \cite[p. 32]{stallings}. A \emph{block cipher} will
encrypt a block of data of a specific size. If the data is larger than the
block size used by the application, a \emph{mode of operation} is needed. In a
\emph{stream cipher}, the plaintext will usually be combined with a pseudorandom key
stream to generate the ciphertext.

\paragraph{Symmetric Encryption} Symmetric-key encryption is an encryption scheme
where the same key is used for both encryption and decryption \cite[p.
32]{stallings}. The \ac{AES} is a block cipher and is the current standard for
symmetric encryption. The \ac{AES} works on a block of 128 bits at a time,
and support keys with length of 128, 192 and 256 bits.

\paragraph{The Mode of Operation} The mode of operation used for a
symmetric-key encryption enables subsequent safe use of the same key.

In a simple scenario, this could be to encrypt the normal data block-by-block
with pure \ac{AES}, which is called the \ac{ECB} mode of operation. The problem
with this is that some information of the plaintext will leak, i.e. the same
plaintext will always be encrypted as the same ciphertext.

An other mode is \emph{\ac{CBC}}. In \ac{CBC}, a non-predictable and not reused
\ac{IV} is used. The \ac{IV} is XORed with the first block of plaintext, which
again is encrypted with \ac{AES}. The resulting ciphertext is used as an
``\ac{IV}'' for the next block \cite[p. 183]{stallings}, and so on.

\paragraph{Asymmetric Encryption} Asymmetric key encryption is an encryption scheme
where different keys are used for encryption and decryption
\cite[p. 259]{stallings}.

An asymmetric encryption scheme is often called a \emph{public-key
encryption} scheme, where one key is defined as private and the other as public.
The public key is shared to allow other parties to encrypt messages that only the
owner of the private key can decrypt.

The downside of asymmetric encryption compared to symmetric is that it requires
a larger key, and that it has a larger computational overhead to obtain the
same level of confidentiality as comparable symmetric-key encryption. The
probably best known asymmetric cipher is \ac{RSA}.

\subsection{Cryptographic Hash Functions}

A cryptographic hash function is a deterministic mathematical procedure, which
takes an arbitrary block of data and outputs a fixed size bit string. The
output is referred to as the \emph{hash value}, \emph{message digest} or simply
\emph{digest}.

Another property of a cryptographic hash function, is that the
smallest change in the input data, e.g. one bit, should completely change the
output of the hash function. In other words, it should be infeasible to find the
reverse of a cryptographic hash function \cite[p. 335]{stallings}. It should
also be infeasible to find two blocks of data which produce the same hash value
(a \emph{collision}).

The standard for cryptographic hash functions today, are \ac{SHA}-1 and the
\ac{SHA}-2 family.

\subsection{MAC Functions} 

\citet{schneier} defines a \ac{MAC} to be a construction that detects tampering
with a message -- i.e. it authenticates the message. A \ac{MAC} can be
constructed in different ways, one example is H\ac{MAC} which constructs the
\ac{MAC} using a secret key, the message and a hash function \cite{rfc2104}. 

\section{Applications of Cryptographic Primitives}

\subsection{Digital Signatures}

A digital signature is the digital equivalent of a normal signature, i.e. it
verifies that an entity approves with or has written a message. It can also
verify the date the signature was made. In addition, it should be verifiable by
a third party \cite[p.  379]{stallings}.

It should logically not be possible, or at least unfeasible, to fake a digital
signature.

The \ac{RSA} cipher can be used to generate signatures. In addition, there is also a
standard for digital signatures, called \ac{DSS}, which uses \ac{DSA} as the
underlying algorithm.

\subsection{Digital Certificates and PKI}

A digital certificate is the pairing of a digital signature and a public key
\cite{stallings}. By this scheme, the services confidentiality, authentication
and non-repudiation can be achieved.

For example, a person has a certificate with some clues about the identity
in it, e.g. the e-mail, together with a public key. This certificate can then
be signed using digital signatures, to verify that some other entity trusts this
certificate.

In practice, the entity which signs certificates is the \ac{CA}, which all
clients have the public key information for, and trusts. The \ac{CA} will also
contain information about which certificates has been revoked, i.e. should not
be trusted in use. Such a scheme is usually referred to as a \ac{PKI}.

\subsubsection{PGP}

\ac{PGP} is a scheme similar to \ac{PKI}, but with no \ac{CA} that all users
trust \cite{stallings}. Instead, trust is made between users by somehow
verifying their public key, for instance by meeting face to face. A user can
then sign another users key, set a trust level for the user, and publish this
information to a key server.

Another user can then calculate a trust on an unknown person, based on the trust
set by peoples that he trusts, from information located on publicly
available key servers.

\subsection{SSL/TLS}

\ac{TLS}, and its predecessor \ac{SSL}, are technologies for obtaining
confidentiality, integrity and authentication for transfer of files over a
network \cite{stallings}. It does so by a combination of different algorithms
and primitives, but a digital certificate is required for authentication.

To transfer files securely over \ac{HTTP}, \ac{TLS}/\ac{SSL} is used to form
\ac{HTTPS}.

\subsection{Key Derivation Functions}
% FIXME: Dette kapitellet og MAC er det primitiver eller applications?
\label{sec:PBKDF2}
A key derivation function is a function which takes a key, a password, a
passphrase or similar and creates a new key from it. One of the applications of
such a function is to create a stronger key from a weaker key, such as a
password. This technique is called \emph{Key Stretching}. What the process
involves is making the derivation of a key from a password an expensive
process in terms of computing power, which in turn makes it more resistant to
brute force attacks.

\ac{PBKDF2} is a key derivation function which uses key stretching. It uses a
password together with a randomly generated salt and a pseudorandom function to
do this\cite{rfc2898}. The function will combine this in a specific way, and
can repeat the process for a specified number of times, the iteration count.
A higher iteration count results in a stronger key. The salt provides defense
against a precomputed collection of keys, a \emph{rainbow table}, in the sense
that it will make sure that a password will not derive the same key if the same
salt is not used.

\section{Security Attacks}

This section briefly list security attacks relevant to this thesis, as defined
by \citet[Ch. 1.3]{stallings}.

\paragraph{Active and Passive Attacks} Two general classifications of security
attacks exist, where a \emph{passive attack} attempts to learn or make use of
information from the system, but does not affect system resources. An
\emph{active attack} attempts to alter system resources or affect their
operation.

\paragraph{Traffic Analysis} Traffic Analysis is the act of capturing and
examining communication data sent between two parties. This information might
contain secrets or for instance leak enough information about an encryption key
to make it breakable.

\paragraph{Masquerade} Masquerade is an active attack where the attacker pretends to be
one of the legitimate parties.

\paragraph{Replay} Replay is an active attack where the attacker capture some
data in a communication session and subsequently retransmit that information.

\paragraph{Modification of Messages} Modification of messages is an active
attack where the attacker alters some of the contents of a message sent between
two communicating parties.

\paragraph{Denial of Service} Denial of Service is an active attack where the
attacker seeks to make resources unavailable for legit users, i.e. by
overloading an application by sending it lots of traffic.

\paragraph{\acl{MITM}} \ac{MITM} is an attack where an attacker intercepts messages
between the communicating parties and then either relay or substitute the
intercepted message.

\subsection{Attacks on Cryptographic Primitives}

Even though cryptographic primitives are designed to be secure, they might have
implementation flaws and be used in an improper fashion, e.g. by using wrong
parameters.

\paragraph{Cryptanalysis Attack} A cryptanalysis attack is an attempt to deduce
a specific plaintext or to deduce the key being used in a ciphertext.

\paragraph{Brute-Force Attack} In a brute-force attack, an attacker tries
to obtain a secret by testing the algorithm with up to all possible inputs. The
secret might be an encryption key, or the data fed into a cryptographic hash
function.

A related attack is the \emph{Dictionary attack}, where the attacker
tries to obtain a secret by trying a subset of all known inputs, i.e. a
predefined dictionary of words.

\section{Cloud Computing}

In this section, we will extend from the definitions given in Chapter
\ref{ch:intro}, and further describe terms that are associated with
\emph{Cloud Computing}.

\subsection{Service Models}
The \ac{NIST} also defines three service models which deals with what kind of
service the consumer can rent from a provider.

\paragraph{\ac{SaaS}} The capability for a consumer to run the provider's
application running on cloud infrastructure, using a thin-client, browser or
similar, is called \ac{SaaS}. The web-based email service
GMail\footnote{\url{http://www.gmail.com}} can be seen as an example of this.

\paragraph{\ac{PaaS}} The capability for a consumer to deploy software onto
the cloud, but without actually controlling the underlying platform, operating
system and so on, is called \ac{PaaS}.

\paragraph{\ac{IaaS}} The capability provided to the consumer to provision
processing, storage, networks and other fundamental computing resources where
he can run arbitrary software, including operating systems and applications, is
called \ac{IaaS}. An example is when renting a \ac{VM}.

\subsection{Deployment Models}

The \ac{NIST} draft \cite{cloud_nistdef} also lists several deployment models
which deals with how the cloud is organized in terms of where it is hosted, and
who has access to it.

\paragraph{Private Cloud} A private cloud is a cloud infrastructure operated
solely for an organization. Which party manages the cloud, and where it is
located is not defined.

\paragraph{Community Cloud} A community cloud is a cloud infrastructure is
shared by several organizations to serve a common concern. Where it is located
and who manages it is not given.

\paragraph{Public Cloud} A public cloud is a cloud infrastructure where
everyone, or at least a large group, can have access, and is owned by an external
provider of cloud services.

\paragraph{Hybrid Cloud} A hybrid cloud is a cloud infrastructure composed of
two or more clouds of any other model.

\subsection{Security Considerations in Cloud Computing}

There are some considerations when using cloud services from an external
provider, as opposed to self controlled hardware, software and platforms. Most
notably is that you loose the control of selecting the people which will have
physical and digital access to the infrastructure \cite{cloud_getoff}. In
essence, this means that the provider can read every data sent to and from the
cloud as well as the data saved in the cloud.

Another risk is that information might be leaked to other users of the same
cloud. For instance it might be able possible for a \ac{VM} to leak information
to other \acp{VM} on the same host \cite{cloud_getoff}.

\section{Research}
\label{sec:research}

This section will elaborate on selected previous research concerning privacy
within cloud computing. The research on this subject can be divided into
proactive solutions that either reduce, or prevent the risk of leaking privacy
related information. Only the latter type of solutions are further discussed.

We choose to present these papers as they provide possible solutions to the
same problems this thesis is set out to solve, although from a different angle.
A criterion of the scheme presented in this thesis, as described in Section
\ref{sec:criteria}, is that unauthorized access to the encrypted files stored
on the server should be avoided, but that it should not be crucial for the
security of the content of the files. The following first three security
systems seeks to secure the cloud server itself, and the last one argues for
building a secure system on top of non-trusted cloud servers.

\subsection{Privacy as a Service}

A concept entitled \ac{PasS}, was suggested in 2009 \cite{PasS}. \ac{PasS} is a
set of security protocols ensuring privacy of customer data in cloud computing
architectures. The main design goal with \ac{PasS}, is to maximize the user's
control over his sensitive data, both processed and stored within a cloud.

The \ac{PasS} concept is based on a fundamental \emph{system model} and
\emph{trust model}. The system model consists of three communicating parties,
namely a \emph{cloud provider}, a \emph{cloud customer} and a \emph{\ac{TTP}}.
The \ac{PasS} system model is shown in Figure \ref{fig:RW:PasS}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ArchitecturePasS.pdf}
    \caption{System model of PasS}
    \label{fig:RW:PasS}
\end{figure}

It is important to notice that the \ac{PasS} system model is dependent on
pre-installed cryptographic coprocessors in the hardware running the cloud
service.

A cryptographic coprocessor is a small hardware card, including a processor,
\ac{RAM}, \ac{ROM}, backup battery, persistent storage and an Ethernet network
card. A coprocessor interfaces with a server in the cloud, and provides a safe
environment for processing of a customer's sensitive data.

The cryptographic coprocessors are used in the cloud because they are
tamper-proof against physical attacks. The coprocessors are pre-configured by
the \ac{TTP} before they are installed. By using this procedure, the \ac{TTP}
provides a safe computational environment for the cloud customer, which is kept
secret from the cloud provider.

The main task of the \ac{TTP} is to compute a set of public/private key pairs,
load them into the persistent storage of the co-processor, and further send
them to the customer. The \ac{TTP} also loads its own secret key into the
coprocessor. This key distribution ensures secure communication between the
\ac{TTP}, coprocessors and the cloud customer. The customer's key pair is sent
through a secure communication channel.

With cryptographic coprocessors in the cloud and a secure communication, the
cloud customer can choose between three different levels of privacy towards the
cloud provider -- no privacy, privacy with a trusted provider and privacy with
a none-trusted provider.

\emph{No privacy} implies storing data as clear text in the cloud.
\emph{Privacy with a trusted provider} involves storing encrypted data in the
cloud. This data is encrypted by the cloud provider and only achievable by the
customer or cloud provider.

In the case of \emph{privacy with a non-trusted provider}, the customer
encrypts the private data before uploading it to the cloud provider. The key
used for encryption is shared with the cryptographic co-processor, through an
authenticated version of the Diffie-Hellman key management protocol. The
co-processor can further process the encrypted data and store it in the cloud
facility. The stored data is encrypted and unknown to the cloud provider.

\subsection{Privacy Manager}

In 2009, HP Labs proposed a way to manage and control a user's private data,
stored and processed in a cloud facility \cite{privacymanager}. Their solution
was partially implemented as a software program called a \emph{privacy manager}.

The privacy manager uses a feature called \emph{obfuscation}, which is quite
similar to encryption. However, the obfuscation method is different from
encryption in the sense that the obfuscated data can be processed in the
cloud, without the cloud provider knowing the encryption key or the original
data. \citet{privacymanager} mention the following obfuscation methods:

\begin{itemize}
\item Yao's protocol for secure two-party computation \cite{yao}
\item Gentry's homomorphic encryption scheme \cite{gentry}
\item Narayanan and Schmatikov's obfuscation method \cite{obfuscationmethod}
\end{itemize}

Due to better efficiency, the privacy manager uses the latter alternative. However,
Narayanan and Schmatikov's obfuscation method does not provide complete
confidentiality to the cloud provider \cite{obfuscationmethod}.

In addition to installing a privacy manager at the user's terminal, HP Labs
suggests the use of trusted computing solutions to address the lower-level
protection of data. The \ac{TCG} is an example of an organization developing
and providing trusted computing solutions \cite{tcg}. A tamper-proof piece of
hardware called a \ac{TPM} is recommended \cite{privacymanager}, which is
designed by \ac{TCG}. The \ac{TPM} is installed in the machine running the
privacy manager, to ensure that processes carried out by the privacy manager can
be fully trusted.

The privacy manager is suggested to work in three different use cases. It can
be implemented to support a \emph{single client}, the use of \emph{hybrid
clouds} and/or the use of an \emph{infomediary} within the cloud.

%Regarding applications in the cloud where users have to upload unobfuscated
%private data, the privacy manager includes two additional features called
%preferences and personae. Both features are dependent on a trustworthy service
%and cloud provider, and are therefore irrelevant to our development.

\subsection{Trusted Cloud Computing Platform}

Equal to \acl{PasS} and the privacy manager, \emph{\ac{TCCP}} was proposed as a
solution to provide secure computations and storage within a non-trusted cloud
provider \cite{tccp}. As opposed to the previous solutions, \ac{TCCP} is
directed against secure execution of guest \acp{VM} outsourced to \ac{IaaS}
providers.

The original infrastructure, before adding \ac{TCCP}, is assumed to
consist of a \emph{cloud manager}, which manages a cluster of nodes running one or more
\acp{VM}. Among multiple tasks, the cloud manager is responsible for loading \ac{VM}
images into its own nodes.  Each node has a \emph{\ac{VM} monitor} which will further
launch and monitor \acp{VM} from the received corresponding images.

\ac{TCCP} is based upon the \acf{TPM} chip designed by the \acl{TCG}. The
\ac{TPM} contains a private/public key pair that it uses to uniquely identify
itself. The public key is additionally signed by the manufacturer to guarantee
correctness of the \ac{TPM} chip.

With this in mind, \ac{TCCP} is based upon a \emph{remote attestation scheme}.
The scheme enables a network entity to verify whether another remote entity
runs a \ac{TPM} chip or not. A detailed description of the remote attestation scheme
is given by \citet{tccp}.

The \ac{TCCP} system architecture is illustrated in Figure \ref{fig:RW:TCCP}.
The trusted computing base of \ac{TCCP} includes a \emph{trusted coordinator}
and a \emph{trusted virtual machine monitor}. The coordinator manages the
trusted nodes within a cluster. To be trusted, a node must be located within a
security perimeter and run a trusted virtual machine monitor.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{ArchitectureTCCP.pdf}
    \caption{System architecture of TCCP}
    \label{fig:RW:TCCP}
\end{figure}

The coordinator maintains a record of the nodes located in the security
perimeter, and use remote attestation to ensure nodes are trusted. Each trusted
node in a cluster contains a \ac{TPM} chip and a corresponding trusted monitor.
The main task of the trusted monitor, is to enforce a local closed box
protection of a client's running \ac{VM}. Details about the design of the
trusted \ac{VM} monitor, are given by \citet{tccp}.

Each trusted virtual machine monitor cooperates with a trusted coordinator to
protect the transmission of \acp{VM} between trusted nodes, and to ensure that
\acp{VM} are executed by trusted nodes. In this context, the \ac{TCCP}
specifies several protocols for both launching and migrating \acp{VM} inside
the cloud. These protocols are described by \citet{tccp}.

The trusted coordinator-part is installed in servers operated and maintained by a
trusted third party, to prevent unwanted tampering from the \ac{IaaS} provider.
A client can further use remote attestation to the coordinator to verify that the
\ac{IaaS} provider secures its computation.

With \ac{TCCP}, the client interacts with the \ac{IaaS} provider as usual. The
difference is that the trusted nodes and their trusted coordinator communicates
to ensure a secure environment for executing the client's \ac{VM}.

\subsection{Cryptographic Cloud Storage}

In 2010, researchers at Microsoft were looking at the problem of building a
secure cloud storage service on top of a non-trusted cloud storage provider
\cite{microsoftresearch}. They described architectural solutions related to
both consumers and enterprises. The architectures were explained in high level
and were designed to utilize and combine recent and non-standard cryptographic
primitives.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ArchitectureCCSC.pdf}
    \caption{Cryptographic cloud storage, customer scenario.}
    \label{fig:RW:CCS:CA}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ArchitectureCCSE.pdf}
    \caption{Cryptographic cloud storage, enterprise scenario.}
    \label{fig:RW:CCS:EA}
\end{figure}

The consumer architecture is depicted in Figure \ref{fig:RW:CCS:CA}, and a typical
enterprise architecture is shown in Figure \ref{fig:RW:CCS:EA}.\\

\noindent Each architecture consists of the following computational components:
\begin{description}
  \item[\ac{DP}] \hfill \\Processes data before it is sent to the cloud.
  \item[\ac{DV}] \hfill \\Checks whether data stored in the cloud has been
  tampered with.
  \item[\ac{TG}] \hfill \\Generates tokens that enable the cloud provider to
  retrieve segments of customer data.
  \item[\ac{CG}] \hfill \\Responsible for creating and distributing access
  policies.
\end{description}

The core components are suggested to support \emph{searchable encryption},
\emph{attribute-based encryption} and a \emph{proofs of storage} protocol.

\section{Existing Solutions}
\label{sec:existing}

There are a number of existing solutions for storing data in the cloud,
with more or less of the functionality required to fulfill the problem
description for this thesis. The section highlights some of them.

\subsection{Dropbox}

Dropbox\footnote{\url{http://www.dropbox.com/}} is a popular commercial
application for storing data in the cloud, claiming more than 25 million users
\cite{dropbox_users}. All files are saved using Amazons S3 storage service.

The company boasts strong encryption and strict access control
\cite{dropbox_security}, but has received criticism for its lack of security
\cite{dropbox_concerns}. Among these concerns, is the \emph{Forgotten Password}
feature, which implies that Dropbox can read the users files if they really
want to -- because they have the password -- and that the encryption is
performed server-side.

In addition, Dropbox is not Open Source, and hence one has no way of verifying
that the security features actually work as claimed.

\subsection{Tahoe-LAFS}
\label{sec:tahoe}

Tahoe-\ac{LAFS}\footnote{\url{http://www.tahoe-lafs.org/}} is an open source,
distributed and secure cloud storage file system, which does fulfill
the criteria set in Section \ref{sec:criteria}.
The integrity and confidentiality of the
files are guaranteed by the algorithms used on the client, and is independent
of the storage servers, which may be operated by untrusted people.
This is defined as \emph{provider-independent security} \cite{tahoe}.

In Tahoe-\ac{LAFS}, files are exclusively encrypted client-side, then split up
using \emph{Erasure-coding}, before being uploaded into the cloud\footnote{The
\emph{cloud} in the Tahoe-\ac{LAFS} sense, often refers to other nodes in a so
called \emph{friend net}.}, as illustrated in Figure \ref{fig:B:tahoe}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{Tahoe-newfile.pdf}
    \caption{Tahoe-LAFS: Insertion of a new file}
    \label{fig:B:tahoe}
\end{figure}


\subsubsection{Architecture of Tahoe-LAFS}

Tahoe-\ac{LAFS} has a three layer architecture: the key-value store, the file system, and
the application \cite{tahoe}.

The \textbf{key-value store}, is the lowest layer and is implemented by a grid
of Tahoe-LAFS storage servers. Data is kept on the storage servers in the form
of \emph{shares}, which are encrypted and encoded parts of files. Capabilities
are short ASCII strings, containing information on where to find a file, and
how to verify it.  Nodes in the grid learn about each other through an
\emph{introducer}.

The \textbf{file system} layer is responsible for mapping human-meaningful
pathnames to pieces of data. Each directory contains a table of capabilities
for its children, i.e. subdirectories or files. Two forms of capabilities is
available for each file, read-only and read-write, and these can be distributed
to e.g. share a file with friends.

Since it is not practical for users to remember strings containing random
characters, the \textbf{application} layer is used for providing a user-friendly
interface to the directories and files.

\paragraph{File Types}

There are two kinds of files in the Tahoe-\ac{LAFS} -- \textbf{immutable} and
\textbf{mutable} files. An immutable file is created exactly once, i.e. it
cannot be modified, and can be read repeatedly. Mutable files can be modified,
and everyone who has access to the signing key can make new versions of
the mutable file. Directories are implemented as mutable files.

\paragraph{Erasure Coding}

Erasure-coding with the Solomon-Reed scheme, enables Tahoe-\ac{LAFS} to recover
a file using only a predefined subset of the parts distributed to the storage
servers. Erasure coding is a type of \ac{FEC} code, which extends a message
with $C$ characters into a longer message with $N$ symbols
\cite{t_reed-solomon}. The original $C$ characters can then be recovered from a
subset of the $N$ symbols.

\subsection{Wuala}

Wuala\footnote{\url{http://www.wuala.com/}} is a closed source secure cloud
storage file system, that seemingly operates very similar to Tahoe-\ac{LAFS}.

The authors have released a paper on a cryptographic tree structure for file
systems, called Cryptree \cite{cryptree}, and has strong focus on reliability
by both providing central servers, in addition to a \emph{P2P cloud} of Wuala
users that has donated capacity to the system.

%**************************************%
\chapter{Technical Procedure}
\label{ch:technical}
%**************************************%

% TODO: Complete this

This chapter will describe a proposed architectural and cryptographic scheme
for providing secure storage of data on a remote untrusted system. It will
further explain the procedures carried out to create a proof of concept
application, that implements the proposed architectural and cryptographic
scheme. The application, named \emph{\ac{CSV}}, is implemented as an
Android application, and consists of a separate server and client functionality.

The chapter will start by giving an overview of the proposed architectural
scheme followed by a more detailed description of the corresponding
cryptographic scheme. The chapter will end by describing the implementation
details for both the server and client side functionality of the Cloud Storage Vault.

\section{Architectural Overview}
%**************************************%
\label{chap:AS}

The architectural solution of a secure cloud file sharing system has to
convince its users that the functions indeed are secure, and that the concepts
are easy to understand and accept. The following sections will elaborate on the
architecture designed by us, favouring simplicity and familiar concepts, such
as files and directories. We also introduce the concept of \emph{capabilities}.

Figure \ref{fig:AS:overview} represents an overview of the functionality that
the architecture must support. The illustration exhibits a user uploading a
file to the cloud, and adding this to a parent directory. After he has done
this, it is possible for him to distribute the capability to other users to
realize sharing of files or directories.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureOverview.pdf}
    \caption{Overview of user functionality}
    \label{fig:AS:overview}
\end{figure}

\subsection{File Storage}
\label{sec:AS:FS}

The solution for file storage proposed in this thesis, is that only a simple
\emph{key-value store} is needed on the server side. The key works as a lookup
index for a specific value, while the corresponding value equals an encrypted
file object. The server will be required to support the operations of uploading
and downloading key-value pairs to this store.

From the users perspective however, a file object can have multiple forms -- it
can either be a \emph{mutable} or an \emph{immutable} file. A mutable file can
be changed, and is what a user will see as a directory, while an immutable file
is utilized as a normal file.

A user will need certain information to be able to reach and read a file
object, we define these properties as the \emph{capability} of a file object.
For now, the capability represents the ability to find, read, verify that a
file has not been tampered with, and possibly write to the file object.

\subsubsection{Directory Structure}

The contents of a directory are files and other directories. More specifically,
a directory contains the means to find files or directories, namely the
capabilities of these file objects. In addition, there exist a human readable
name, an \emph{alias}, for each entry in a directory. This design gives a
flexible and space-conservative structure, since any file object may be found
from multiple directory, but does only exist once in the cloud.

A user will have to have some way of storing the capabilities of his file
objects. This could potentially be done client side, but a problem arises if
the user wants to use several terminals. Thus, we introduce the \emph{root
folder}, a folder from which all other files and folders can be reached. The
user will only need to know of one single capability to reach all his stored
data. This capability needs to be stored and protected by the client in a
password protected \emph{keyring}. The resulting structure is a
directed graph, as illustrated in Figure \ref{fig:AS:filesystem}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureFileSystem.pdf}
    \caption{File system structure}
    \label{fig:AS:filesystem}
\end{figure}

\subsection{ACL/Authentication Layer}

The possession of a capability gives a user access to read a file or read or
write a folder, and hence serve as the primary access control. There are
however some properties that the server provider might want that can not be
given by the capability. Therefore a layer implementing authentication,
accountability and possibly more access control could be preferable.

\subsubsection{Block Access to Encrypted Data}

The capability for a file or folder might be intentionally or unintentionally
leaked by a user. In this case, it would be preferable that the server can
block access to a particular object. The server could also potentially enforce
access rights on all encrypted objects, based on who a user has shared a file
with. This does however require the client to notify the server every time it
shares a file object with a new person, and is strictly not necessary from a
security standpoint.

\subsubsection{Modification and deletion of objects}

For each directory, there exist a different capability for read and write
operations, though the read capability can be deduced from the write
capability. From the write capability, it is possible to deduce another secret,
the \emph{write enabler}, which the server also knows of.  Knowledge of the
write enabler is needed for the server to grant access to modify or delete a
folder.

For immutable files, there is no concept of write-access, only read. It is both
illogical and impractical to assume that read access should also yield delete
access. A layer that identifies the creators of a file, can by the same method
decide who should have the rights to delete it.

\subsubsection{Accounting}

If the server side of the system is held by a cloud storage provider, it
is important to be able to decide which users should be billed for the file
\emph{storage} and generated \emph{network traffic}.

In the case of an immutable file, the storage costs can be billed to the user
creating the file. The costs of network traffic can further be charged to the
users retrieving the file.

Accounting might also be interesting for an organization using a third party
cloud provider. For instance an employee who leaves the organization, might be
tempted to copy all the data stored on the server. The organization should then
be able to discover what he has done.

It is however worth noting that if the accounting happens server side, there is
no real way to verify that all logs stored there are correct, since the cloud
provider will have access to modify or delete them.

\subsection{User Scenarios}

The various user scenarios supported by the software, provides a logical way to
describe the external properties of the system. The fundamental operations are
\emph{downloading}, \emph{uploading} and \emph{sharing} of files.

\subsubsection{Download File}

The download procedure is depicted in Figure \ref{fig:AS:download}. The client
sends a download request with the identifier of a folder, which he possesses
the capability of. The server will respond with the encrypted directory.
The user will use the capability to decrypt the directory.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureDownload.pdf}
    \caption{Scenario: Downloading a file}
    \label{fig:AS:download}
\end{figure}

In the directory, the user finds the aliases and necessary capabilities to gain
access to the children of that folder. If the user now wants to download a file
from the accessed folder, he obtains the identifier for this file through the
capability of the file, and requests the server for this file. Once downloaded,
the capability provides means of decrypting and verifying that the file has not
been tampered with.

\subsubsection{Upload File}

Figure \ref{fig:AS:upload} shows the process of uploading new files. The
capability for the new file is generated by the client, and used to encrypt the
file. The file is then uploaded to the cloud, and the capability and an alias
is linked in to the parent folder of the file.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureUpload.pdf}
    \caption{Scenario: Uploading a file}
    \label{fig:AS:upload}
\end{figure}

\subsubsection{Share Files}

As shown in Figure \ref{fig:AS:sharing}, for Alice to be able to share files
with Bob, she first has to create a new directory that will contain these
files. Alice is then required to share the capability of the new directory with
Bob. When the capability is shared, the new directory will work as a secure
channel where Bob and Alice can share their own folders and files.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureShare.pdf}
    \caption{Scenario: Sharing files}
    \label{fig:AS:sharing}
\end{figure}

Before transferring the capabilities to Bob, Alice links the shared directory
to a parent directory, so she can easily find it again at a later time. She can
also link files and other directories to the shared directory.

The capability distribution is a key design issue, and has to be performed in a
secure manner. This can be solved in a variety of ways, and the solutions
proposed in this thesis are discussed in Section \ref{sec:DI:keydist}.

After receiving the capabilities for the shared folder from Alice, Bob requests
and receives the encrypted shared directory, in addition to linking it with a
parent directory for future usage. He can then download shared files as if they
where his own.

\paragraph{Read-Only Shares}

If Alice wants to share a directory in Read-Only mode, she can simply share the
read capability with Bob, instead of the write capability. This will work as
intended, but might prove somewhat cumbersome for Alice. If Alice wants to
write to the directory she has shared with Bob, she can not enter it through
the parent folder shared with Bob, since this will only grant her the read
capability. The implication is that Alice will have to find the directory
another place in her directory tree, to get the write capability.

A more simple solution is to enable Alice to store the write capability
individually among her private files, while storing the read capability in the
shared parent directory. The solution can easily be implemented by using a
specialized \emph{write key folder} under Alice's root folder. The write key
folder will then contain write capabilities to every folder that Alice has
shared in Read-Only mode. The idea behind the write key folder is illustrated
in Figure \ref{fig:AS:readonly}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{ArchitectureShareReadOnlyFolder.pdf}
    \caption{Sharing write-protected folders}
    \label{fig:AS:readonly}
\end{figure}

\subsection{Constraints}

The software using this architecture should be able to run on restricted
devices, i.e. equipment with limited memory and \ac{CPU} power, often in
addition to constraints on power and network utilization.

This has implications for the design of the software, since all cryptographic
operations has to be performed client-side. These considerations will be
brought up throughout the further description of the software.

%**************************************%
\section{Cryptographic Architecture}
%**************************************%
\label{chap:CS}

This section elaborates on the cryptographic solutions applied to the
architectural scheme in Section \ref{chap:AS}. It will take a closer look at
how confidentiality and integrity can be integrated into the proposed
architecture.

We will start with a brief introduction explaining the fundamental security
concepts utilized by the cryptographic architecture. The cryptographic
architecture is further described in terms of file and directory operations.
Key concepts are based on equivalent operations found in the Tahoe-\ac{LAFS}
\cite{tahoe}.

\subsection{Security Concepts}

The basic security concept of the application is to keep the files of a user
confidential to a third-party storage provider. To solve this, the application
encrypts files locally at the user's terminal before uploading them to the
third-party storage provider.

When accessing a file, the application first downloads the encrypted file
before decrypting it locally. To enable this simple encryption scheme, a user's
terminal is required to locally possess the knowledge of at least one
capability, which contains cryptographic keys to decrypt and verify the
contents of the \emph{root folder}.

The root folder will in turn contain the capabilities for its own children,
which enables the client to decrypt files and folders stored in the root
folder. The other folders work in the same manner.

By initially knowing that files are placed encrypted on a remote server and
that the user possesses one or more cryptographic keys locally, we can continue
with a more comprehensive description of the complete cryptographic solution.
The details are explained in terms of capabilities and the operations conducted
on files and folders.

\paragraph{Capabilities} Capabilities are containers which contain the
necessary information to locate, encrypt, decrypt, verify and possibly write
file objects. The contents is summarized in Table \ref{tbl:capability}, and
will vary somewhat for files and folders, since they are implemented by
respectively immutable and mutable files.

\input{tables/capability.tex}

\paragraph{Encrypted Keychain} Every user will need to keep a copy of his root
capability somewhere. The capability contains both an encryption key and
verification data that a user will need to safely access his files.

This amount of random data will be hard for a person to remember, and therefore
the capability will have to be stored on the terminal which runs the client
software. Since it might happen that this terminal is either broken in to,
lost or stolen, precautions should be taken to protect the capability on the
device. The normal approach to this, is by using password protection.

The strength of a password is related to its length and randomness properties.
Passwords shorter than 10 characters are usually considered to be weak
\cite{pbkdf_nist}. In the event of loosing one of the clients, and thus the
encrypted keychain, a potential attacker can use fast password cracking attacks
to try to compromise the root folder keys. As an precaution for this, we will
use \ac{PBKDF2}/RFC2898\footnote{http://tools.ietf.org/html/rfc2898} with a
salt value, to create additional computational work for the process of
unlocking the keychain. This method is known as key stretching
\cite{keystretch}.

\subsection{File and Directory Operations}
\label{sec:CS:DO}

This section describes the elementary file and directory operations supported
by the application. The basic file operations are \emph{upload file} and
\emph{download file}, and correspondingly for directories, \emph{create
directory} and \emph{open directory}.

For simplicity, the illustrations in the following sections includes naming of
cryptographic primitives. However, it is important to note that this
cryptographic scheme will work with other primitives. Any symmetric cipher
could work instead of \ac{AES}, any signing function that uses both a private
and public key could be used, any \ac{MAC} could be used instead of
HMAC-\ac{SHA}1, and any cryptographic hash function could be used instead of
\ac{SHA}-256.

Though, the security of the system does rely on these choices, and a
recommendation with rationale for each of the needed primitives will be given
in Section \ref{sec:cryptoprimitivechoice}.

\subsubsection{Upload File}
\label{sec:CS:CF}

The operation behind uploading a file, is depicted in Figure \ref{fig:CS:CF}. A
random symmetric encryption key is generated. This is hashed once to obtain the
\emph{storage index} for the file. The storage index is then hashed again to
form the \ac{IV} for the file.

Next, the file is hashed and the resulting digest is stored together with the
encryption key in the capability. Lastly, the file is encrypted with the
encryption key and the \ac{IV}, and is transfered to the server.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{CryptoCreateFile.pdf}
    \caption{Behind the scenes: Uploading a file}
    \label{fig:CS:CF}
\end{figure}

\subsubsection{Download File}
\label{sec:CS:OF}

The process of retrieving a file is illustrated in Figure \ref{fig:CS:OF}. The
storage index is obtained by hashing the stored encryption key extracted from
the capability, and the \ac{IV} is obtained by hashing the storage index. The
file is then downloaded from the server and decrypted. Next, the file is
hashed, and the resulting digest is compared against the digest stored in the
capability. If these two match, the file has not been tampered with.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{CryptoOpenFile.pdf}
    \caption{Behind the scenes: Downloading a file}
    \label{fig:CS:OF}
\end{figure}

\subsubsection{Create Directory}

Creating and uploading a directory from the user terminal, is illustrated in
Figure \ref{fig:CS:CD}. The process is a bit more complex than for files,
because it has to support changing the contents of the folder.

\begin{figure}[h!]
    \centering
        \includegraphics[width=\columnwidth]{CryptoCreateFolder.pdf}
	    \caption{Behind the scenes: Creating a directory}
    \label{fig:CS:CD}
\end{figure}

Firstly, an asymmetric key pair is generated, and forms the private
\emph{signing key} and the public key. The signing key is hashed to form the
\emph{write key}, and again to form the \emph{read key}, and even once more to
form the \emph{storage index}.

The contents of the folder, which may be empty, is encrypted with the read key
and the resulting ciphertext is signed with the signing key. The signing key is
further encrypted with the read key, and together with the ciphertext, the
public key, the \ac{IV} and the signature, uploaded to the server.

The \emph{write enabler} is made from the write key with a \ac{MAC} function
and sent alongside the file. The write key is stored together with a hash of
the public key in the capability.

\subsubsection{Open Directory}

Opening a directory involves both downloading, verifying and decrypting the
directory. The verification illustrated in Figure \ref{fig:CS:VOD} and
decryption is illustrated in Figure \ref{fig:CS:OD}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{CryptoVerifyOpenFolder.pdf}
    \caption{Verifying a directory}
    \label{fig:CS:VOD}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{CryptoOpenFolder.pdf}
    \caption{Decrypting the contents of a directory and obtaining the signing
    key}
    \label{fig:CS:OD}
\end{figure}

From the capability, the user either obtains the read key or the write key. If
the write key is found, it can be hashed to obtain the read key. The read key
is again hashed to form the storage index, which is used to request content
from the server.

From the server, the user receives the encrypted contents of the folder, the
signature for the folder and the public key. The user verifies that the public
key is correct by hashing it and matching it against a hash stored in the
corresponding capability. Afterwards, the public key is used to verify the
signature. If both these checks pass, the folder is decrypted with the
read key and the content is obtained.

\subsubsection{Modify Directory}

In addition to read the contents of a directory, the user might want to write
to it as well. The process of doing this, is similar to initially creating the
first directory. The key difference, is that the user has the write key in a
capability, and must use this to decrypt the encrypted signing key which he
downloads from the server, instead of generating a new one.
% TODO: Is the sentence above making any sense?

A new \ac{IV} is generated, and the content of the folder is encrypted, and
signed by the signing key. The fresh \ac{IV}, the signature and the encrypted
contents are then uploaded to the server. The write enabler is also sent
alongside, which is deduced in the same way as when creating a new folder.

\subsection{Recommendations for Cryptographic Primitives}
\label{sec:cryptoprimitivechoice}

For the proposed cryptographic scheme to be secure, it needs secure
cryptographic primitives. More specific, it needs a symmetric cipher, a
cryptographic hash function, a \ac{MAC} function, a key stretching function,
and a function for digital signatures, as found in Figures \ref{fig:CS:CF},
\ref{fig:CS:OF}, \ref{fig:CS:CD}, \ref{fig:CS:VOD} and \ref{fig:CS:OD}.

These primitives needs to be set in accordance with the security requirements
established in Section \ref{sec:criteria}. Additionally, the hard part of
selecting appropriate cryptographic primitives, is trying to predict for how
long the primitives will be secure. \citet{keylength} compares studies listing
predictions on how long primitives will be secure based on different sources
with different predictions.

% TODO: finn ut hvordan vi skal liste kilder her

% Poeng: Det skal være trygt lenge nok
% For filer: Vi bruker hver nøkkel 1 gang
% For mapper: Vi bruker hver nøkkel flere ganger, men forskjellig IV
% CBC > CTR fordi det er "enklere å implementere"
% "Med blokker på 128 bit får man aldri 128 bit sikkerhet

% AES key length, keylength.org, Ecrypt II. AES 128 er bra nok, men viktig at
% man kan endre det. AES-256 dersom vi skulle gått kommerst

% Viktige ting
% Alle IVer brukes bare 1 gang (per nøkkel)
% Alle fil-nøkler brukes kun 1 gang
% Alle

% Nøkkellengde på SHA-256, og hva er poenget med konkatinering

% Framtiden: Quantum Computing, Moores law

% Hva er problemet om hva som blir knukket?

% SchneieR:
% AES-256 for å være sikker
% SHAd-++
% RSA: ??

\subsubsection{Symmetric Cipher}
% Argumentasjon skal kanskje være delvis i background
\defcitealias{ecrypt2_2010}{ECRYPT II}

For a symmetric cipher the choice is pretty simple -- \ac{AES}. \ac{AES} is the
NIST standard for symmetric encryption and is readily available in most
programming languages. We have chosen a key size of 128-bit.
\citetalias{ecrypt2_2010} \cite{ecrypt2_2010} has one of the more pessimistic
predictions on how long this will be secure, saying data encrypted with this
key size should be secure until 2030-2040.

The gain of not choosing a larger key is a somewhat greater
performance -- \ac{AES}-128 is 10 rounds while \ac{AES}-256 is 14
rounds -- and of course that the keys are smaller to store.

\paragraph{Mode of operation} The mode of operation we have chosen is \ac{CBC}.
This is based more on practical advice than on security consideration.
\citet{schneier} advices the use of either \ac{CBC} or \ac{CTR} mode, where
\ac{CBC} mode is easier to implement correctly, while \ac{CTR} mode, at least
in theory, leaks the least information.

\paragraph{Padding} One negative consequence of using \ac{CBC}, is that it
requires that the plaintext is an exact multiple of the block length, i.e.
128-bit. Since this is not always the case, a padding scheme will be required.
A padding scheme does not have any security implications as long as it is
reversible \cite{schneier}, at least not for \ac{CBC}. We decided on
\emph{PKCS5Padding} in our implementation, based on its existence in the
cryptographic libraries we utilized.

\subsubsection{Cryptographic Hash Function}

The \ac{SHA}-family is the current standard for cryptographic hash functions,
and from this we chose double \ac{SHA}-256. The cryptographic scheme requires
the hash function to have an output of at least the size of the key used for
encryption. The \ac{SHA}-1 has an output of 160 bits and could have been used,
but more and more attacks are discovered (e.g. by \citet{sha1}) and are not
recommended for use in new systems. The use of double \ac{SHA}-256 compared to
single, is to prevent a length-extension attack \cite{schneier}.

\subsubsection{Signature Algorithm}

For a signature scheme, the standard seems to be either \ac{RSA} or \ac{DSA}.
Both functions would work, but we went with \ac{RSA}, primarily because
Tahoe-\ac{LAFS} made the same choice.

There might however be a performance bonus in selecting \ac{RSA}. An internet
draft \cite{dsa_sha2} suggests that \ac{DSA} is about three times faster than
\ac{RSA} at signing, but \ac{RSA} is about ten times faster at verifying a
signature. A performance comparison from \citet{msdn_perf} suggest that
\ac{DSA} is 29\% faster at signing and \ac{RSA} is 29\% faster at verifying
signatures. Verification, in the form of opening a folder, is an operation we
believe most users will do significantly more than signing, updating and
creating folders.

For the key length we have implemented 1024 bit, but in retrospect this is a
bad choice. All sources at this point recommends at least 2048 bit.
%TODO FIX KILDE

\subsubsection{\ac{MAC}}
The use of the \ac{MAC} function in \ac{CSV} is somewhat special. The
definition states that MAC function is used for authenticating messages.  As
depicted in Figure \ref{fig:CS:CD}, the result of the \ac{MAC} function is
another key. By presenting this key, a user verifies \emph{to the server} that
he is in posession of the write key for a folder and thereby his is
authenticated and authorized to change the folder contents. The main difference
between the ``normal" use of a \ac{MAC} is that the user will always present
the same \ac{MAC} for the same folder.

Because of the usage of the \ac{MAC} as a simple key derivation function, the
most important factor to consider when choosing a primitive, is that it should
be infeasible to go from the result back to the origin key. On the basis of
this, \citet{schneier} recommend HMAC-SHA256.

\subsubsection{Password Based Key Derivation} 
\label{sec:PBKD}
To protect the secret that has to be stored on a users terminal our
recommendation is \ac{PBKDF2}. \ac{PBKDF2} makes a key that a user can remember
into a key which with greater resistance to brute force and dictionary attacks.
\ac{PBKDF2} has further been recommended by \ac{NIST} in \cite{pbkdf_nist}.
The salt that is used should be randomly generated and the length is
recommended by \ac{NIST} to be at least 128 bits long. The recommendation for
the iteration count 

\ac{NIST} recommends that the iteration count for \ac{PBKDF2} should be as long
as possible while at the same time maintaining acceptable
performance\cite{pbkdf_nist}. To come up with a secure recommendation, we
looked at the usage of \ac{PBKDF2} in WPA\footnote{WPA is a security protocol
for wireless networks} and what security it provides against brute force
attacks. WPA is an excellent measuring unit, since the utilization of
\ac{PBKDF2} is quiet similar to the one in our scheme. So far, the most
sensational brute force attack against WPA was published on Black Hat DC 2011
by a security researcher named Thomas Roth. He proved that anyone can crack WPA
passwords with a speed of up to about 400 000 passwords per second, using
multiple Amazon \ac{EC2} cluster \ac{GPU} instances \cite{rothwpa}. His
findings also indicate that Amazon them selves can reach an even higher unknown
brute force speed. The same researcher has also hinted that he might be able to
reach 1 million keys per second on the same equipment\cite{rothblog}.

The mayor difference between our scheme and WPA is that the necessary data to
launch a brute force attack in WPA can be sniffed by anyone with a wireless
device and with no risk. For our scheme one would have to get physical or
virtual access to it, which has a high risk. In the event that an attacker
obtains this access installing a keylogger or similar might be a better
approach than to try an attack on the encrypted keyring. But in the event that
the attacker is someone who steals or finds a lost device it will be his only
option. In this event it is however possible for the owner of the terminal to
simply replace his root capability with a new one to make the information that
the attacker can obtain almost harmless. There of course exist a theoretical
scenario where the cloud provider is actually the party which steals the
terminal, and can protect the server-side encrypted data.

With this in mind, we recommend at least the same amount of iterations
to be used in our scheme as in WPA, that being over 4000. This should deal
acceptable performance on most devices. However the strength of \ac{PBKDF2} is
not enough alone, if the password used is to weak.

\paragraph{Password requirements}

If we assume every password can only consist of the English letters, both
uppercase and lowercase, and the numbers 0-9, there exists 62\^n different
passwords for a password of length n. With Roths theoretical results of 1
million passwords per second this means that any password of length 6, 7 and 8
is cracked in about 0,66, 40 and 2527 days respectively. But this is the case
where the attacker finds a password on the last try, which is not plausible.
These results also only holds if we can guarantee that a user actually chooses
a random password, which is probably not true either. A more realistic setting
is that the attacker uses some dictionary, and that a users password is not
strictly random. By this rationale, it is more important to be safe than sorry,
and for password guidelines we therefore recommend:

\begin{itemize}
\item Password length >= 9.
\item Password must include at least one capital letter, one small letter and
one number.
\end{itemize}
%TODO: Reduce text!


\section{Server Implementation}

The server, in the most basic form, has to support two operations -- sending
and receiving files. In addition, an \ac{ACL} layer is needed to support user
management and access control to able to allow the deletion of files from the
server.

\subsection{Communication and Architectural Patterns}

By definition, cloud applications are accessible over the Internet. The system
we are creating, should be able to send and receive files and information from
a server in the cloud. The \acf{HTTP} is the foundation of data communication
for the World Wide Web, it is well tested, will pass through most firewalls and
has a multitude of libraries in programming languages. To get a working server
we can also use any existing web server as a foundation, which saves a lot of
work. Thus \ac{HTTP} was chosen as our communication protocol.

\subsubsection{\acs{REST}} The Web is built around an architectural style called
\ac{REST} \cite[ch. 5]{fielding}, which is defined by four interface
constraints: identification of resources, manipulation of resources through
representations, self-descriptive messages, and, hypermedia as the engine of
application state. In addition, \ac{REST} dictates five\footnote{And one
optional, Code on demand, which is not applicable for our system.} architectural
constraints \cite{fielding}. Our server application adheres to these
constraints or \emph{patterns} as follows:

\begin{description}
  \item[Client-server] \hfill \\
    The server is our server application, and the client is the various client
    applications,

  \item[Stateless] \hfill \\
    Since the server is just a simple key-value file store, it does
    not need to keep state.

  \item[Cacheable] \hfill \\
    The server could easily add caching, by putting each encrypted file in
    memory as downloaded, and using the Least-Frequently Used algorithm for
    choosing which items to swap out. In addition, for every update of a folder,
    the corresponding cache item has to be marked as invalid.

  \item[Layered system] \hfill \\
    Layers are used to encapsulate, separate and hide functionality.
    Figure \ref{fig:IM:layers} illustrates the layers of the server application.

  \item[Uniform interface] \hfill \\
    The interface between clients and server(s) are given by the URI scheme in
    Table \ref{tbl:IM:restinterface}. When a folder is uploaded a Write Enabler
    must also be provided together with the storage index..
\end{description}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{ImplementationServerLayers.pdf}
    \caption{Architectural layers in the server application.}
    \label{fig:IM:layers}
\end{figure}

\begin{table}[h!]
    \centering
    \caption{The \acs{REST} interface of the server application.}
    \begin{tabular}{|l|l|}
        \hline
        \multicolumn{1}{|c}{\textbf{\acs{URI}}} & \multicolumn{1}{|c|}{\textbf{Description}} \\
        \hline
        \texttt{/put/<storage index>} & Creates or updates encrypted file \\
        \hline
        \texttt{/get/<storage index>} & Retrieves encrypted file \\
        \hline
    \end{tabular}
    \label{tbl:IM:restinterface}
\end{table}

In this context, resources are the encrypted files, and the architectural
constraints of \ac{REST} also matches that of our system as a
whole. Thus, the server application are designed in a \acs{REST}ful manner.

\subsubsection{Network Security} Since we are utilizing \ac{HTTP}, we can
easily add an extra layer of \ac{TLS} to form \ac{HTTPS}. This makes it more
difficult for potential attackers to intercept messages, and also provides
protection against the most basic form of \ac{MITM} attacks. It also provides
protection against eavesdropping, which would have revealed the Write Enabler
for folders and could be used by an attacker to delete user files. The top-most
layer of Figure \ref{fig:IM:layers} thus refers to \ac{TLS}.

\subsection{Environment}

The Python programming language in a Linux environment was chosen as development
platform, together with a set of applications, interfaces and micro frameworks.
The rationale for each of these follows.

\paragraph{Python} Python is a high-level general-purpose programming language.
It was chosen due to previous knowledge and experience by the
authors, in addition to its simplicity.

\paragraph{Apache} The Apache HTTP Server is a well tested and used web
server. According to \citet{netcraft}, Apache is by far the most used web server
software, and has been so since 1996. It was chosen on the basis of previous
experience and its superb documentation.

\paragraph{\acs{WSGI}} The Python \ac{WSGI} is, as the name suggests, an
interface between a web server and a Python application. It is defined in
\ac{PEP} 3333\footnote{\url{http://www.python.org/dev/peps/pep-3333/}}, and
specifies both sides of the interface -- the \emph{application} and the
\emph{server}. The server side is implemented in the form of an Apache
module, namely \texttt{mod\_wsgi}, and the application is where we put our
code.

For each of the requests the server (i.e. \texttt{mod\_wsgi}) receives, a call
to the application function is made with two arguments -- a data structure
containing the environment variables, and a callback function for which the
application uses to return data to the requesting user via the server.

\paragraph{Pyroutes} To adhere to the \ac{DRY} principles, we chose to make use
of a micro framework around \ac{WSGI} called
Pyroutes\footnote{\url{http://www.pyroutes.com/}}. It provides shortcuts for the
most frequently used functionality when developing web services, as that of
\ac{URL} handling and processing of submitted user data in the form of
\texttt{GET} and \texttt{POST} requests.

Pyroutes did not, however, support the HTTP \texttt{PUT} request, so this was
implemented and contributed back to the project.

\subsection{Implementation Details}

The code was structured as illustrated in Figure \ref{fig:IM:layout}. The file
\texttt{handler.py} provides the interface for \texttt{mod\_wsgi} and the server
application, and basically includes the \ac{URL} scheme in
\texttt{fileserver.py}. An example \ac{URL} mapping is shown in Listing
\ref{lst:IM:get}. The function \texttt{get\_file} is registered to have the
\ac{URL} \texttt{/get} through the decorator provided by Pyroutes. After
retrieving the file from disk, a proper \ac{HTTP} response is returned,
containing required headers.

The file \texttt{filesystem.py} contains the low-level file system operations,
\texttt{save\_file()} and \texttt{retrieve\_file()}, together with a set of
helper functions to manage file access checking and database operations.  The
folder \texttt{sql/} contains \ac{SQL} code to create necessary tables in the
database, and \texttt{db.py} provides an helper function to connect to the
database.

\begin{figure}[h!]
\begin{verbatim}
|-- cloudstorage
|   |-- __init__.py
|   |-- db.py
|   |-- fileserver.py
|   |-- filesystem.py
|   |-- settings.py
|   `-- sql
|       `-- write_enablers.sql
|-- handler.py
`-- tests
    `-- filesystem_tests.py
\end{verbatim}
    \caption{Server module structure}
    \label{fig:IM:layout}
\end{figure}

\lstinputlisting[language=Python,breaklines=false,label=lst:IM:get, caption=URL mapping in fileserver.py]
{listings/fileserver.py}

\subsubsection{\acs{ACL} functionality}

The only \ac{ACL} functionality implemented, is the server-side verification
that a client has proper access to overwrite a file, e.g. when a client wishes
to update a folder with new contents. We call this \textbf{Write-Enabler
Verification}.

When a client first uploads a new folder, it also provides a
\emph{Write-Enabler Key}, which the server adds to the database along with the
\emph{Storage Index} of the folder.  For every subsequent request to write to a
file with this specific Storage Index, the server verifies that the provided
Write-Enabler Key is equal to that in the database.

If a client tries to put a file with a Storage Index that already exists, the
server replies with an error code if the client in addition does not provide a
valid Write-Enabler Key.

\section{Client Implementation - Android}

The \ac{PoC} client we have implemented, is made for devices using the Android
operating system, which is based on Linux. The \ac{SDK} for making Android
applications, is essentially a somewhat modified version of Java.

Most devices that use the Android operating system are mobile phones or
tablets, which implies that they are limited in terms of speed and
memory. The point of making the \ac{PoC} client for such a device, i.e. a
\emph{smart phone}, is the growing availability, and the flexibility these
devices provide. A user carries the device everywhere, it has a network
connections, and it is always on.

A nice side effect of developing on a smart phone platform, is that if the
software performs well on a constrained device, it will almost certainly also
have good performance on any faster device as well.

\subsection{Environment}

The \ac{PoC} client was made on the Android platform and written in the Java
programming language, together with a set of frameworks. The rationale for
these are as follows.

\paragraph{Android} The Android operating system is made by Google, and is most
commonly found on mobile phones and tablets. The platform choice of Android was
done based on hardware availability and familiarity with developing on the
platform and the programming language (Java).

\paragraph{Java} Java is a high-level, object-oriented programming language.
Applications written in Java runs in a \ac{JVM}, which implies that a Java
application can run on almost any device which has a \ac{JVM}.

The ``\ac{JVM}'' on Android is called \emph{Dalvik}, but it is strictly not a
\acl{JVM} as the bytecode on which it operates is not Java bytecode.
After the regular Java compiler has created the \texttt{.class} files, a Dalvik
tool transforms them to another class file format called \texttt{.dex}
\cite{dalvik}.

\paragraph{HttpComponents} Apache HttpComponents are a set of libraries for
\ac{HTTP} transport in Java. The part used in our client is called HttpClient.
Android incorporates parts of this client in its runtime environment. The use
of this library adheres to the \ac{DRY} principles.

\paragraph{\ac{JCA}} \ac{JCA} is an architecture for doing cryptographic
operations in Java. The architecture is based on principles of implementation
independence, implementation interoperability and algorithm extensibility.
Basically what this means, is that each implementation of the \ac{JVM} can have
different implementations of the cryptographic primitives, but the developer
does not need to know which implementation is available.

\paragraph{ZXing Barcode Scanner} ZXing Barcode Scanner is a popular Android
application which can be used by other Android applications to both scan and
generate barcodes. By the use of this application, we adhere to the \ac{DRY}
principles, by not creating our own code to generate barcodes.

\subsection{Architectural Patterns}

\paragraph{Client-Server} It should be obvious that the client we have
implemented is the client part of the overall client-server pattern.

\paragraph{Pipe-and-Filter} The basis of the pipe-and-filter pattern is that
there exist a chain of processing elements, where the output of one element is
the input of the next element. We use this for file uploads and downloads to
limit the memory usage of the client, as well as to increase performance.

\paragraph{Asynchronous Pattern} We use asynchronous calls to slow operations
-- e.g. file upload and key generation -- extensively, to prevent the interface
from hanging and to deliver a smoother user experience in general.

\subsection{Implementation Details}
\label{sec:cli:impl:det}

\subsubsection{Structure}
% Package Structure, some nice UML (?)
% Which qualities do we wish to achive? Security, Performance, Usability

The source of our client is logically separated into two entities --
\textbf{CSVlib} and \textbf{CSVAndroid}. CSVlib is a pure Java library which
contain the necessary entities, cryptographic operations and communication
calls required for the client. CSVAndroid contains primarily a graphical user
interface to make use of CSVlib on an Android device.

\subsubsection{Cryptographic Entities}
\label{sec:cryptoentities}
All the cryptographic entities -- namely folders, files and capabilities -- are all
part of CSVlib. Their relationship can be seen in Figure \ref{fig:CSVlib:overview}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{csvobjects.pdf}
    \caption{Cryptographic entities and their relations}
    \label{fig:CSVlib:overview}
\end{figure}

\paragraph{Capabilities} Capabilities are containers for
cryptographic keys and information to identify a corresponding object. A
capability will contain information to identify an object as either a file or a
folder, and have the information to read, write or verify that object.

Capabilities are stored server side in folders, in it's serialized form shown
in Figure \ref{fig:CAP:serial}. \emph{Object Type} specifies if the capability
represents a file or a folder, with values \emph{F} or \emph{D}
respectively.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{CapabilitySerialization.pdf}
    \caption{Serialized form of a capability}
    \label{fig:CAP:serial}
\end{figure}

\emph{Key Type} specifies the permissions the key will grant on the object and
can be either \emph{RO} (Read Only), \emph{RW} (Read and write) or \emph{V}
(Verify).

The different parts are separated by the character \textbf{:}. The key and
verify string are encoded in Base32, which means that the 128 bits these
strings are represented by, will be replaced by an alphabet of 32 different
symbols, namely A-Z and 2-7. This transformation will give some overhead in
storage and transfer (26 bytes compared to 16), but makes it possible to read for a human
with few mistakes or misunderstandings.

\paragraph{Folders}

A folder is represented by the class \textbf{CSVFolder}. A CSVFolder object is
a collection of aliases and their corresponding capabilities. For
the most part, the data stored in a folder is so small that it can easily live for
as long as needed in the memory of the client.

When a folder is created or updated, the content is serialized and encrypted,
before it is uploaded to the server directly from memory. The serialization for
each item in a folder is simply \textbf{alias;capability}, where the capability
itself is also serialized.

\paragraph{Files}

A file is represented by the class \textbf{CSVFile}. While a folder in general is small,
a file can be of any size, even larger than the space the \ac{RAM} on the
device itself represents.

To keep the memory footprint low, we use the pipe-and-filter architectural
pattern to stream data all the way from the cloud to the disk, or vice versa,
through encryption and verification.

An example of how we do this for uploads is shown in Listing
\ref{lst:inputstream}.

\lstinputlisting[label=lst:inputstream, caption=Pipe and filter upload of a file]
{listings/fileupload_example.java}

The \emph{InputStreams} are chained together, with the effect that a read from
\emph{readBuffer} will trigger a read trough the whole pipe. The
\emph{DigestInputStream} will update the state of the hash function, but is
transparent in the sense that whatever goes into the stream will also be what
comes out. The \emph{CipherInputStream} on the other hand, will output an encrypted
stream of the data from the file. Buffers are placed between each step of the
stream for some performance increase.

\subsubsection{Communication with Server}
% Do not repeat what is said in Server equivalent section
% Apache commons, Serialization of objects

For \ac{HTTP} transport we utilize the Apache Software Foundations
HttpComponents Client\footnote{ \url http://hc.apache.org/} also known as
HttpClient.

This Client offers support for authenticated requests to a server, and both
upload and download through \textbf{PUT} and \textbf{GET} requests respectively.
We wrap communication with the server in two classes,
\texttt{Communication.java} and \texttt{CSVFileManager.java}.
\texttt{Communication.java} provides functionality for sending and retrieving
data from our server, while \texttt{CSVFileManager.java} provides specific
methods for sending and receiving the encrypted objects, CSVFile and CSVFolder.

\subsection{Sharing}
% Sequence Diagram - How we use the cryptographic solutions (and which ones) to
% achieve sharing, securely

A \emph{shared folder} is basically just a folder object which two or more
people have the required encryption keys for.

The problem of creating a share with someone, is that you have to verify that
you are actually sharing with the correct person. The data, or \emph{secret},
that will have to be shared, is a serialized form of the capability of the
shared folder, as shown in Figure \ref{fig:CAP:serial}.

The client supports two methods of doing this. The most cumbersome
is having to manually copying the key from one users client to another, and
afterwards verifying that the key for the selected folder is correct. An example
of this can be seen in Figure \ref{fig:CSVAndroid:manualimport}. This feature
is also needed to support out-of-band methods for establishing a share.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-manualimport.png}
    \caption{Establishing a share by copying the key}
    \label{fig:CSVAndroid:manualimport}
\end{figure}

The other possibility is to make use of a \emph{\ac{QR} code}, which is a matrix
barcode that can store information. What this means is that one user will
generate a barcode on his device, and the other user can scan that code using
the camera on his device. Figure \ref{fig:CSVAndroid:barcode} illustrates how
this code will look. The barcode contains both the key and the verification for
the shared folder. Once two users have shared a folder once, that folder can be
used for all future shares, which means that the two people will never have to
meet and do the capability exchange again. The identity has thus been verified.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-barcode.png}
    \caption{Establishing a share by using barcodes}
    \label{fig:CSVAndroid:barcode}
\end{figure}

\subsection{Adding a New Client}

Using more clients, or different devices, is almost the exact same as sharing,
and is solved in the same manner. The only difference is that the capability
that needs to be transfered, is that of the \emph{root folder}. It is also
possible to take any other folder and use as a new root for the new client if
that is the users wish.

\subsection{Securing the Client}

For a user to access his root folder, the client will have to know the
capability of that folder. This is clearly to much for a user to remember, so
the capability will have to be stored on the client. However, the client might
be stolen or broken into by some means, and if the capability is stored in
clear text, it is easily stolen.

We partially remedy this by the use of the \ac{PBKDF2} algorithm, which makes
an encryption key from a password. This generated key is used to encrypt the
root capability in a file stored on the client. We call this the encrypted
keyring.

\subsection{User Interface}
% goal: As easy as possible!
% First start: Generate new cap/import an old one (Adding a new client section)
% Browsing remote file(s)/folders
% Sharing a file - first/following times - Key Distribution
% Uploading/Downloading file

We have tried to make a user interface that is easily understandable by a
novice user, both in terms of \emph{where to click} and in terms of how we name
cryptographic operations. For instance we never use the word \emph{capability}
in the client.

\paragraph{Main Screen}

The main screen of the application is shown in Figure
\ref{fig:CSVAndroid:mainscreen}. However, before the user gets to this screen,
he will have to unlock his local keyring with his password. If it is the first
time the user starts the application, he will have to enter his online
credentials, and gets a choice to either import an existing root folder, or to
generate a new one. In both cases the user will have to choose a password to
encrypt the root capability in to the local keyring. From the main screen the
most common action would be to \emph{Browse the vault} -- in other words to see
the files that the user has stored in the cloud.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-mainscreen.png}
    \caption{Main screen of the client application}
    \label{fig:CSVAndroid:mainscreen}
\end{figure}

\paragraph{Browse the Cloud}

The interface for browsing the files stored in the cloud is made in what we
understand as a common and understandable way of interpreting users actions on
the android platform, and can be seen in Figure
\ref{fig:CSVAndroid:remotebrowse}. Tapping a file will download that file, and
tapping a folder will open that folder.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-remotebrowse.png}
    \caption{Browsing the cloud storage from the client}
    \label{fig:CSVAndroid:remotebrowse}
\end{figure}

An upload is treated in a similar way. To reveal this option, the user have to
press the \textbf{Menu}-button. The user will then be allowed to browse his
local file system for the file he wishes to upload, and tapping that file will
start the upload.

A long press on a file, or a folder item, will reveal the context menu shown in
Figure \ref{fig:CSVAndroid:remotecontext}. The least understandable action is
probably \emph{Unlink}, which remove a file or a folder from the parent folder.
The reason why it says unlink and not delete, is that a file can potentially be
linked in a number of different folders, and it is impossible by our design to
reveal which folders the file has been linked to, except the one that we are
unlinking from.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{client-browsecontext.png}
    \caption{Context menu showing actions available for items stored}
    \label{fig:CSVAndroid:remotecontext}
\end{figure}

%**************************************%
\chapter{Experimental Procedure}
\label{ch:experimental}
%**************************************%

This chapter will explain the experimental procedures performed on the Cloud
Storage Vault. It will start by explaining the measurements on the performance
of the application. The performance is further compared to similar existing
network applications. Finally, the chapter will go through the experimental
procedures taken to measure the security of the weakest link in the cryptographic
scheme.

The security of the weakest link is measured by attacking the encrypted keyring
stored by the cryptographic scheme. It is important to mention that it is the
keyring pass phrase that is utilized during the attacks rather than the employed
cryptographic primitives. Recall from Section \ref{sec:cryptoprimitivechoice} that the
cryptographic primitives are considered secure. 

\section{Performance}

We have tested the android client on two Android smartphones, an HTC Desire and
an HTC Hero. We have also tested the Java libraries on a desktop computer. The
specifications for HTC Desire can be seen in Table \ref{tbl:device:desire}, for
HTC Hero in Table \ref{tbl:device:hero}, and the desktop computer in Table
\ref{tbl:device:computer}. We emphasis that the measurements are meant to be
taken as indications of the performance of the scheme and implementation and
not exact measurements. We also emphasis that the Android measurements are our
main objective, since that is what the client is primarily

\input{tables/exp_desire.tex}
\input{tables/exp_hero.tex}
\input{tables/exp_computer.tex}

\subsection{What is Measured}

The construction we use to encrypt, hash and upload \emph{files} is a pipeline
as described in Section \ref{sec:cryptoentities}. The interesting thing to
measure is the overall speed of the pipeline compared to a simple file upload
with no extra operations such as hashing and encryption. To try to pinpoint the
exact bottlenecks in the pipeline we also measure the bandwidth we get from
each of the operations in the pipeline on one of the Android devices, the HTC
Desire.

\emph{Folders} are relatively small in size, and the implementation is not a
pipeline. Compared to files, the heavy operations are done client side before
the content is uploaded to the server. We therefore measure the speed of these
operations, more specifically we measure:

\begin{enumerate}
    \item The average time it takes to create a folder (initial key generation)
    \item The time it takes to encrypt and sign a folder, with varying amount
        of data
    \item The time it takes to verify a newly downloaded folder, with varying
        amount of data
    \item The time it takes to serialize a folder, with varying amount of data
\end{enumerate}

\subsection{How we Measure}

To test the bandwidth of the pipeline for files, we measure the incoming
traffic to our server using the tool \emph{nload}\footnote{
\url{http://www.roland-riegel.de/nload/}} during a file upload.  We measure the
average bandwidth from a few seconds after the file upload has been started,
until the file upload is nearly complete. Granted this does not take overhead
such as the initial key generation into account, but for any file of some size
this overhead should be neglectable.

% TODO: neglectable slår ut i stavekontrollen min!

To test the different folder operations we have to measure in the program code,
we do this by the use of the Java function
\emph{System.currentTimeMillis()}
\footnote{\url{http://download.oracle.com/javase/6/docs/api/java/lang/System.html\#currentTimeMillis()}},
which we call before and after an operation and calculate the difference. When
we test operations that are dependant on the contents of a folder we do this
with folder entries of 86 Byte.

\subsection{Eliminating Bottlenecks on Android Devices}

On the Android devices, we identify three possible bottlenecks that we might be
able to control: The \emph{network}, our \emph{application} by itself and the
\emph{memory card}.

The mobile phones will normally obtain their network connection through a
wireless protocol that varies naturally in throughput, e.g. \ac{UMTS}. While
these protocols work just fine, from a measurement standpoint, we want to have
a fast and stable connection. Our solution was therefore to connect the Android
devices to the test computer, and use the computers network through the
\ac{USB} interface.

Another bottleneck, might be the memory card. The \emph{class} of a memory card
will identify the least sustained write speeds obtainable from the card in a
fragmented state \cite{sdcard}. The class number $X$ represents this guarantee
in $X$ MB, so a Class 2 card guarantees a speed of 2 MB/s. However, there are
the possibility that the card can perform significantly better than what the
class number indicates.


\subsection{Sources of Error}

The trouble with measuring performance on operations that are relatively quick,
is that they are very vulnerable to \emph{noise} from the system. The Android
system comes with a lot of built-in services that runs sporadically, and hence
affect the measurements. However, the small and quick operations are not
necessarily facinating to measure -- the interesting behaviour to observe is
how their performance is affected when the amount of data is increased. The
goal of the client is to deliver a quick and smooth experience for the user.

We cannot explicitly tell what the speed of either the network nor the memory
card are, and this is thus another error source. But by comparing the speed for
file operations in \ac{CSV} with the modified version without encryption and
hashing, we should get an indication about how quick the software can be.

\section{Security}
\label{sec:BFLK}

The locally stored and encrypted keyring can be considered a security risk if
it somehow ends up in an attacker's hands, either by a device being lost or by
an intrusion in to a device. Even though the keyring is encrypted, it might be
prone to a brute force or dictionary attack. If an attacker is able to decrypt
the keyring, he will obtain enough information to access a user's root folder,
and thus all the other files stored by the user as well.

When considering brute force attacks, it must be emphasized that it is the
user's password, indirectly encrypting the keyring, that is the target weakness.
Brute forcing the 256-bit AES encryption key directly will be very inefficient
as it involves a key space of $2^{256}$ keys. The possibility of dictionary
attacks would additionally disappear, as the encryption key is generated in a
pseudo random manner.

This section describes our approach to attack the keyring.

\subsubsection{Keyring Format}

The format of the encrypted keyring is given in Figure \ref{fig:KeyringFormat}.
It is encrypted with 128-bit \ac{AES} in \ac{ECB} mode, but the key is not
randomly generated. The key is given by the key strengthening function
\ac{PBKDF2}, but this is based on a password set by the user, which is why this
key is potentially weaker than the keys for files and folders.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{KeyringFormat.pdf}
    \caption{The keyring format with encrypted fields shaded in blue}
    \label{fig:KeyringFormat}
\end{figure}

An attacker will also know some of the plaintext of the keyring. The
serialization of a capability for a writeable folder will
start with \texttt{D:RW:}, followed by 16-byte of Base32-encoded data, another
\texttt{:} and then 16 more bytes of Base32-encoded data.

\subsubsection{General Procedure}

To perform a brute force or dictionary attack on the encrypted keyring, one
must decrypt the keyring for each password guessed. The decryption involves
both key derivation with \ac{PBKDF2}, and decryption with 128-bit \ac{AES} in
\ac{ECB} mode. The \ac{PBKDF2} is a function that can be used with a
varying number of iterations, with the purpose of having a customizable way for
users to increase key strength. Our attacks are tested on 500, 1000, 2000 and
4000 iterations.

%We verified a successful attack based on our knowledge of the
%serialization of the capability.

\subsubsection{Implemented Attacks}

We created two programs designed to crack the keyring password. The first
program, named \ac{BFDA}, was designed for a single computer, while the second
program, named \ac{CDA}, was created to perform attacks by a cluster of
cooperating computers.

Both use dictionary attacks, but the firstly mentioned is also capable of a
pure brute force attack. The source code and compiled \texttt{.jar} files for
both programs can be found in the attached CD-ROM. Implementation details are
given in Appendix \ref{ap:other}.

\subsubsection{Configuration}

\ac{BFDA} requires Java with the \ac{JCE} and Jurisdiction Policy
files\footnote{Policy files enables Java to use stronger encryption than what
is allowed by US export law.} installed. It also depends on Java being
configured to use Bouncy Castle as its primary \ac{JCE} provider. These
prerequisites are required because the keyring is encrypted using Bouncy
Castle, as this is used by default on the Android platform.

\ac{CDA} requires almost the same configuration as \ac{BFDA}, but naturally for
each node in the cluster. Additionally, the cluster must be configured with
Apache Hadoop.

The steps we performed to set up Java with Bouncy Castle and the Jurisdiction
Policy files, are as described by \citet{jce+bc}, and the guide we used for
configuring Apache Hadoop in a Cluster using Ubuntu Server, are made by
\citet{cluster}.

\subsubsection{Hardware Specifications}

The hardware specifications for the \acl{BFDA} are given in Table
\ref{tab:hwbf}. The \acl{CDA} was executed over a cluster of Amazon \ac{EC2}
instances, of type \emph{High-CPU Extra Large Instances}. The hardware
specification for a single instance, used in the cluster attack, is given in
Table \ref{tab:hwcda}.

\input{tables/hw_bf.tex}
\input{tables/hw_cda.tex}

\subsubsection{Running \ac{BFDA}}

The command used for executing a plain brute force attack with \ac{BFDA} can be
seen in Listing \ref{lst:bf}. The command for running a local dictionary attack
is seen in Listing \ref{lst:da}.

\lstset{label=lst:bf, caption=Running local brute force attack}
\begin{lstlisting}
$ java -jar BFDA.jar /path/to/keyring  \
    maximum_password_length number_of_threads
\end{lstlisting}

\lstset{label=lst:da, caption=Running local dictionary attack}
\begin{lstlisting}
$ java -jar BFDA.jar /path/to/keyring \
    /path/to/dictionary number_of_threads
\end{lstlisting}

\subsubsection{Cloud Dictionary Attack with \ac{CDA}}

The cluster attack was carried out by 20 of the previously specified Amazon EC2
nodes. One instance was configured as both a Hadoop \emph{master} and
\emph{slave} node, while the 19 other instances were configured as slaves.
This was done to utilize as much as possible out of the available nodes, as the
master node performs quite a bit less computational work than the slave nodes.

Multiple scripts are needed to initiate the distributed attack.
The commands executed to start the Hadoop master and slaves, and mount up the
shared, distributed file system \ac{HDFS}, are shown in Listing
\ref{lst:hadoop}. The final command enables the Hadoop cluster to support
\emph{MapReduce}. This is necessary as the \ac{CDA} attack is implemented as a
map-reduce problem. Details about Apache Hadoop, MapReduce and the
implementation of \ac{CDA}, are given in Appendix \ref{ap:other}.

\lstset{language=bash, label=lst:hadoop, caption=Starting Hadoop Cluster with HDFS}
\begin{lstlisting}
# Start HDFS and initialize master and slave nodes
$ /path/to/Hadoop/bin/start-dfs.sh

# Start a MapReduce cluster from the master node
$ /path/to/Hadoop/bin/start-mapred.sh
\end{lstlisting}

The last requirement, before executing the attack, is to copy the
desired dictionary file and keyring into the \ac{HDFS}. Copying files from the
master node to the \ac{HDFS} is done with the command shown in Listing
\ref{lst:cpHDFS}. The attack can then be started on the master node with the
command shown in Listing \ref{lst:CDA}.

\lstset{language=bash, label=lst:cpHDFS, caption=Copying files into HDFS}
\begin{lstlisting}
$ /path/to/Hadoop/bin/hadoop dfs -put /path/to/file \
    /path/to/file/in/HDFS
\end{lstlisting}

\lstset{language=bash, label=lst:CDA, caption=Executing the CDA Attack}
\begin{lstlisting}
$ /path/to/Hadoop/bin/hadoop jar /path/to/CDA.jar \
    /HDFSpath/to/dictionary /HDFSpath/to/output/file \
    /HDFSpath/to/keyring number_of_slaves \
    number_of_threads_per_slave
\end{lstlisting}

%**************************************%
\chapter{Results}
\label{ch:results}
%**************************************%

In this chapter we will present the quantifiable numbers retrieved when doing
the experimentation in Chapter \ref{ch:experimental}. This includes performance
measurements of the proof of concept client, and figures on the attacks
presented, that target the local keyring.

\section{Client Performance}

This section presents the results of the benchmarking of the proof of concept
client, and highlights the most important results.

\subsection{Files}

The following results shows the network speed obtained when uploading and
downloading files. Table \ref{tbl:files:encrypted} shows the speed when using
the \emph{unmodified} client, while Table \ref{tbl:files:unencrypted} shows the
speed obtained when using the same client, but with \emph{encryption and
hashing disabled}. Table \ref{tbl:desire:pinpoint} shows the speed of the
individual, isolated operations in the process pipeline on the HTC Desire.

\input{tables/performance_files.tex}
\input{tables/performance_files_unencrypted.tex}
\input{tables/result_desire_pinpoint.tex}

We observe that the performance of the Android devices for uploads is severely
lower for uploads than for downloads, and that this is not the case for the
computer client. We also observe that the speed with encryption and hashing
disabled, is severely higher for all three devices. From the individual
results for the HTC Desire, we identify that the encryption and decryption
part is the most time consuming operation.

\subsection{Folders}

Table \ref{tbl:folder:createblank} shows the average time it takes to create an
empty folder on the different devices. The Tables
\ref{tbl:folder:serializefolder} and \ref{tbl:folder:encryptsign} shows the
respective time it takes to serialize, encrypt and sign the folder. These three
actions are what has to be performed every time a folder is changed, while the
operation of creating a blank folder is added if the content should be added to
a new folder. Table \ref{tbl:folder:verify} displays the time the devices used
to verify an existing folder, a step which is taken by the client every time a
folder is opened. Results noted as \emph{N/A} for the HTC Hero, is operations
that lead to an \emph{Out of Memory} exception during execution.

\input{tables/result_perf_createblankfolder}
\input{tables/result_perf_serializefolder}
\input{tables/result_perf_encryptsignfolder}
\input{tables/result_perf_verifyfolder}

We observe that the slowest part of folders operations are the initial key
generation and more important, the serialization speed. Verification,
encryption and signing is pretty fast for all devices. We also note that our
implementation struggle to handle folders with a certain amount of items on the
HTC Hero.

\section{Brute Force Local Keyring}
\label{sec:R:BFLK}

In Section \ref{sec:BFLK}, we tried to brute force the locally stored keyring,
by implementing and executing two different programs. The first program, named
\acf{BFDA}, was designed to run on a single computer, and supports both brute
force and dictionary attacks. The second program, named \acf{CDA}, was created
to run in a computational cluster. As the name implies, the \ac{CDA} attack
does only support dictionary attacks. The results for both programs are given
in the following sections.

\subsection{Brute Force and Dictionary Attack (BFDA)}

With \ac{BFDA}, we executed both a brute force and a dictionary attack to
estimate the amount of passwords we could test during the course of a second.

The brute force and dictionary attacks achieved approximately the same results,
although the brute force attack turned out to manage about 30 passwords more
per second than the dictionary attack. A cause of this, might be due to the
file reading overhead in the dictionary attack. 

The results for both attacks are illustrated in Table \ref{tab:res_bf}. Results
are given for different numbers of \ac{PBKDF2} iterations, in the matter of
passwords per second. Figure \ref{fig:bfres} exhibits these numbers in the form
of a histogram.

\input{tables/res_bf.tex}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.55]{bf.png}
\caption{Results from running brute force and dictionary attacks against encrypted keyring.}
\label{fig:bfres}
\end{figure}

Figure \ref{fig:bfres} indicates that by doubling the number of iterations in
\emph{PBKDF2}, the efficiency of a brute force attack would decrease by half of
its value.

Using 1000 iterations in \ac{PBKDF2}, as recommended by \citet{pbkdf2std}, the
brute force attack was able to reach a speed of around 1800 passwords per
second. With this speed, it will take, in average, 24 hours to crack a password
with a length of 6 characters, consisting of only small letters.

\subsection{Cluster Dictionary Attack (CDA)}

When running \ac{CDA}, each node of the cluster achieved approximately the same
results as a single computer running a dictionary attack with \ac{BFDA}. We
found that there was a small difference where the local computer achieved about
100 passwords per second more, compared to an instance in the cluster. This was
expected, with respect to the difference in \ac{CPU} power between the local
computer and a single cluster instance \cite{cpubench}. 

With 20 nodes in the cluster, we were able to test around 35 000 passwords per
second, given \emph{PBKDF2} with 1000 iterations. Running the \ac{CDA} in a
cluster of 200 nodes, would further reach a speed of 350 000 passwords per
second. The latter case would in average use about 7 minutes and 20 seconds to
crack a password with a length of 6 characters, consisting of only small
letters.

At the time of writing, renting a single \emph{Amazon EC2 high-CPU extra large}
instance costs 0.68 USD per hour. This unit price results in an hourly cost of
13.6 USD and 136 USD for clusters of 20 and 200 instances respectively. 

%**************************************%
\chapter{Discussion}
\label{ch:discussion}
%**************************************%
%\section{Complexity}
% Hvordan vi lagrer filer
% Lagring av nøkler
% Hvordan direktorier fungerer
% Hvordan vi deler

%Vår løsning VS relatert research og existing solutions

%\subsection{Keys}
%Type of keys, what distribution scheme was chosen
%\subsection{Files}

%\subsection{Folders}

%\subsection{Sharing}

\section{Cryptographic Scheme}
%What is/is not used from TAHOE?

In this section, we will go through the cryptographic scheme produced and
described in Section \ref{chap:CS}. The influence of Tahoe-\ac{LAFS} is
described in detail, followed by subsections scrutinizing how the scheme does
or does not support various features and functionality.

\subsection{Influence of Tahoe-LAFS}
%TODO: This subsection lacks the 'why' questions (and answers!)

The general idea behind the development of the cryptographic scheme, was that
we would use the scheme of Tahoe-\ac{LAFS} as a basis, and simplify it where
possible. One of the primary design goals was to make it easy to
understand and therefore simple to accept the security features.

\paragraph{Capabilities} The term \emph{capability} is directly based on that
found in Tahoe-\ac{LAFS}, as it is a good descriptive name for what it is. The
possession of a capability enables one to find, decrypt and verify the
integrity of a file or folder.

\paragraph{File Types} The concept of having two different file types, i.e.
\emph{mutable} and \emph{immutable} files, resembles that found in
Tahoe-\ac{LAFS}. The only use of mutable files in the \acl{CSV}, is for
implementing directories. By not allowing the users to generate mutable files,
the scheme is significantly simplified.

\paragraph{Key Generation} The process of generating keys for directories, as
described in Section \ref{sec:CS:DO}, are heavily based on the scheme of
Tahoe-\ac{LAFS}. By using the combination of symmetric keys derived from
asymmetric keys, the scheme supports safe sharing of folders in both read-only
and read-write modes.

\paragraph{Cryptographic Primitives} A significant design difference, is that
it is substantially more difficult to change cryptographic primitives for the
user in Tahoe-\ac{LAFS} than in \ac{CSV}.

\subsection{Sharing}
% Read/write keys, integrity, the general key distribution problem

One of the major advantages of \ac{CSV} over other cloud storage systems, is
the possibility to share files and folders in a secure manner. If the read
capability of a folder is shared, the user holding the write capability are
guaranteed to be the only one capable of making changes to the folder.

The server denies people with only the read capability to make changes to the
folder by the use of the \emph{write enabler}. The write enabler serves the
purpose of proving to the server that one holds the correct write capability.
If someone with access to the file system on the server, e.g. a cloud
provider employee, decides to make changes on a folder, the integrity check
will warn the user of this.

\paragraph{Key Distribution} The sharing of files and directories implicitly
deals with the general problem of key distribution. The cryptographic scheme
does not propose specific solutions for this, and leaves it up to the
implementation to choose the best suiting method in light of the specific
requirements. The procedure used in the proof of concept system developed, are
described in Section \ref{sec:DIS:impl}.

\subsection{Deletion of Files}

To support deletion of files, various alternatives has to be assessed.
Consider the following scenarios:

\begin{enumerate}
  \item A folder is shared between two users, and one of the users has
    linked in the files in other directories as well. What should happen if the
    other user deletes the files in the shared folder?

  \item A folder contains a folder which is a link to a folder ``higher''
    in the folder tree, and thus creating a loop. By deleting the folder,
    should all subdirectories be deleted as well, i.e. cascading delete?
\end{enumerate}

The choice of the alternatives presented shortly, are not taken by the proposed
cryptographic scheme, as it is merely a practical decision.

\paragraph{Creator/\ac{ACL}} The \ac{ACL} layer on the server could store the
username of the creator of the file along with each storage index, and use this
to decide who should be granted access to delete files.

\paragraph{Write Enabler} Similarly, the server could grant removal rights to
whoever provides the write enabler, in the same manner as when updating
folders. This requires that \emph{delete enablers} is produced for immutable
files as well as folders.

\paragraph{Link Count} The files could include a link count in its meta data,
updated whenever a user links or unlinks it from a folder. When the link count
reach zero, the user notifies the server to delete it.

\subsubsection{Loop Detection in a Directed Acyclic Graph}

In remedy of the problem of cascading deletion with loops, the system could
utilize an algorithm for finding strongly connected components of a graph,
before actually deleting any files.

Two components are strongly connected if there exist a path from $A$ to $B$,
and from $B$ to $A$, as depicted in Figure \ref{fig:DSC:cycles} where a
directory is linked in at a higher level in the directory tree. The dashed line
represents the actual path in the graph. If the folder $X$ is requested to be
deleted, the $Y$ directory will also be removed, and this is might not the
behaviour the user expected.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.6]{CyclesintheDAG.pdf}
    \caption{Theoretical cycle in the directory graph}
    \label{fig:DSC:cycles}
\end{figure}

\emph{Tarjan's Algorithm} \cite{tarjan} is an example of algorithm that can be
implemented to do this kind of check, and is basically a depth first search,
with a stack containing visited nodes.

\subsection{Verification of Files}

The verification scheme for immutable files is suboptimal in pretty much every
way a user wants to use an ordinary file, with the exception of the case where
the user wants the entire file and the file has not been tampered with.

The problem with the scheme, is that the user will have to download the whole
file, before he can verify by absolute certainty that the file is what it is
supposed to be. If it turns out that the file does not pass this check, and
the error was in the very first byte, the user has wasted time and bandwidth
downloading a lot of useless data.

If the file is a movie file, and the user only wants to look at a
small part of this file, this is not possible with the current verification
scheme. There is no way for the user to verify only parts of a
file, and he will have to download the whole file, which is suboptimal.

A possible solution to support this kind of streaming, would be to build a
\emph{hash tree} of the whole file, as shown in Figure \ref{fig:hashtree}. With
a hash tree, smaller bits of the file can be verified, and errors can be
detected earlier. The hash tree could be stored encrypted on the server
together with the ciphertext, and the capability could hold information to
verify the hash tree. The downside to this approach, is that performance would
be affected due to the substantial amount of hash operations required to
compute the hash tree. This idea of a hash tree is implemented in the
Tahoe-\ac{LAFS} \cite{tahoe}.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.55]{hash-tree.pdf}
\caption{Hash tree of a file}
\label{fig:hashtree}
\end{figure}

\subsection{Version Control System}

Some of the currently available cloud storage systems, as Wuala and Dropbox
mentioned in Section \ref{sec:existing}, support a kind of \emph{version
control} of the files stored. This means that the data lost during a
modification of a file are saved alongside the current file, so that the user
has enough information to restore the file to a previous state.  In practice,
this often mean to store multiple versions of the same file.  This could be
implemented in \ac{CSV} as follows.

\paragraph{Extension to Folders} By adding a nested list to the directory
structure exemplified in Section \ref{sec:cli:impl:det}, we can link previous
versions of a file in the serialization form:

\begin{quote}
    \centering
    \textbf{alias;capability;capability;capability}
\end{quote}

To make this feasible and user friendly, a time stamp would have to be added to
the capability.

\paragraph{Type of Mutable File} A new form of mutable file could be
implemented in practically the same shape as a directory, containing timestamps
instead of aliases, and pointing to corresponding storage indexes. With this
procedure, it should be easy to configure for the user which files and folders
that should be under version control.

\subsection{Deduplication}

The term \emph{data deduplication} implies not having to store redundant data.
By implementing a deduplication scheme, multiple advantages can arise in the
sense of a secure cloud storage system. For the service provider, this could
mean cost savings in the form of not having to store the same file twice, but
still claim money from users for the given storage. For the users of the
service, this could mean better network utilization, as uploading a big file
that already exist on the server would take no time at all.

However, there are practical disadvantages and great privacy concerns related
to deduplication, in addition to some solutions that address these issues.
The \ac{CSV} does not utilize deduplication, as the scheme simply does not
support it. Since all encryption keys are randomly selected, neither the server
or the client is able to detect whether a file already exists in the system.

\paragraph{Practical Disadvantages} Deduplication relies on the use of hash
functions to check whether a file or a block of data exist on the storage node.
In general, as long as you hash something larger than the length of the digest,
there is the potential for a collision, and hence data corruption.

Further on, the additional hash operations and queries to the server pose
extra computational overhead, which increase if the deduplication is on block
level.

\paragraph{Privacy} Implicitly, using deduplication globally -- i.e. for the
whole system, for all users -- gives any user of the system the possibility to
check a file for existence. This could for instance be utilized by anti piracy
companies working for the movie industry, by first uploading a file known to be
illegally spread over the Internet, and then see if it takes next to nothing
time to upload it to the server. If this is the case, they can file a petition
to get the company hosting the server to yield the contact information for the
users in question.

\paragraph{Customizable Deduplication} The Tahoe-\ac{LAFS} tries to provide a
solution that has all the advantages and none of the issues related to
deduplication, by \emph{convergent encryption with an added secret}
\cite{tahoe}.

Convergent encryption implies using the hash of the plaintext as the key to the
symmetric encryption algorithm, i.e. the same plaintext will always yield the
same ciphertext, making it relatively easy to implement deduplication.

Tahoe-\ac{LAFS} adds an extra per-client secret to the hashing procedure, as
depicted in Figure \ref{fig:tahoe:dedup}, before using the result as a key to
encrypt the file. This enables per-client deduplication, or per-group
duplication if the user shares the secret with other users. Since the storage
index is based on the encryption key, and the plaintext will always lead to the
same encryption key, the client can check for file existence on the server and
hinder duplication.

\begin{figure}[!h]
    \centering
    \includegraphics[scale=0.55]{TahoeDeduplication.pdf}
    \caption{Tahoe-LAFS deduplication scheme}
    \label{fig:tahoe:dedup}
\end{figure}

\section{Implementation}
\label{sec:DIS:impl}

This section will discuss and deal with the different choices taken to fulfill
the implementation of the cryptographic scheme. We will start by discussing the
use case we chose to implement. Further on, we will analyse our choice of key
distribution and look at alternative solutions. The section will end by a
discussion of the most important cryptographic primitives chosen and utilized
in our implementation.

\subsection{Choice of Use Case}

There are mainly two types of user groups interested in a cloud storage
solution -- personal or enterprise. The proof of concept implementation is more
aimed against the personal use case, than the enterprise market. The main
difference between these two use cases, is that in an enterprise there will
usually be some kind of IT department which will have the possibility of
initially setting up the terminals before handing them out to the users.

An additional fundamental difference is that it would usually be more defined
who the users are supposed to share files with, and what they should have
access to. An organization might not approve of a model where all users can
forward read rights to every other users.

\subsection{Choice of Key Distribution}
\label{sec:DI:keydist}
%Describe possible key distributions schemes
%Argue why we chose our scheme

The challenge of key distribution is a hard one. To successfully authenticate a
user and transfer a key, it is possible to choose from the following methods:

\begin{itemize}
 \item Use a trusted third party
 \item Meet a user in person
 \item Use some sort of out of bound safe channel
\end{itemize}

Since one of the basic problems of this thesis is that the cloud provider is
not to be trusted, it is not desirable to use a trusted third party. This
implies that the only option left, is to verify another user in person,
although a scheme similar to \ac{PGP} could be used. 

In \ac{PGP}, users can publish that they have verified other users and to which
degree they trust them \cite{stallings}. Other users can use this information
to calculate the probability that a certain user is legit. The reason why this
scheme is not implemented, is that it is fairly complex for a standard user to
grasp. There are however nothing that stops a user that want to use the
\ac{PGP} scheme to transfer capabilities through it.

If the cryptographic scheme presented in Section \ref{chap:CS} should be used
in an organization, a \ac{PKI} is probably the best solution. In this setting,
the organization can itself be the trusted third party that enforces that all
certificates granted to users are correct. A user could then simply be prompted
by the name of the user he would like to share a file with, and the rest could
be handled by software logic and the trust of the \ac{PKI}.

\subsection{Deviations in the Choice of Cryptographic Primitives}

The implementation of the proof of concept client deviates from
the recommendation given in Section \ref{sec:cryptoprimitivechoice}. 
These deviations occurred as a result of new discoveries that were made while analysing
the system. All unfortunate deviations are corrected with a patch file submitted
along with the code attachment, described in Appendix \ref{ap:attachments}. The
following deviations exist.

\paragraph{RSA Key Length} The key length chosen for the RSA cipher is 1024
bits, in contrast to the argued 2048 bits. It is therefore important to notice
that all measurements, presented in Chapter \ref{ch:experimental} and
\ref{ch:results}, are based on an RSA key length of 1024 bits.

\paragraph{PBKDF2 Salt} As argued in Section \ref{sec:cryptoprimitivechoice},
the length of the salt used with the \ac{PBKDF2} should be as long as the
length of the key. In the implementation, the salt value is only 8 bytes, as
opposed to the key length of 32 bytes.

\subsection{Simplifying the Server}

The implemented proof of concept server generally performs quite well, and was
never identified as a bottleneck during the performance measurements. However,
by making the server-side contain less logic, \ac{CSV} could be used against
for instance the Amazon S3 service. This would more easily enable users that
are not comfortable with setting up a web server, to set up the whole system
from scratch.

By redesigning the scheme to use a \emph{dumb file store}, the \ac{ACL}
functionality will be lost. However, a service like Amazon S3 do provide some
access control, and in the scenario of a \emph{friend net}, this could actually
be considered as a better solution. Luckily, the cryptographic architecture
presented in Section \ref{chap:CS}, are loosely coupled with the \ac{ACL}
layer, so extending the proof of concept software to use a dumb file store
should not pose any great problems.

\section{Performance}

The measurements of performed on our client reveal that it is not as fast as
desirable. For files, a perfect client would render the network or the SD card
as the bottleneck, but our measurements state that this is clearly not the
case. 

The speed we get when downloading or uploading a file is decreased by about
50-80\% on all three test devices. The results for the individual operations
performed on HTC Desire shown in Table \ref{tbl:desire:pinpoint}, clearly
indicates that encryption and decryption are the slowest elements in the
process pipeline, and responsible for most of the performance drop. 

\paragraph{Limitations of Libraries} Another thing to note, is that the
implementations of the \texttt{InputStreams} and \texttt{OutputStreams} stream
objects in Java and the Apache HttpComponents seem to read and write the
requested number of bytes stream by stream. This implies that the
implementation will never reach even the speed of the slowest component in the
pipeline.

\paragraph{Multiple CPU Cores} Branching the operations in the pipeline to
different threads should make it possible to gain better performance,
especially in an environment which spots multiple processor cores. Multiple
\ac{CPU} cores is standard on modern computers, and there is no reason to
suspect otherwise than that also smart phones will be equipped with this in the
nearest future. In addition, dedicated cryptographic co-processors may
relieve the \ac{CPU} from additional work.

\paragraph{Folders} The performance of the folder operations in the
implementation is quite good, if we look at only the cryptographic
functionality. We identify the slowest operation to be the generation of
new cryptographic keys. For a user of the Android client, this should not be a
problem, since the folder creation is done as an asynchronous task while the
user enters the name of the new folder. Another solution is to have the
application generate a pool of keys before they are requested by the user, in
this way a key can almost always be ready for the user when he needs it.

The other cryptographic operations on folders completes quite quickly, but the
performance for serializing the folder contents is too low when folders contain
a large number of items. A folder with thousands of children is not
something we expect an ordinary user of our Android client to have, but if we
change the scenario to backing up an entire computer, the serialization part
might become a problem. 

The reason why this serialization operation is slow, it to be blamed on our
implementation alone. The folder items are stored in a \texttt{HashMap}, which
is serialized to a string to make it ready for encryption. Ideally, this step
is not necessary, if the contents exists in the correct form in memory by
default. Even though this might not be possible for other reasons, such as
decreased performance when manipulating the folder contents, we believe a
faster implementation of a serialization algorithm is possible to find.

\paragraph{Cache} Since opening folders is a relatively expensive procedure,
given that it has to be downloaded from the server, decrypted and verified, we
keep the currently opened folder and its parents in a stack. This can be seen
on as a kind of cache, and could be extended to include all folders opened
in the active session.

\section{Security}

The secure storage system described in this thesis is based on the idea of
hiring storage from an untrusted provider. Thus, the security of the
application should primarily reflect that. With this as a starting point, we
can assume that all data stored on the server is obtainable by the provider.

This section will discuss the general security provided by the \acl{CSV}, and
is further divided into security of the cryptographic scheme and security of
the user client.

\subsection{Security of Cryptographic Scheme}

The proposed cryptographic scheme is subject to certain weaknesses that
currently, or in the future, may be utilized by an attacker. The following
subsections will discuss possible weaknesses and their consequences.

\subsubsection{Information leakage}

The storage provider can access all encrypted data on the server, and also know
whether a stored data object corresponds to a file or a folder. This is
revealed by the difference in header content and size between folder and file
objects. Folders are specially recognizable by the server, as their write
enabler is revealed during upload procedure. 

Additionally, a user's root folder is known, since it is the first object
accessed in a newly created session. It is also possible for the provider to
reveal the structure of the directory tree of a user. The series of file and
folder requests from a user enables the provider to learn which files are
contained in which folders.

Considering the findings in various research, information can also be leaked to
other potential attackers besides the untrusted cloud provider. External
attackers can locate the server in the cloud, used by the application, and
further set up a \ac{VM} on the same server \cite{cloud_getoff}. The \ac{VM}
can then be used to mount cross-\ac{VM} side-channel attacks to extract
information from the server side application. This will, however, in a worst
case scenario, enable an attacker to achieve the exact same information as the
untrusted cloud provider, hence, no more information is leaked from the
application than expected.

\subsubsection{Content Disclosure}

The confidentiality of both files and folders relies primarily on the symmetric
cipher used to encrypt the data. But for folders one can obtain this key if one
manages to obtain the asymmetric private key belonging to the folder, as seen
in Figure \ref{fig:CS:CD}. In other words, files and folders are attackable
both trough the asymmetric and the symmetric cipher used.

Disclosing folder content through the asymmetric cipher may be avoided by
changing the usage of the private key. Instead of hashing the private key to
derive the write key of a folder, the write key could rather be generated from
a random key generator. In this way, even though the asymmetric private key is
revealed, the symmetric keys used to provide confidentiality are not retrieved.
However, revealing the private key would still breach the integrity of the
cryptographic scheme.

If the confidentiality of a folder is breached, it will additionally enable the
attacker to decrypt all of the corresponding subfolders and files. In
contrast, cracking the confidentiality of a file will only compromise that
specific file. It is also important to note that if the confidentiality of a
user's root folder is breached, all files, belonging to that user, are
effectively compromised.

\subsubsection{Disclosing the Keyring Content}

The confidentiality of the cryptographic root key and user passwords is held by
a single encrypted keyring that is stored locally client-side.

The keyring is encrypted with a cryptographic key derived from a password
provided by the user. Unfortunately, using a password to encrypt the keyring,
makes the keyring a suitable target for brute force and dictionary attacks. The
vulnerability of the keyring against brute force and dictionary attacks was
questioned in Section \ref{sec:BFLK}.

\paragraph{Brute Forcing the Keyring} From the results in Section
\ref{sec:R:BFLK} and Figure \ref{fig:bfres}, we noticed that the choice of
iterations in \ac{PBKDF2} were conclusive to the efficiency of a brute force
attack against the local keyring. By doubling the number of iterations in
\ac{PBKDF2}, the efficiency of a brute force attack would decrease by a
corresponding 50\%.

It is important to notice that both of the \ac{CDA} and the \ac{BFDA} programs
were written in Java. With this in mind, it is reasonable to believe that
general performance can be improved by using a lower-layer programming
language, such as C, to implement the attacks. Another way to increase
performance is to design both attacks to run on \acp{GPU} rather than
\acp{CPU}.

When following the recommendations for \ac{PBKDF2} and password constraints
given in Section \ref{sec:PBKD}, it is impossible to perform a plain brute
force attack against the local keyring. However, even though the keyring is
secured against a plain brute force attack, it is still vulnerable to
dictionary attacks.

To completely avoid brute force and dictionary attacks against the keyring, the
most efficient and preventive action is to simply ensure that the encrypted
keyring is only accessible by its authorized users. In other words, the
confidentiality of the encrypted keyring relies primarily on the security of
the client software itself.

\subsubsection{The Weakest Link}

Considering the potential weaknesses discussed above, the weakest link in the
secure cloud storage scheme presented, is, by no doubt, the locally encrypted
keyring. To provide usability, users are given the possibility of choosing
their own password, to indirectly encrypt their keyring. However, it is fairly
well known that users can not be trusted to generate and use long, secure
passwords.

As mentioned earlier, even with the recommended password constraints, the
keyring is still vulnerable to dictionary attacks. However, disclosing the
keyring is only possible if the keyring is accessible to an attacker. Getting
access to a user's keyring is defined as an \emph{active attack}, and is
further discussed in the next section.

\subsection{Client Security}

Given enough users, sooner or later, there will be a user who looses the
control over the equipment where the client software is installed.
Additionally, a user's client might also be broken into without the user even
knowing it. This section will look at the security of the application in both
scenarios.

\subsubsection{Lost Client}

If a user physically looses his client, and the client is logged on to the
\acl{CSV}, anyone who finds the client can get access to the user's
private files and folders. 

While logged on to the service, it is also possible for an experienced attacker
to reveal the server access username and password, as well as the password to
decrypt the locally stored keyring. This is possible due to the fact that all
information is stored in memory while logged on to the system. Although this is
a severe security breach, it can be avoided by adding additional functionality,
e.g. by simply flushing or overwriting the password values stored in memory
right after a successful login session.

Even though this mechanism prevents disclosure of critical access data in the
event of loosing a client, it does not prevent a logged in attacker from
disclosing the user's encrypted files and folders. To reduce this problem, the
client software could implement a timeout mechanism for inactive users. If a
user has been inactive for a reasonable given time interval, the user should be
logged out of the application. 

\paragraph{Downloaded Files} Even though a timeout value may deny an attacker
access to the storage vault, it can not prevent the attacker from accessing
files that have already been downloaded from the system. There is, however, two
ways of handling this problem.

The first solution is to avoid writing downloaded files to the persistent
storage medium. This can be implemented using a temporary file system that only
persists in the memory of the client, e.g. \emph{ramfs} and \emph{tmpfs} are
two temporary file systems for clients running Unix-like operating systems.
However, by utilizing this method, will limit the possible size of the
downloaded files to the size of the available memory. 

In case limited file size is not an acceptable solution, it is possible to use
a temporary file system that supports swapping, as in the case of \emph{tmpfs}.
This will, however, potentially keep parts of a large file on the persistent
storage medium, revealing information about a downloaded file.

A second solution would be for the \acl{CSV} to store downloaded files in their
encrypted form. The downloaded files could then only be opened locally through
the client application itself, which would further decrypt and enable the user
to open the file through other programs. It is worth noting that this
mechanism resembles the procedure of \emph{file synchronization} between the
client and the cloud, similar to the functionality of Dropbox, mentioned in
Section \ref{sec:existing}.

\subsubsection{Compromised Client}

As mentioned earlier, an attacker could also break into the user equipment of a
user, using a backdoor, trojan horse or similar. Depending on the attack, a
worst case scenario would be that the attacker is able to obtain root access on
the user equipment. 

With root access, the attacker has gained complete control over the client and
can access whatever data resource desired within the client. With this in mind,
the attacker can read, write and execute every file that has been downloaded by
the \acl{CSV}.

\paragraph{Reading Memory} Given root access, the attacker can also utilize
software to read live content from the memory of the client. In this case, it
is unfortunately not possible to protect against disclosure of passwords or
capabilities, as the software is dependent on storing the keyring password in
memory during the login procedure.

Capabilities are also stored in memory during browsing of contents in the
cloud. Both passwords and capabilities are therefore retrievable by the
attacker, even though their necessary storage time in memory is kept to a
minimum by the application. 

\paragraph{Keylogger} Another and more plausible scenario, would involve the
attacker installing a keylogger on the compromised client. This peace of
software can further detect the keyring password when the user logs in to the
application.

%**************************************%
\chapter{Conclusion and Future Work}
\label{ch:conclusion}
%**************************************%

As it turns out, one of the greatest challenges when developing a software
application, is the choice and implementation of the cryptographic primitives.
Good references and external recommendations can help, but only so far.
The \ac{CSV} does indeed utilize functions from the whole cryptographic
spectrum, so the choice of basing the cryptographic architecture on an already
well tested solution -- i.e. the Tahoe-\ac{LAFS} -- has proven to be a good
idea.

\section{Compared with Other Solutions}
% BibTeX bibliography lives in external file
\bibliographystyle{unsrtnat}
\bibliography{references}
% TODO: Can we fix references in order of apperance?

%**************************************%
\appendix
\appendixpage
\addappheadtotoc
%**************************************%
%**************************************%
\chapter{Other Relevant Implementations}
\label{ap:other}
%**************************************%

This chapter will study implementation details from applications that were
created, but not a part of the thesis' main topic. Applications considered are
Brute Force and Dictionary Attack (BFDA) and the Cluster Dictionary Attack (CDA).

\section{Brute Force and Dictionary Attack}

\emph{\ac{BFDA}} includes a plain brute force attack and a dictionary attack against
a users encrypted keyring. Details about the implementation follows.

\subsection{Implementation Details}

\ac{BFDA} is written in Java and utilize the \texttt{javax.crypto} library with Bouncy
Castle version 1.34 as JCE provider to decrypt the encrypted keyring. The
Bouncy Castle JCE provider seems to be necessary as Android 2.2 uses it by
default to encrypt the keyring. To enable \emph{PBKDF2} before decryption, \ac{BFDA}
utilize a \emph{PBKDF2} Java library \cite{pbkdf2}.

The program is divided into two functions, named \texttt{bruteForceAttack} and
\texttt{dictionaryAttack} that correspondingly executes a brute force and
dictionary attack. The \texttt{bruteForceAttack} function is shown in Listing
\ref{lst:bffunc}.

\lstinputlisting[language=java, label=lst:bffunc, caption=bruteForceAttack
function]{listings/bruteForceAttack.java}

\texttt{bruteForceAttack} starts a number of \texttt{BruteForceThread} threads.
The function continues after all \texttt{BruteForceThreads} are initialized and
ready to start their task. It then enters a while-loop, which executes a
\texttt{pushWord} function for each iteration.

The task of \texttt{pushWord} is to simply create and push all possible words
of a given length onto a stack of words. The length of the words to push are
given by its integer argument. The whole attack is based on letting the main
thread create and push words onto a stack, while the \texttt{BruteForceThreads} are
pulling words from the stack. When a word is pulled from the stack, it is
subject to \emph{PBKDF2}, where the result is used to decrypt the ciphertext. If
decryption results in a given plaintext, the password is found.

The \texttt{dictionaryAttack} function is shown in Listing \ref{lst:dafunc}.

\lstinputlisting[language=java, label=lst:dafunc, caption=dictionaryAttack
function]{listings/dictionaryAttack.java}

\texttt{dictionaryAttack} reads an input dictionary file into a
\texttt{BufferedReader}. It then starts a given number of
\texttt{DictionaryThreads}. The \texttt{DictionaryThreads} will read from the
\texttt{BufferedReader} in a synchronized way. When a word is read from a
\texttt{DictionaryThread} it will be subject to \emph{PBKDF2}, where the result is
used to decrypt the ciphertext. If decryption results in a given plaintext, the
password is found.

\section{Cluster Dictionary Attack}

The \ac{CDA} is written in Java, and is built around the same procedure as the
dictionary attack in \ac{BFDA}. However, the difference lays in the cooperation
of multiple computers. To enable a cluster of computers to cooperate, we used
the following environment.

\subsection{Environment}

The environment is based upon a software framework from Apache called
\emph{Hadoop}. The main functionality of Hadoop is described below.

\subsubsection{Apache Hadoop}

Apache Hadoop makes it possible for multiple machines to cooperate
and run computational work together. Hadoop also provides a distributed file system
\ac{HDFS}, that can store data across multiple cooperating machines \cite{hadoop}. The
computational work in Hadoop is organized and distributed using \emph{MapReduce}.

\paragraph{MapReduce} MapReduce is a programming paradigm introduced by Google.
It is designed to process and generate large sets of data using a cluster of
machines \cite{mapred}.

In MapReduce, a large set of input data is divided into multiple key/value
pairs. The key/value pairs are further distributed to multiple MapReduce tasks
running on multiple machines.

A MapReduce task is divided into a \emph{mapper} and a \emph{reducer}. The task
of a mapper is to perform an operation on a key/value pair and return a
key/value pair as a result to the reducer. The reducer collects key/value pairs
from multiple mappers and combine the results into one or more output files.

\subsection{Implementation Details}

The \ac{CDA} attack is implemented as a MapReduce problem, with a large
dictionary file as the data input set. The dictionary is split into separate
key/value pairs, where each value is a single line in the dictionary and the
key corresponds to the line's offset within the dictionary.

The key/value pairs are handled by a map function implemented in
\texttt{CDAMapper}. The
map function has the responsibility of checking every word on a single
dictionary line. Each line in the dictionary should contain a certain amount of
words. This is to enable the map function to run multiple threads at the same
time, where each thread checks one or more words. With multiple threads, the
attack is able to utilize more \ac{CPU} power for each running machine in the
cluster. A detailed view of the map function, is given in Listing
\ref{lst:mapfunc}.

\lstinputlisting[language=java, label=lst:mapfunc, caption=Mapper function in
CDAMapper]{listings/mapper.java}

When receiving a key/value pair, the map function first splits the input line
into an array of words called line. It then creates a given number of
\texttt{DictionaryThread} threads and serves each thread a sub array of words from the
line array. Each \texttt{DictionaryThread} will check all of its incoming words similar
to the \texttt{DictionaryThread} in BFDA. If the correct password is found, the
password will be written to the \texttt{sysout} folder on the machine where the mapper is
running.

A class named \texttt{Processor} initializes the \ac{CDA} attack by configuring
the mapper and reducer tasks. The number of mappers is set equal to the number
of nodes used in the cluster. This is to ensure that each machine only runs one
mapper at a time. The number of reducers are set to zero, because their
behavior in MapReduce is not needed.

\paragraph{Notice} The for-loop at Line 10 in Listing \ref{lst:mapfunc}
requires the number of words per line, in the dictionary, to be equal to a
multiple of the number of threads in use. It is recommended that the input
dictionary follows this requirement.

In this occasion, we have created a Bash script, named \texttt{dictmaker.sh},
that changes a regular dictionary into an $N$ words-per-line dictionary. The
script can be found on the attached CD-ROM.

%**************************************%
\chapter{Attachments}
\label{ap:attachments}
%**************************************%

This thesis comes with two available attachments -- one digitally uploaded to
the DAIM system\footnote{\url{http://daim.idi.ntnu.no/}}, and one physical DVD.

\section{Electronic Attachment}

The electronic attachment, uploaded to
DAIM, consists of the following files
and directories:

\begin{description}
  \item[Application] All files and source code of the proof of concept system,
    i.e. the background library, server and client. A patch file containing
    security fixes, is also included.
  \item[Report] All files that is used to create this report, including images
    and tables.
  \item[Other] Scripts and raw data from the experiments.
\end{description}

\section{Attached DVD}

All the source code generated while working on this thesis, including the
source code for the proof of concept client code, can be found on an attached
DVD. In addition, all files related to the writing of this document, including
images and most of the references, are also included on the same DVD.

\end{document}
